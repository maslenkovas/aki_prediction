{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "\n",
    "# Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import f1_score, multilabel_confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_PATH = os.getcwd()\n",
    "PKL_PATH = CURR_PATH+'/pickles/'\n",
    "DF_PATH = CURR_PATH +'/dataframes/'\n",
    "TXT_DIR_TRAIN = CURR_PATH + '/txt_files/train'\n",
    "destination_folder = CURR_PATH + '/training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT_DIR_TRAIN = '/home/svetlana.maslenkova/LSTM/txt_files/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import  Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "import os\n",
    "from os.path import exists\n",
    "import glob\n",
    "\n",
    "# Training the tokenizer\n",
    "if exists(CURR_PATH + '/aki_prediction/tokenizer.json'):\n",
    "    print(f'Tokenizer is loaded from {CURR_PATH}')\n",
    "    tokenizer = Tokenizer.from_file(CURR_PATH + '/aki_prediction/tokenizer.json')\n",
    "else:\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    trainer = BpeTrainer(special_tokens=[\"[PAD]\", \"[UNK]\"], min_frequency=3)\n",
    "    files = glob.glob(TXT_DIR_TRAIN+'/*')\n",
    "    tokenizer.train(files, trainer)\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save('/home/svetlana.maslenkova/LSTM' + '/tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21675"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', '72190']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.encode('D72190')\n",
    "output.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = {'demographics':5, 'lab_tests':400, 'vitals':200, 'medications':255}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_length, max_days):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_days = max_days\n",
    "        self.max_len_demo = max_length['demographics']\n",
    "        self.max_len_labs = max_length['lab_tests']\n",
    "        self.max_len_vitals = max_length['vitals']\n",
    "        self.max_len_meds = max_length['medications']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.make_matrices(idx, self.max_days)\n",
    "    \n",
    "    def tokenize(self, text, max_length):\n",
    "        \n",
    "        output = self.tokenizer.encode(text)\n",
    "        # padding and truncation\n",
    "        if len(output.ids) < max_length:\n",
    "            len_missing_token = max_length - len(output.ids)\n",
    "            padding_vec = [self.tokenizer.token_to_id('[PAD]') for _ in range(len_missing_token)]\n",
    "            token_output = [*output.ids, *padding_vec]\n",
    "        elif len(output.ids) > max_length:\n",
    "            token_output = output.ids[:max_length]\n",
    "        else:\n",
    "            token_output = output.ids\n",
    "        \n",
    "        return token_output\n",
    "\n",
    "    def make_matrices(self, idx, max_days):\n",
    "        info_demo = self.df.demographics_in_visit.values[idx][0]\n",
    "        info_med = self.df.medications_in_visit.values[idx]\n",
    "        info_vitals = self.df.vitals_in_visit.values[idx]\n",
    "        info_labs = self.df.lab_tests_in_visit.values[idx]\n",
    "        aki_status = self.df.aki_status_in_visit.values[idx]\n",
    "        days = list(self.df.days.values[idx])\n",
    "\n",
    "        aki_happened = False\n",
    "        labels = []\n",
    "        info_med_list = []\n",
    "        info_vitals_list = []\n",
    "        info_labs_list = []\n",
    "\n",
    "        for day in range(max_days+1):\n",
    "            # if aki happened - pad labels and info for next days \n",
    "            if (day not in days) or (aki_happened==True):\n",
    "                labels.append(0)\n",
    "                info_med_list.append(self.tokenize('', self.max_len_meds))\n",
    "                info_vitals_list.append(self.tokenize('', self.max_len_vitals))\n",
    "                info_labs_list.append(self.tokenize('', self.max_len_labs))\n",
    "\n",
    "            else:\n",
    "                i = days.index(day)\n",
    "                # indicate that aki happened\n",
    "                if aki_status[i] == 1:\n",
    "                    aki_happened = True\n",
    "\n",
    "                labels.append(aki_status[i])\n",
    "                if str(info_med[i]) == 'nan':\n",
    "                    info_med_list.append(self.tokenize('[PAD]', self.max_len_meds))\n",
    "                else:\n",
    "                    info_med_list.append(self.tokenize(info_med[i], self.max_len_meds))\n",
    "\n",
    "                if str(info_vitals[i]) == 'nan':\n",
    "                    info_vitals_list.append(self.tokenize('[PAD]', self.max_len_vitals))\n",
    "                else:\n",
    "                    info_vitals_list.append(self.tokenize(info_vitals[i], self.max_len_vitals))\n",
    "\n",
    "                if str(info_labs[i]) == 'nan':\n",
    "                    info_labs_list.append(self.tokenize('[PAD]', self.max_len_labs))\n",
    "                else:\n",
    "                    info_labs_list.append(self.tokenize(info_labs[i], self.max_len_labs))\n",
    "                    \n",
    "        info_demo = self.tokenize(info_demo,  self.max_len_demo)\n",
    "\n",
    "        #make tensors\n",
    "        tensor_demo = torch.tensor(info_demo, dtype=torch.int32)\n",
    "        tensor_med = torch.tensor(info_med_list, dtype=torch.int32)\n",
    "        tensor_vitals = torch.tensor(info_vitals_list, dtype=torch.int32)\n",
    "        tensor_labs = torch.tensor(info_labs_list, dtype=torch.int32)\n",
    "        tensor_labels = torch.tensor(labels, dtype=torch.int32)\n",
    "        return (tensor_demo, tensor_med, tensor_vitals, tensor_labs), tensor_labels\n",
    "\n",
    "\n",
    "\n",
    "class LSTM_model(nn.Module):\n",
    "\n",
    "    def __init__(self, H=128, max_length=max_length, max_day=13):\n",
    "        super(LSTM_model, self).__init__()\n",
    "\n",
    "\t\t# Hyperparameters\n",
    "        self.max_day = max_day\n",
    "        L = (self.max_day+1) * (256 + 256 + 512) + 1280\n",
    "        self.H = H\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "        self.fc_med = nn.Linear(max_length['medications'] * 2 * self.H, 256)  #65,280\n",
    "        self.fc_vit = nn.Linear(max_length['vitals'] * 2 * self.H, 256)   #51,200\n",
    "        self.fc_lab = nn.Linear(max_length['lab_tests'] * 2 * self.H, 512) #102,400\n",
    "\n",
    "        self.lstm_day = nn.LSTM(input_size=embedding_size,\n",
    "                            hidden_size=self.H,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.fc_1 = nn.Linear((self.max_day+1) * (256 + 256 + 512) + 1280, 2048)\n",
    "\n",
    "        self.lstm_adm = nn.LSTM(input_size=2048,\n",
    "                            hidden_size=self.H,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=False)\n",
    "\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc_2 = nn.Linear(self.H, (self.max_day+1))\n",
    "        \n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, tensor_demo, tensor_med, tensor_vitals, tensor_labs):\n",
    "\n",
    "        batch_size = tensor_med.size()[0]\n",
    "        days = self.max_day + 1\n",
    "\n",
    "        out_emb_med_demo = self.embedding(tensor_demo.squeeze(1))\n",
    "        output_lstm_day_demo, _ = self.lstm_day(out_emb_med_demo)\n",
    "        full_output = output_lstm_day_demo.reshape(batch_size, self.max_length['demographics']* 2 * self.H)\n",
    "\n",
    "\n",
    "        for d in range(days):\n",
    "            # if i > 1:\n",
    "            #     break\n",
    "            # embedding layer applied to all tensors\n",
    "            out_emb_med = self.embedding(tensor_med[:, d, :].squeeze(1))\n",
    "            out_emb_vitals = self.embedding(tensor_vitals[:, d, :].squeeze(1))\n",
    "            out_emb_labs =  self.embedding(tensor_labs[:, d, :].squeeze(1))\n",
    "            # lstm layer applied to embedded tensors\n",
    "            output_lstm_day_med = self.fc_med(\\\n",
    "                                    self.lstm_day(out_emb_med)[0]\\\n",
    "                                        .reshape(batch_size, max_length['medications'] * 2 * self.H))\n",
    "\n",
    "            output_lstm_day_vitals = self.fc_vit(\\\n",
    "                                        self.lstm_day(out_emb_vitals)[0]\\\n",
    "                                            .reshape(batch_size,  max_length['vitals'] * 2 * self.H))\n",
    "\n",
    "            output_lstm_day_labs = self.fc_lab(\\\n",
    "                                    self.lstm_day(out_emb_labs)[0]\\\n",
    "                                        .reshape(batch_size, max_length['lab_tests']* 2 * self.H))\n",
    "                                        \n",
    "            # concatenate for all 26 days\n",
    "            full_output = torch.cat((full_output, \\\n",
    "                                        output_lstm_day_med,\\\n",
    "                                            output_lstm_day_vitals,\\\n",
    "                                                output_lstm_day_labs), dim=1)\n",
    "        \n",
    "        # print('full_output size: ', full_output.size())\n",
    "        output = self.fc_1(full_output)\n",
    "        output, _ = self.lstm_adm(output)\n",
    "        output = self.drop(output)\n",
    "        output = self.fc_2(output)\n",
    "        output = torch.squeeze(output, 1)\n",
    "        # output = self.sigmoid(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class LSTM_model(nn.Module):\n",
    "\n",
    "    def __init__(self, max_length, pred_window, vocab_size, H=128,  max_day=7, embedding_size=200):\n",
    "        super(LSTM_model, self).__init__()\n",
    "\n",
    "\t\t# Hyperparameters\n",
    "        self.max_day = max_day\n",
    "        self.pred_window = pred_window\n",
    "        L = (self.max_day+1) * (256 + 256 + 512) + 1280\n",
    "        self.H = H\n",
    "        self.max_length = max_length\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # self.embedding = pretrained_model\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "    \n",
    "\n",
    "        self.fc_med = nn.Linear(max_length['medications'] * 2 * self.H, 256)  #65,280\n",
    "        self.fc_vit = nn.Linear(max_length['vitals'] * 2 * self.H, 256)   #51,200\n",
    "        self.fc_lab = nn.Linear(max_length['lab_tests'] * 2 * self.H, 512) #102,400\n",
    "\n",
    "        self.lstm_day = nn.LSTM(input_size=embedding_size,\n",
    "                            hidden_size=self.H,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.fc_1 = nn.Linear((self.max_day - self.pred_window) * (256 + 256 + 512) + max_length['demographics']*2*H, 2048)\n",
    "\n",
    "        self.lstm_adm = nn.LSTM(input_size=2048,\n",
    "                            hidden_size=self.H,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=False)\n",
    "\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc_2 = nn.Linear(self.H, (self.max_day - self.pred_window))\n",
    "        \n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, tensor_demo, tensor_med, tensor_vitals, tensor_labs):\n",
    "\n",
    "        batch_size = tensor_med.size()[0]\n",
    "        days = self.max_day\n",
    "\n",
    "        out_emb_med_demo = self.embedding(tensor_demo.squeeze(1))\n",
    "        output_lstm_day_demo, _ = self.lstm_day(out_emb_med_demo)\n",
    "        full_output = output_lstm_day_demo.reshape(batch_size, self.max_length['demographics']* 2 * self.H)\n",
    "\n",
    "\n",
    "        for d in range(days - self.pred_window):\n",
    "            # embedding layer applied to all tensors\n",
    "            out_emb_med = self.embedding(tensor_med[:, d, :].squeeze(1))\n",
    "            out_emb_vitals = self.embedding(tensor_vitals[:, d, :].squeeze(1))\n",
    "            out_emb_labs =  self.embedding(tensor_labs[:, d, :].squeeze(1))\n",
    "            # lstm layer applied to embedded tensors\n",
    "            output_lstm_day_med = self.fc_med(\\\n",
    "                                    self.lstm_day(out_emb_med)[0]\\\n",
    "                                        .reshape(batch_size, max_length['medications'] * 2 * self.H))\n",
    "\n",
    "            output_lstm_day_vitals = self.fc_vit(\\\n",
    "                                        self.lstm_day(out_emb_vitals)[0]\\\n",
    "                                            .reshape(batch_size,  max_length['vitals'] * 2 * self.H))\n",
    "\n",
    "            output_lstm_day_labs = self.fc_lab(\\\n",
    "                                    self.lstm_day(out_emb_labs)[0]\\\n",
    "                                        .reshape(batch_size, max_length['lab_tests']* 2 * self.H))\n",
    "                                        \n",
    "            # concatenate for all * days\n",
    "            full_output = torch.cat((full_output, \\\n",
    "                                        output_lstm_day_med,\\\n",
    "                                            output_lstm_day_vitals,\\\n",
    "                                                output_lstm_day_labs), dim=1)\n",
    "        \n",
    "        # print('full_output size: ', full_output.size())\n",
    "        output = self.fc_1(full_output)\n",
    "        output, _ = self.lstm_adm(output)\n",
    "        output = self.drop(output)\n",
    "        output = self.fc_2(output)\n",
    "        output = torch.squeeze(output, 1)\n",
    "        # if self.criterion == 'BCELoss':\n",
    "        #     output = self.sigmoid(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained model\n",
    "max_length = {'demographics':5, 'lab_tests':400, 'vitals':200, 'medications':255}\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_length, max_days, pred_window):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_days = max_days\n",
    "        self.pred_window = pred_window\n",
    "        self.max_len_demo = max_length['demographics']\n",
    "        self.max_len_labs = max_length['lab_tests']\n",
    "        self.max_len_vitals = max_length['vitals']\n",
    "        self.max_len_meds = max_length['medications']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.make_matrices(idx, self.max_days)\n",
    "    \n",
    "    def tokenize(self, text, max_length):\n",
    "        \n",
    "        output = self.tokenizer.encode(text)\n",
    "        # padding and truncation\n",
    "        if len(output.ids) < max_length:\n",
    "            len_missing_token = max_length - len(output.ids)\n",
    "            padding_vec = [self.tokenizer.token_to_id('[PAD]') for _ in range(len_missing_token)]\n",
    "            token_output = [*output.ids, *padding_vec]\n",
    "        elif len(output.ids) > max_length:\n",
    "            token_output = output.ids[:max_length]\n",
    "        else:\n",
    "            token_output = output.ids\n",
    "        \n",
    "        return token_output\n",
    "\n",
    "    def make_matrices(self, idx, max_days):\n",
    "        info_demo = self.df.demographics_in_visit.values[idx][0]\n",
    "        info_med = self.df.medications_in_visit.values[idx]\n",
    "        info_vitals = self.df.vitals_in_visit.values[idx]\n",
    "        info_labs = self.df.lab_tests_in_visit.values[idx]\n",
    "        aki_status = self.df.aki_status_in_visit.values[idx]\n",
    "        days = self.df.days.values[idx]\n",
    "\n",
    "        aki_happened = False\n",
    "        labels = []\n",
    "        info_med_list = []\n",
    "        info_vitals_list = []\n",
    "        info_labs_list = []\n",
    "\n",
    "        for day in range(days[0], days[0]+ max_days - self.pred_window):\n",
    "            if day not in days:\n",
    "                labels.append(0)\n",
    "                info_med_list.append(self.tokenize('', self.max_len_meds))\n",
    "                info_vitals_list.append(self.tokenize('', self.max_len_vitals))\n",
    "                info_labs_list.append(self.tokenize('', self.max_len_labs))\n",
    "            else:\n",
    "                i = days.index(day)\n",
    "                \n",
    "                if (day + self.pred_window) not in days:\n",
    "                    labels.append(0)\n",
    "                else:              \n",
    "                    if np.isnan(aki_status[i + self.pred_window]):\n",
    "                        labels.append(0)\n",
    "                    else:\n",
    "                        labels.append(aki_status[i + self.pred_window])\n",
    "\n",
    "                if str(info_med[i]) == 'nan':\n",
    "                    info_med_list.append(self.tokenize('[PAD]', self.max_len_meds))\n",
    "                else:\n",
    "                    info_med_list.append(self.tokenize(info_med[i], self.max_len_meds))\n",
    "\n",
    "                if str(info_vitals[i]) == 'nan':\n",
    "                    info_vitals_list.append(self.tokenize('[PAD]', self.max_len_vitals))\n",
    "                else:\n",
    "                    info_vitals_list.append(self.tokenize(info_vitals[i], self.max_len_vitals))\n",
    "\n",
    "                if str(info_labs[i]) == 'nan':\n",
    "                    info_labs_list.append(self.tokenize('[PAD]', self.max_len_labs))\n",
    "                else:\n",
    "                    info_labs_list.append(self.tokenize(info_labs[i], self.max_len_labs))\n",
    "                    \n",
    "        info_demo = self.tokenize(info_demo,  self.max_len_demo)\n",
    "\n",
    "        #make tensors\n",
    "        tensor_demo = torch.tensor(info_demo, dtype=torch.int32)\n",
    "        tensor_med = torch.tensor(info_med_list, dtype=torch.int32)\n",
    "        tensor_vitals = torch.tensor(info_vitals_list, dtype=torch.int32)\n",
    "        tensor_labs = torch.tensor(info_labs_list, dtype=torch.int32)\n",
    "        tensor_labels = torch.tensor(labels, dtype=torch.int32)\n",
    "        return (tensor_demo, tensor_med, tensor_vitals, tensor_labs), tensor_labels\n",
    "   \n",
    "class EHR_Embedding(nn.Module):\n",
    "    def __init__(self, embedding_size, vocab_size=15463, drop=0.1):\n",
    "        super(EHR_Embedding, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        \n",
    "        self.projection = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=embedding_size, out_features=embedding_size)\n",
    "        )\n",
    "        self.drop = nn.Dropout(p=drop)\n",
    "        \n",
    "    def forward(self, tensor_demo, tensor_med, tensor_vitals, tensor_labs):   \n",
    "        batch_size = tensor_med.size()[0]\n",
    "\n",
    "        # first traansformation\n",
    "        emb_demo_X = self.drop(self.embedding(tensor_demo.squeeze(1)))\n",
    "        emb_med_X = self.drop(self.embedding(tensor_med[:,:].squeeze(1)))\n",
    "        emb_vitals_X = self.drop(self.embedding(tensor_vitals[:,:].squeeze(1)))\n",
    "        emb_labs_X =  self.drop(self.embedding(tensor_labs[:,:].squeeze(1)))\n",
    "\n",
    "        projection_demo_X = self.projection(emb_demo_X)\n",
    "        projection_med_X = self.projection(emb_med_X)\n",
    "        projection_vitals_X = self.projection(emb_vitals_X)\n",
    "        projection_labs_X = self.projection(emb_labs_X)\n",
    "\n",
    "        embedding_X = (emb_demo_X, emb_med_X, emb_vitals_X, emb_labs_X)\n",
    "        projection_X = (projection_demo_X, projection_med_X, projection_vitals_X, projection_labs_X)\n",
    "\n",
    "        # second transformation\n",
    "        emb_demo_Y = self.drop(self.embedding(tensor_demo.squeeze(1)))\n",
    "        emb_med_Y = self.drop(self.embedding(tensor_med[:,:].squeeze(1)))\n",
    "        emb_vitals_Y = self.drop(self.embedding(tensor_vitals[:,:].squeeze(1)))\n",
    "        emb_labs_Y =  self.drop(self.embedding(tensor_labs[:,:].squeeze(1)))\n",
    "\n",
    "        projection_demo_Y = self.projection(emb_demo_Y)\n",
    "        projection_med_Y = self.projection(emb_med_Y)\n",
    "        projection_vitals_Y = self.projection(emb_vitals_Y)\n",
    "        projection_labs_Y = self.projection(emb_labs_Y)\n",
    "\n",
    "        embedding_Y = (emb_demo_Y, emb_med_Y, emb_vitals_Y, emb_labs_Y)\n",
    "        projection_Y = (projection_demo_Y, projection_med_Y, projection_vitals_Y, projection_labs_Y)\n",
    "\n",
    "        return embedding_X, projection_X, embedding_Y, projection_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda'\n",
    "\n",
    "res = evaluate(test_model, test_loader, threshold=0.5, log_res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, threshold=0.5, log_res=True):\n",
    "    \n",
    "    stacked_labels = torch.tensor([]).to(device)\n",
    "    stacked_preds = torch.tensor([]).to(device)\n",
    "    model.eval()\n",
    "    step = 1\n",
    "    correct_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (tensor_demo, tensor_med, tensor_vitals, tensor_labs), tensor_labels in test_loader:\n",
    "            print(f'Step {step}/{len(test_loader)}' )\n",
    "            labels = tensor_labels.to(device)\n",
    "            demo = tensor_demo.to(device)\n",
    "            med = tensor_med.to(device)\n",
    "            vitals = tensor_vitals.to(device)\n",
    "            labs = tensor_labs.to(device)\n",
    "\n",
    "            output = model(demo, med, vitals, labs)\n",
    "            output = nn.Sigmoid()(output)\n",
    "            output = (output > threshold).int()\n",
    "\n",
    "            # stacking labels and predictions\n",
    "            stacked_labels = torch.cat([stacked_labels, labels], dim=0, )\n",
    "            stacked_preds = torch.cat([stacked_preds, output], dim=0, )\n",
    "\n",
    "            get_list_correct_preds(output, labels, correct_preds)\n",
    "            step += 1\n",
    "\n",
    "    # calculate accuracy\n",
    "    acc = np.round(np.sum(correct_preds) / len(correct_preds), 2)\n",
    "    # transfer to device\n",
    "    stacked_labels = stacked_labels.cpu().detach().numpy()\n",
    "    stacked_preds = stacked_preds.cpu().detach().numpy()\n",
    "    # get classification metrics for all samples in the test set\n",
    "    classification_report_res = classification_report(stacked_labels, stacked_preds, zero_division=0, output_dict=True)\n",
    "    # classification_report_res.update({'epoch':epoch+1})\n",
    "\n",
    "    if log_res:\n",
    "        for key, value in classification_report_res.items():\n",
    "            # wandb.log({key:value, 'epoch':epoch+1})\n",
    "            wandb.log({key+'test':value})\n",
    "        # wandb.log({'epoch':epoch+1, 'accuracy':acc})\n",
    "        \n",
    "    return classification_report_res, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "threshold = 0.5\n",
    "correct_preds = []\n",
    "stacked_labels = torch.tensor([]).to(device)\n",
    "stacked_preds = torch.tensor([]).to(device)\n",
    "step = 1\n",
    "for (tensor_demo, tensor_med, tensor_vitals, tensor_labs), tensor_labels in test_loader:\n",
    "    print(f'step {step}/{len(test_loader)}')\n",
    "    labels = tensor_labels.to(device)\n",
    "    demo = tensor_demo.to(device)\n",
    "    med = tensor_med.to(device)\n",
    "    vitals = tensor_vitals.to(device)\n",
    "    labs = tensor_labs.to(device)\n",
    "\n",
    "    output = test_model(demo, med, vitals, labs)\n",
    "    output = sigmoid(output)\n",
    "    # get_list_correct_preds(output, labels, correct_preds,  threshold)\n",
    "    output = (output > threshold).int()\n",
    "    # stacking labels and predictions\n",
    "    stacked_labels = torch.cat([stacked_labels, labels], dim=0, )\n",
    "    stacked_preds = torch.cat([stacked_preds, output], dim=0, )\n",
    "    step += 1\n",
    "    # if step > 9:break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering admissions...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/svetlana.maslenkova/LSTM/aki_prediction/other/dataframes/pid_train_df_finetuning_6days_aki.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_817441/2308935500.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# loading the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDF_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'pid_train_df_finetuning_6days_aki.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpid_train_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/svetlana.maslenkova/LSTM/aki_prediction/other/dataframes/pid_train_df_finetuning_6days_aki.pkl'"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "print('Filtering admissions...')\n",
    "CURR_PATH = os.getcwd()\n",
    "PKL_PATH = CURR_PATH+'/pickles/'\n",
    "DF_PATH = CURR_PATH +'/dataframes/'\n",
    "\n",
    "# loading the data\n",
    "with open(DF_PATH + 'pid_train_df_finetuning_6days_aki.pkl', 'rb') as f:\n",
    "    pid_train_df = pickle.load(f)\n",
    "\n",
    "with open(DF_PATH + 'pid_val_df_finetuning_6days_aki.pkl', 'rb') as f:\n",
    "    pid_val_df = pickle.load(f)\n",
    "\n",
    "with open(DF_PATH + 'pid_test_df_finetuning_6days_aki.pkl', 'rb') as f:\n",
    "    pid_test_df = pickle.load(f)\n",
    "\n",
    "observing_window = 3 \n",
    "\n",
    "train_admissions = []\n",
    "for adm in pid_train_df.hadm_id.unique():   \n",
    "    if ({1,2,3,4}.issubset(set(pid_train_df[pid_train_df.hadm_id==adm].days.values[0])) or \\\n",
    "        {-1,0,1,2}.issubset(set(pid_train_df[pid_train_df.hadm_id==adm].days.values[0]))or \\\n",
    "            {0,1,2,3}.issubset(set(pid_train_df[pid_train_df.hadm_id==adm].days.values[0]))) and \\\n",
    "        (len(pid_train_df[pid_train_df.hadm_id==adm].days.values[0])>3) and\\\n",
    "            sum(pid_train_df[pid_train_df.hadm_id==adm].aki_status_in_visit.values[0][:observing_window])==0:\n",
    "        train_admissions.append(adm)\n",
    "\n",
    "val_admissions = []\n",
    "for adm in pid_val_df.hadm_id.unique():   \n",
    "    if ({1,2,3,4}.issubset(set(pid_val_df[pid_val_df.hadm_id==adm].days.values[0])) or \\\n",
    "        {-1,0,1,2}.issubset(set(pid_val_df[pid_val_df.hadm_id==adm].days.values[0]))or \\\n",
    "            {0,1,2,3}.issubset(set(pid_val_df[pid_val_df.hadm_id==adm].days.values[0]))) and \\\n",
    "        (len(pid_val_df[pid_val_df.hadm_id==adm].days.values[0])>3) and\\\n",
    "            sum(pid_val_df[pid_val_df.hadm_id==adm].aki_status_in_visit.values[0][:observing_window])==0:\n",
    "        val_admissions.append(adm)\n",
    "\n",
    "test_admissions = []\n",
    "for adm in pid_test_df.hadm_id.unique():   \n",
    "    if ({1,2,3,4}.issubset(set(pid_test_df[pid_test_df.hadm_id==adm].days.values[0])) or \\\n",
    "        {-1,0,1,2}.issubset(set(pid_test_df[pid_test_df.hadm_id==adm].days.values[0]))or \\\n",
    "            {0,1,2,3}.issubset(set(pid_test_df[pid_test_df.hadm_id==adm].days.values[0]))) and \\\n",
    "        (len(pid_test_df[pid_test_df.hadm_id==adm].days.values[0])>3) and\\\n",
    "            sum(pid_test_df[pid_test_df.hadm_id==adm].aki_status_in_visit.values[0][:observing_window])==0:\n",
    "        test_admissions.append(adm)\n",
    "\n",
    "print('train_admissions', len(train_admissions))\n",
    "print('val_admissions', len(val_admissions))\n",
    "print('test_admissions', len(test_admissions))\n",
    "\n",
    "pid_train_df = pid_train_df[pid_train_df.hadm_id.isin(train_admissions)]\n",
    "pid_val_df = pid_val_df[pid_val_df.hadm_id.isin(val_admissions)]\n",
    "pid_test_df = pid_test_df[pid_test_df.hadm_id.isin(test_admissions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokenizer...\n",
      "\n",
      "\n",
      "\n",
      "Vocab size is 28577\n"
     ]
    }
   ],
   "source": [
    "min_frequency = 5\n",
    "print('Training tokenizer...')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(special_tokens=[\"[PAD]\", \"[UNK]\"], min_frequency=min_frequency)\n",
    "files = glob.glob(TXT_DIR_TRAIN+'/*')\n",
    "tokenizer.train(files, trainer)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(f'Vocab size is {tokenizer.get_vocab_size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', '72190']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.encode('D72190')\n",
    "output.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_length_day=400, pred_window=2, observing_window=3):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.observing_window = observing_window\n",
    "        self.pred_window = pred_window\n",
    "        self.max_length_day = max_length_day\n",
    "        self.max_length_diags = 30\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.make_matrices(idx)\n",
    "    \n",
    "    def tokenize(self, text, max_length):\n",
    "        \n",
    "        try:\n",
    "            output = self.tokenizer.encode(text)\n",
    "        except:\n",
    "            print(type(text), text, max_length)\n",
    "            output = self.tokenizer.encode(text)\n",
    "\n",
    "        # padding and truncation\n",
    "        if len(output.ids) < max_length:\n",
    "            len_missing_token = max_length - len(output.ids)\n",
    "            padding_vec = [self.tokenizer.token_to_id('[PAD]') for _ in range(len_missing_token)]\n",
    "            token_output = [*output.ids, *padding_vec]\n",
    "        elif len(output.ids) > max_length:\n",
    "            token_output = output.ids[:max_length]\n",
    "        else:\n",
    "            token_output = output.ids\n",
    "        \n",
    "        return token_output\n",
    "\n",
    "    def make_matrices(self, idx):\n",
    "        \n",
    "        day_info = self.df.days_in_visit.values[idx]\n",
    "        diagnoses_info = self.df.previous_diagnoses.values[idx][0]\n",
    "        aki_status = self.df.aki_status_in_visit.values[idx]\n",
    "        days = self.df.days.values[idx]\n",
    "        # print(idx)\n",
    "\n",
    "        labels = []\n",
    "        day_info_list = []\n",
    "        label = None\n",
    "\n",
    "        for day in range(days[0], days[0] + self.observing_window + self.pred_window):\n",
    "            # print('day', day)\n",
    "            if day not in days:\n",
    "                labels.append(0)\n",
    "                day_info_list.append(self.tokenize('', self.max_length_day))\n",
    "            else:\n",
    "                i = days.index(day)\n",
    "                \n",
    "                if np.isfinite(aki_status[i]):                    \n",
    "                    labels.append(aki_status[i])\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "\n",
    "                if (str(day_info[i]) == 'nan') or (day_info[i] == np.nan):\n",
    "                    day_info_list.append(self.tokenize('[PAD]', self.max_length_day))\n",
    "                else:\n",
    "                    day_info_list.append(self.tokenize(day_info[i], self.max_length_day))\n",
    "\n",
    "\n",
    "        if sum(labels[-self.pred_window:]) > 0:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        if (str(diagnoses_info) == 'nan') or (diagnoses_info == np.nan):\n",
    "            diagnoses_info = self.tokenize('[PAD]', self.max_length_diags)\n",
    "        else:\n",
    "            diagnoses_info = self.tokenize(diagnoses_info, self.max_length_diags)\n",
    "\n",
    "        #make tensors\n",
    "        tensor_day = torch.tensor(day_info_list[:self.observing_window], dtype=torch.int64)\n",
    "        tensor_diags = torch.tensor(diagnoses_info, dtype=torch.int64)\n",
    "        # tensor_labels = torch.tensor(labels[- self.pred_window:], dtype=torch.float64)\n",
    "        tensor_labels = torch.tensor(label, dtype=torch.float64)\n",
    "    \n",
    "\n",
    "        return tensor_day, tensor_diags, tensor_labels, idx\n",
    "\n",
    "\n",
    "class EHR_MODEL(nn.Module):\n",
    "    def __init__(self, max_length, vocab_size, device, pred_window=2, observing_window=3,  H=128, embedding_size=200):\n",
    "        super(EHR_MODEL, self).__init__()\n",
    "\n",
    "        self.observing_window = observing_window\n",
    "        self.pred_window = pred_window\n",
    "        self.H = H\n",
    "        self.max_length = max_length\n",
    "        self.max_length_diags = 30\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.device = device\n",
    "\n",
    "        # self.embedding = pretrained_model\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "\n",
    "        self.lstm_day = nn.LSTM(input_size=embedding_size,\n",
    "                            hidden_size=self.H,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.fc_day = nn.Linear(self.max_length * 2 * self.H, 2048)\n",
    "\n",
    "        self.fc_adm = nn.Linear(2048*self.observing_window +  self.max_length_diags * 2 * self.H, 2048)\n",
    "\n",
    "        self.lstm_adm = nn.LSTM(input_size=2048,\n",
    "                            hidden_size=self.H,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc_2 = nn.Linear(self.H*2, 1)\n",
    "\n",
    "    def forward(self, tensor_day, tensor_diagnoses):\n",
    "\n",
    "        batch_size = tensor_day.size()[0]\n",
    "\n",
    "        # full_output = torch.tensor([]).to(device=self.device)\n",
    "        out_emb_diags = self.embedding(tensor_diagnoses.squeeze(1))\n",
    "        out_lstm_diags, _ = self.lstm_day(out_emb_diags)\n",
    "        full_output = out_lstm_diags.reshape(batch_size, self.max_length_diags * 2 * self.H)\n",
    "        \n",
    "\n",
    "        for d in range(self.observing_window):\n",
    "            # embedding layer applied to all tensors [16,400,200]\n",
    "            out_emb = self.embedding(tensor_day[:, d, :].squeeze(1))\n",
    "            # print('out_emb', out_emb.size())\n",
    "\n",
    "            # lstm layer applied to embedded tensors\n",
    "            output_lstm_day= self.fc_day(\\\n",
    "                                    self.lstm_day(out_emb)[0]\\\n",
    "                                        .reshape(batch_size, self.max_length * 2 * self.H))\n",
    "\n",
    "            # print('output_lstm_day', output_lstm_day.size())                   \n",
    "            # concatenate for all * days\n",
    "            full_output = torch.cat([full_output, output_lstm_day], dim=1) # [16, 768]\n",
    "\n",
    "        # print('full_output size: ', full_output.size(), '\\n')\n",
    "        output = self.fc_adm (full_output)\n",
    "        # print('output after fc_adm size: ', output.size(), '\\n')\n",
    "        output, _ = self.lstm_adm(output)\n",
    "        # print('output after lstm_adm', output.size())\n",
    "        output = self.drop(output)\n",
    "        output = self.fc_2(output)\n",
    "        # print('output after fc_2', output.size())\n",
    "        output = torch.squeeze(output, 1)\n",
    "\n",
    "        # output = nn.Sigmoid()(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set shape:  (1755, 10)\n"
     ]
    }
   ],
   "source": [
    "# with open(DF_PATH + 'pid_test_df.pkl', 'rb') as f:\n",
    "#    pid_test_df = pickle.load(f)\n",
    "# print('test set shape: ', pid_test_df.shape)\n",
    "\n",
    "# with open(DF_PATH + 'pid_test_df_finetuning.pkl', 'rb') as f:\n",
    "#    pid_test_df = pickle.load(f)\n",
    "\n",
    "with open(DF_PATH + 'pid_test_df_finetuning_6days_aki.pkl', 'rb') as f:\n",
    "    pid_test_df = pickle.load(f)\n",
    "\n",
    "print('test set shape: ', pid_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "vocab_size = tokenizer.get_vocab_size() #+ 1\n",
    "embedding_size = 200\n",
    "dimension = 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "frac = 1\n",
    "train_dataset = MyDataset(pid_train_df.sample(frac=frac), tokenizer=tokenizer, max_length_day=400)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = MyDataset(pid_val_df.sample(frac=frac), tokenizer=tokenizer, max_length_day=400)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = MyDataset(pid_test_df.sample(frac=frac), tokenizer=tokenizer, max_length_day=400)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = LSTM_model(max_day=13).to(device)\n",
    "# test_model = LSTM_model(max_length=max_length, H=128, max_day=max_days, pred_window=pred_window, vocab_size=vocab_size).to(device)\n",
    "# optimizer = optim.Adam(test_model.parameters(), lr=0.00001)\n",
    "\n",
    "# load_checkpoint(file_path + '/model.pt', test_model, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_correct_preds(output, target, correct_preds):\n",
    "    # correct_preds - the list of size (number of samples) where 1 when predicted value \n",
    "    # is equal to target, othrwise 0.\n",
    "\n",
    "    # predicted = (output > threshold).int()\n",
    "    predicted = output\n",
    "    for i in range(target.size(0)):\n",
    "        true = target[i].cpu().numpy()\n",
    "        pred = predicted[i].cpu().numpy()\n",
    "\n",
    "        if any(target[i] == 1):\n",
    "            idx_of_one = np.where(true==1)[0][0]\n",
    "            if (pred[idx_of_one] == 1) & all(pred[:idx_of_one] == 0):\n",
    "                correct_preds.append(1)\n",
    "            else:\n",
    "                correct_preds.append(0)\n",
    "        \n",
    "        else:\n",
    "            if all(pred == 0):\n",
    "                correct_preds.append(1)\n",
    "            else:\n",
    "                correct_preds.append(0)        \n",
    "                       \n",
    "    return correct_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device, threshold=0.5, log_res=True):\n",
    "    model = model.to(device)\n",
    "    stacked_labels = torch.tensor([]).to(device)\n",
    "    stacked_preds = torch.tensor([]).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    step = 1\n",
    "    with torch.no_grad():\n",
    "        for tensor_day, tensor_diags, tensor_labels, idx in test_loader:\n",
    "            # print(f'Step {step}/{len(test_loader)}' )\n",
    "            labels = tensor_labels.to(device)\n",
    "            day_info = tensor_day.to(device)\n",
    "            tensor_diags = tensor_diags.to(device)\n",
    "\n",
    "            output = model(day_info, tensor_diags)\n",
    "            output = nn.Sigmoid()(output)\n",
    "            output = (output > threshold).int()\n",
    "\n",
    "            # stacking labels and predictions\n",
    "            stacked_labels = torch.cat([stacked_labels, labels], dim=0, )\n",
    "            stacked_preds = torch.cat([stacked_preds, output], dim=0, )\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    # calculate accuracy\n",
    "    acc = torch.round(torch.sum(stacked_labels==stacked_preds) / len(stacked_labels), decimals=2)\n",
    "    # transfer to device\n",
    "    stacked_labels = stacked_labels.cpu().detach().numpy()\n",
    "    stacked_preds = stacked_preds.cpu().detach().numpy()\n",
    "    # get classification metrics for all samples in the test set\n",
    "    classification_report_res = classification_report(stacked_labels, stacked_preds, zero_division=0, output_dict=True)\n",
    "    print(classification_report(stacked_labels, stacked_preds, zero_division=0, output_dict=False))\n",
    "    if log_res:\n",
    "        for k_day, v_day in classification_report_res.items():\n",
    "            if k_day is not 'accuracy':\n",
    "                for k, v in v_day.items():\n",
    "                    if k is not 'support':\n",
    "                        wandb.log({\"test_\" + k + k_day : v})\n",
    "                        # print(\"test_\" + k +'_'+ k_day, v)\n",
    "            else:\n",
    "                # print('accuracy', v_day)\n",
    "                wandb.log({\"test_\" + k_day: v_day})\n",
    "\n",
    "    return classification_report_res, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.01      0.02       146\n",
      "           1       0.19      0.12      0.15       193\n",
      "\n",
      "   micro avg       0.15      0.07      0.10       339\n",
      "   macro avg       0.12      0.07      0.08       339\n",
      "weighted avg       0.13      0.07      0.09       339\n",
      " samples avg       0.02      0.02      0.02       339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = evaluate(test_model, test_loader, device=device, threshold=0.3, log_res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', '4', '5', 'micro avg', 'macro avg', 'weighted avg', 'samples avg'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = {}\n",
    "for k_day, v_day in res[0].items():\n",
    "    if k_day is not 'epoch':\n",
    "        for k, v in v_day.items():\n",
    "            print(\"test_\" + k + \"_day_\" + k_day, v)\n",
    "            print(f'-------------------')\n",
    "    #     v_day.update({'day':k_day})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained model and compare against randomly initialized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== /l/users/svetlana.maslenkova/models/finetuning/embeddings/FT_PREemb_DIAGS_11k_lr1e-05_h128_pw2_ow3_wd0__drop0.4/model.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4763745665550232"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/l/users/svetlana.maslenkova/models/finetuning/embeddings/FT_PREemb_DIAGS_11k_lr1e-05_h128_pw2_ow3_wd0__drop0.4'\n",
    "test_model = EHR_MODEL(vocab_size=vocab_size, max_length=400, device=device, pred_window=2, observing_window=3).to(device)\n",
    "optimizer = optim.Adam(test_model.parameters(), lr=0.00001)\n",
    "load_checkpoint(file_path + '/model.pt', test_model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, f1_score, recall_score, precision_score, confusion_matrix\n",
    "import wandb\n",
    "\n",
    "def evaluate(model, test_loader, device, threshold=None, log_res=False):\n",
    "    model = model.to(device)\n",
    "    stacked_labels = torch.tensor([]).to(device)\n",
    "    stacked_probs = torch.tensor([]).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    step = 1\n",
    "    with torch.no_grad():\n",
    "        for tensor_day, tensor_diags, tensor_labels, idx in test_loader:\n",
    "            # print(f'Step {step}/{len(test_loader)}' )\n",
    "            labels = tensor_labels.to(device)\n",
    "            day_info = tensor_day.to(device)\n",
    "            tensor_diags = tensor_diags.to(device)\n",
    "\n",
    "            probs = test_model(day_info, tensor_diags)\n",
    "            probs = nn.Sigmoid()(probs)\n",
    "            # output = (probs > threshold).int()\n",
    "\n",
    "            # stacking labels and predictions\n",
    "            stacked_labels = torch.cat([stacked_labels, labels], dim=0, )\n",
    "            # stacked_preds = torch.cat([stacked_preds, output], dim=0, )\n",
    "            stacked_probs = torch.cat([stacked_probs, probs], dim=0, )\n",
    "            step += 1\n",
    "            \n",
    "    # transfer to device\n",
    "    if device=='cpu':\n",
    "        stacked_labels = stacked_labels.cpu().detach().numpy()\n",
    "        stacked_probs = stacked_probs.cpu().detach().numpy()\n",
    "\n",
    "    if threshold==None:\n",
    "        if stacked_labels.ndim > 1:\n",
    "            precision, recall, thresholds = precision_recall_curve(stacked_labels[:].sum(axis=1)>0, np.max(stacked_probs, axis=1))\n",
    "        else:\n",
    "            precision, recall, thresholds = precision_recall_curve(stacked_labels, stacked_probs)\n",
    "            \n",
    "        # convert to f score\n",
    "        fscore = (2 * precision * recall) / (precision + recall)\n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(np.nan_to_num(fscore))\n",
    "        threshold = np.round(thresholds[ix], 2)\n",
    "        print('Best Threshold=%.2f, F-Score=%.2f' % (threshold, fscore[ix]))\n",
    "\n",
    "    stacked_preds = (stacked_probs > threshold).astype(int)\n",
    "    if stacked_labels.ndim > 1:\n",
    "        y_true = (stacked_labels[:].sum(axis=1)>0) \n",
    "        y_pred = (stacked_preds[:].sum(axis=1)>0)\n",
    "    else:\n",
    "        y_true = stacked_labels\n",
    "        y_pred = stacked_preds\n",
    "\n",
    "    accuracy = np.round(accuracy_score(y_true, y_pred), 2)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    f1_score_ = np.round(f1_score(y_true, y_pred, pos_label=1, average='binary'), 2)\n",
    "    print(f'F1: ', f1_score_)\n",
    "\n",
    "    recall_score_ = np.round(recall_score(y_true, y_pred, pos_label=1, average='binary'), 2)\n",
    "    print(f'Recall: ', recall_score_)\n",
    "\n",
    "    precision_score_ = np.round(precision_score(y_true, y_pred, pos_label=1, average='binary'), 2)\n",
    "    print(f'Precision: ', precision_score_)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity =  np.round(tn / (tn + fp), 2)\n",
    "    print(f'Specificity: ', specificity)\n",
    "\n",
    "    print(f'Confusion matrix:\\n', confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    if log_res:\n",
    "        wandb.log({'test_accuracy':accuracy, 'test_f1_score':f1_score_, 'test_recall_score':recall_score_, 'test_precision_score':precision_score_, 'test_specificity':specificity})\n",
    "\n",
    "    # get classification metrics for all samples in the test set\n",
    "    classification_report_res = classification_report(stacked_labels, stacked_preds, zero_division=0, output_dict=True)\n",
    "    print(classification_report(stacked_labels, stacked_preds, zero_division=0, output_dict=False))\n",
    "    # if log_res:\n",
    "    #     for k_day, v_day in classification_report_res.items():\n",
    "    #         if k_day is not 'accuracy':\n",
    "    #             for k, v in v_day.items():\n",
    "    #                 if k is not 'support':\n",
    "    #                     wandb.log({\"test_\" + k + k_day : v})\n",
    "    #                     # print(\"test_\" + k +'_'+ k_day, v)\n",
    "    #         else:\n",
    "    #             # print('accuracy', v_day)\n",
    "    #             wandb.log({\"test_\" + k_day: v_day})\n",
    "\n",
    "    return {'accuracy':accuracy, 'f1_score':f1_score_, 'recall_score':recall_score_, 'precision_score':precision_score_, 'specificity':specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate(test_model, test_loader, device='cpu', log_res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "stacked_labels = torch.tensor([]).to(device)\n",
    "stacked_probs = torch.tensor([]).to(device)\n",
    "step = 1\n",
    "for tensor_day, tensor_diags, tensor_labels, idx in test_loader:\n",
    "    labels = tensor_labels.to(device)\n",
    "    day_info = tensor_day.to(device)\n",
    "    tensor_diags = tensor_diags.to(device)\n",
    "\n",
    "    probs = test_model(day_info, tensor_diags)\n",
    "    probs = nn.Sigmoid()(probs)\n",
    "\n",
    "    # stacking labels and predictions\n",
    "    stacked_labels = torch.cat([stacked_labels, labels], dim=0, )\n",
    "    stacked_probs = torch.cat([stacked_probs, probs], dim=0, )\n",
    "    step += 1\n",
    "    # if step > 9:break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_labels = stacked_labels.cpu().detach().numpy()\n",
    "# stacked_preds = stacked_preds.cpu().detach().numpy()\n",
    "stacked_probs = stacked_probs.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.17, F-Score=0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/svetlana.maslenkova/conda_envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(stacked_labels[:].sum(axis=1)>0, np.max(stacked_probs, axis=1), pos_label=1)\n",
    "# convert to f score\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(np.nan_to_num(fscore))\n",
    "threshold = np.round(thresholds[ix], 2)\n",
    "print('Best Threshold=%.2f, F-Score=%.2f' % (threshold, fscore[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(thresholds[ix], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "F1 is  0.55\n",
      "Recall is  0.85\n",
      "Precision is  0.41\n",
      "Specificity is  0.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "# threshold = 0.2\n",
    "stacked_preds = (stacked_probs > threshold).astype(int)\n",
    "y_true = (stacked_labels[:].sum(axis=1)>0) \n",
    "y_pred = (stacked_preds[:].sum(axis=1)>0)\n",
    "a = y_true  == y_pred\n",
    "accuracy = np.round(a.sum() / len(a) , 2)\n",
    "print(accuracy)\n",
    "print(np.round(accuracy_score(y_true, y_pred), 2))\n",
    "\n",
    "f1_score_ = np.round(f1_score(y_true, y_pred, pos_label=1, average='binary'), 2)\n",
    "print(f'F1 is ', f1_score_)\n",
    "\n",
    "recall_score_ = np.round(recall_score(y_true, y_pred, pos_label=1, average='binary'), 2)\n",
    "print(f'Recall is ', recall_score_)\n",
    "\n",
    "precision_score_ = np.round(precision_score(y_true, y_pred, pos_label=1, average='binary'), 2)\n",
    "print(f'Precision is ', precision_score_)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "specificity =  np.round(tn / (tn + fp), 2)\n",
    "print(f'Specificity is ', specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\n",
      "1755\n",
      "0.5470085470085471\n"
     ]
    }
   ],
   "source": [
    "# trained model\n",
    "a = (stacked_labels[:].sum(axis=1)>0) == (stacked_preds[:].sum(axis=1)>0)\n",
    "print(a.sum())\n",
    "print(len(a))\n",
    "print(a.sum() / len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.57      0.44       472\n",
      "           1       0.31      0.70      0.43       449\n",
      "\n",
      "   micro avg       0.33      0.63      0.44       921\n",
      "   macro avg       0.34      0.63      0.44       921\n",
      "weighted avg       0.34      0.63      0.44       921\n",
      " samples avg       0.19      0.22      0.20       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results for 24, 24h prediction\n",
    "print(classification_report(stacked_labels, stacked_preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.sum((stacked_labels.sum(axis=1)>0)==(stacked_preds.sum(axis=1)>0)) / len(stacked_labels), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.46      0.56      1106\n",
      "        True       0.43      0.69      0.53       649\n",
      "\n",
      "    accuracy                           0.55      1755\n",
      "   macro avg       0.57      0.58      0.55      1755\n",
      "weighted avg       0.61      0.55      0.55      1755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results for 48h prediction\n",
    "# 0.2\n",
    "print(classification_report(stacked_labels[:].sum(axis=1)>0, stacked_preds[:].sum(axis=1)>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[510, 596],\n",
       "       [199, 450]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(stacked_labels[:].sum(axis=1)>0, stacked_preds[:].sum(axis=1)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.190138, F-Score=0.549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(stacked_labels[:].sum(axis=1)>0, np.max(stacked_probs, axis=1))\n",
    "# convert to f score\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(np.nan_to_num(fscore))\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       ...,\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(stacked_probs > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Figure' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3422945/2596267371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtesty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mno_skill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mno_skill\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_skill\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'No Skill'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Figure' object has no attribute 'plot'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# plot the roc curve for the model\n",
    "testy = stacked_labels[:].sum(axis=1)>0\n",
    "no_skill = len(testy[testy==1]) / len(testy)\n",
    "pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(recall, precision, marker='.', label='Model')\n",
    "pyplot.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "pyplot.title('PR Curve')\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly initialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = EHR_MODEL(vocab_size=vocab_size, max_length=400, device=device, pred_window=2, observing_window=3).to(device)\n",
    "optimizer = optim.Adam(test_model.parameters(), lr=0.00001)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_197797/2608857918.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_197797/3111227782.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, test_loader, device, threshold, log_res)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstacked_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstacked_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/conda_envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    904\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/torch/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "result = evaluate(test_model, test_loader, device='cuda', log_res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_day, tensor_diags, tensor_labels, idx = next(iter(test_loader))\n",
    "output = test_model(day_info, tensor_diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_labels = torch.cat([tensor_labels, tensor_labels], dim=0, )\n",
    "stacked_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_labels.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135\n",
      "1755\n",
      "0.6467236467236467\n"
     ]
    }
   ],
   "source": [
    "# random model\n",
    "a = (stacked_labels[:].sum(axis=1)>0) == (stacked_preds[:].sum(axis=1)>0)\n",
    "print(a.sum())\n",
    "print(len(a))\n",
    "print(a.sum() / len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      1106\n",
      "        True       0.37      1.00      0.54       649\n",
      "\n",
      "    accuracy                           0.37      1755\n",
      "   macro avg       0.18      0.50      0.27      1755\n",
      "weighted avg       0.14      0.37      0.20      1755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(stacked_labels[:].sum(axis=1)>0, stacked_preds[:].sum(axis=1)>0, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_preds[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339.0\n",
      "172.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(stacked_labels))\n",
    "print(np.sum(stacked_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks ike the model puts zeroes all the time. Now we are going to check the train dataset to see how balanced it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(data_loader):\n",
    "    i = 0\n",
    "    for tensor_day, tensor_diags, tensor_labels, idx in data_loader:\n",
    "        if i == 0:\n",
    "            labels = np.array([]).reshape(0, tensor_labels.size(-1))\n",
    "        labels = np.vstack([labels, tensor_labels], )\n",
    "        i += 1\n",
    "    train_stacked_labels = labels.T\n",
    "    n_pos = np.sum(train_stacked_labels, axis=-1)\n",
    "    n_neg = train_stacked_labels.shape[-1] - n_pos\n",
    "    weights = np.round(n_neg / n_pos, 2)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 64 and the array at index 1 has size 27",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3422945/2260090772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtensor_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/torch/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 64 and the array at index 1 has size 27"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for tensor_day, tensor_diags, tensor_labels, idx in test_loader:\n",
    "    if i == 0:\n",
    "        labels = np.array([])\n",
    "    labels = np.hstack([labels, tensor_labels], ) if labels.size else tensor_labels\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1755,)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/svetlana.maslenkova/conda_envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "train_stacked_labels = (labels[:].sum(axis=1)>0).T\n",
    "n_pos = np.sum(train_stacked_labels, axis=-1)\n",
    "n_neg = train_stacked_labels.shape[-1] - n_pos\n",
    "weights = np.round(n_neg / n_pos, 2)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.32, 2.77, 2.02, 2.07, 2.46, 2.13, 2.07, 2.53, 2.02, 2.39, 1.91,\n",
       "       2.32, 2.46, 2.53, 2.19, 1.68, 2.53, 2.95, 2.19, 2.32, 2.02, 1.96,\n",
       "       2.25, 2.32, 2.32, 2.25, 1.96, 2.25, 2.39, 2.02, 2.53, 2.46, 3.05,\n",
       "       2.69, 2.02, 2.02, 2.46, 2.25, 1.77, 3.15, 1.86, 2.02, 2.95, 1.96,\n",
       "       2.02, 1.96, 2.32, 1.91, 2.61, 1.96, 1.77, 2.32, 2.69, 2.61, 2.61,\n",
       "       3.26, 3.05, 2.69, 1.81, 2.95, 1.72, 3.05, 2.13, 2.69])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_class_weights(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([]).reshape(0,2)\n",
    "for tensor_day, tensor_diags, tensor_labels, idx in train_loader:\n",
    "    labels = np.concatenate([labels, tensor_labels], axis=0, )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10624)\n",
      "The number of positive examples for the 1st day: 2084.0, for the 2nd day: 1984.0\n",
      "The total number of samples: 10624\n",
      "The ratio for the 1st day: 0.2, the 2nd day: 0.19\n"
     ]
    }
   ],
   "source": [
    "train_stacked_labels = labels.reshape(2, len(labels))\n",
    "print(train_stacked_labels.shape)\n",
    "print('The number of positive examples for the 1st day: {}, for the 2nd day: {}'.format(np.sum(train_stacked_labels, axis=1)[0], np.sum(train_stacked_labels, axis=1)[1]))\n",
    "print(f'The total number of samples: {len(labels)}')\n",
    "print('The ratio for the 1st day: {}, the 2nd day: {}'.format(np.round(np.sum(train_stacked_labels, axis=1)[0]/len(labels),2), np.round(np.sum(train_stacked_labels, axis=1)[1]/len(labels),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 135,\n",
       " 1: 71,\n",
       " 2: 40,\n",
       " 3: 39,\n",
       " 4: 32,\n",
       " 5: 22,\n",
       " 6: 16,\n",
       " 7: 8,\n",
       " 8: 10,\n",
       " 9: 12,\n",
       " 10: 8,\n",
       " 11: 7,\n",
       " 12: 6,\n",
       " 13: 3}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(np.where(stacked_labels==1)[1], return_counts=True)\n",
    "counts_aki_day = dict(zip(unique, counts))\n",
    "counts_aki_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 13, 2: 1, 4: 1, 5: 2, 6: 1, 8: 1, 9: 2}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(np.where(stacked_preds==1)[1], return_counts=True)\n",
    "counts_aki_day_preds = dict(zip(unique, counts))\n",
    "counts_aki_day_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ids = np.c_[np.where(stacked_preds==1)]\n",
    "labels_ids = np.c_[np.where(stacked_labels==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "409\n"
     ]
    }
   ],
   "source": [
    "print(len(preds_ids))\n",
    "print(len(labels_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.48      0.61       316\n",
      "           1       0.84      0.60      0.70       464\n",
      "           2       0.82      0.55      0.66       430\n",
      "           3       0.79      0.53      0.63       400\n",
      "           4       0.79      0.48      0.60       376\n",
      "           5       0.54      0.24      0.33       331\n",
      "\n",
      "   micro avg       0.79      0.49      0.61      2317\n",
      "   macro avg       0.77      0.48      0.59      2317\n",
      "weighted avg       0.78      0.49      0.60      2317\n",
      " samples avg       0.32      0.28      0.28      2317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(stacked_labels, stacked_preds, zero_division=0, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset is loaded from <=== /home/svetlana.maslenkova/LSTM/dataframes/train_df_pretraining.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>day_id</th>\n",
       "      <th>demographics</th>\n",
       "      <th>lab_tests</th>\n",
       "      <th>medications</th>\n",
       "      <th>vitals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1411116</th>\n",
       "      <td>10467237</td>\n",
       "      <td>20000019</td>\n",
       "      <td>0</td>\n",
       "      <td>HISPANIC/LATINO F 76.0</td>\n",
       "      <td>Hematology Blood hematocrit {26.5} %; Hematolo...</td>\n",
       "      <td>PNEUMOcoccal 23-valent polysaccharide vaccine ...</td>\n",
       "      <td>temp {98.0} heartrate {65.0} resprate {16.0} o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411117</th>\n",
       "      <td>10467237</td>\n",
       "      <td>20000019</td>\n",
       "      <td>1</td>\n",
       "      <td>HISPANIC/LATINO F 76.0</td>\n",
       "      <td>Hematology Blood hematocrit {28.1} %; Hematolo...</td>\n",
       "      <td>PNEUMOcoccal 23-valent polysaccharide vaccine ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411118</th>\n",
       "      <td>10467237</td>\n",
       "      <td>20000019</td>\n",
       "      <td>2</td>\n",
       "      <td>HISPANIC/LATINO F 76.0</td>\n",
       "      <td>Hematology Blood hematocrit {23.9} %; Hematolo...</td>\n",
       "      <td>PNEUMOcoccal 23-valent polysaccharide vaccine ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306556</th>\n",
       "      <td>16925328</td>\n",
       "      <td>20000024</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE F 92.0</td>\n",
       "      <td>Hematology Blood hematocrit {32.1} %; Hematolo...</td>\n",
       "      <td>OxyCODONE (Immediate Release) {2.5} mg ; Gabap...</td>\n",
       "      <td>temp {98.2} heartrate {53.0} resprate {18.0} o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306557</th>\n",
       "      <td>16925328</td>\n",
       "      <td>20000024</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE F 92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sodium Chloride 0.9%  Flush {3} mL ; Heparin {...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id   hadm_id  day_id            demographics  \\\n",
       "1411116    10467237  20000019       0  HISPANIC/LATINO F 76.0   \n",
       "1411117    10467237  20000019       1  HISPANIC/LATINO F 76.0   \n",
       "1411118    10467237  20000019       2  HISPANIC/LATINO F 76.0   \n",
       "306556     16925328  20000024       0            WHITE F 92.0   \n",
       "306557     16925328  20000024       1            WHITE F 92.0   \n",
       "\n",
       "                                                 lab_tests  \\\n",
       "1411116  Hematology Blood hematocrit {26.5} %; Hematolo...   \n",
       "1411117  Hematology Blood hematocrit {28.1} %; Hematolo...   \n",
       "1411118  Hematology Blood hematocrit {23.9} %; Hematolo...   \n",
       "306556   Hematology Blood hematocrit {32.1} %; Hematolo...   \n",
       "306557                                                 NaN   \n",
       "\n",
       "                                               medications  \\\n",
       "1411116  PNEUMOcoccal 23-valent polysaccharide vaccine ...   \n",
       "1411117  PNEUMOcoccal 23-valent polysaccharide vaccine ...   \n",
       "1411118  PNEUMOcoccal 23-valent polysaccharide vaccine ...   \n",
       "306556   OxyCODONE (Immediate Release) {2.5} mg ; Gabap...   \n",
       "306557   Sodium Chloride 0.9%  Flush {3} mL ; Heparin {...   \n",
       "\n",
       "                                                    vitals  \n",
       "1411116  temp {98.0} heartrate {65.0} resprate {16.0} o...  \n",
       "1411117                                                NaN  \n",
       "1411118                                                NaN  \n",
       "306556   temp {98.2} heartrate {53.0} resprate {18.0} o...  \n",
       "306557                                                 NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DF_PATH + 'train_df_pretraining.pkl', 'rb') as f:\n",
    "    pid_train_df = pickle.load(f)\n",
    "print(f'Train dataset is loaded from <=== {DF_PATH}train_df_pretraining.pkl')\n",
    "pid_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset is loaded from <=== /home/svetlana.maslenkova/LSTM/dataframes/pid_train_df_finetuning.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>demographics_in_visit</th>\n",
       "      <th>lab_tests_in_visit</th>\n",
       "      <th>medications_in_visit</th>\n",
       "      <th>vitals_in_visit</th>\n",
       "      <th>days_in_visit</th>\n",
       "      <th>aki_status_in_visit</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16679562</td>\n",
       "      <td>20001395</td>\n",
       "      <td>[HISPANIC/LATINO M 73.0, HISPANIC/LATINO M 73....</td>\n",
       "      <td>[Hematology Blood hematocrit {51.2} %; Hematol...</td>\n",
       "      <td>[Influenza Vaccine Quadrivalent {0.5} mL ; Bis...</td>\n",
       "      <td>[temp {} heartrate {80.0} resprate {16.0} o2sa...</td>\n",
       "      <td>[HISPANIC/LATINO M 73.0$temp {} heartrate {80....</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10189736</td>\n",
       "      <td>20001789</td>\n",
       "      <td>[WHITE M 71.0, WHITE M 71.0, WHITE M 71.0, WHI...</td>\n",
       "      <td>[Hematology Blood hematocrit {29.4} %; Hematol...</td>\n",
       "      <td>[PNEUMOcoccal 23-valent polysaccharide vaccine...</td>\n",
       "      <td>[temp {98.7} heartrate {66.0} resprate {18.0} ...</td>\n",
       "      <td>[WHITE M 71.0$temp {98.7} heartrate {66.0} res...</td>\n",
       "      <td>[0, 0, 0, 0, nan]</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13390157</td>\n",
       "      <td>20002497</td>\n",
       "      <td>[HISPANIC/LATINO M 44.0, HISPANIC/LATINO M 44....</td>\n",
       "      <td>[nan, Hematology Blood hematocrit {41.4} %; He...</td>\n",
       "      <td>[Metoprolol Succinate XL {100} mg ; , Bag {1} ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[HISPANIC/LATINO M 44.0$nan$nan$Metoprolol Suc...</td>\n",
       "      <td>[nan, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, nan]</td>\n",
       "      <td>[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10995547</td>\n",
       "      <td>20003740</td>\n",
       "      <td>[WHITE M 69.0, WHITE M 69.0, WHITE M 69.0, WHI...</td>\n",
       "      <td>[nan, Hematology Blood hematocrit {30.9} %; He...</td>\n",
       "      <td>[Lansoprazole Oral Disintegrating Tab {30} mg ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[WHITE M 69.0$nan$nan$Lansoprazole Oral Disint...</td>\n",
       "      <td>[nan, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0...</td>\n",
       "      <td>[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19657904</td>\n",
       "      <td>20004357</td>\n",
       "      <td>[BLACK/AFRICAN AMERICAN F 77.0, BLACK/AFRICAN ...</td>\n",
       "      <td>[nan, Hematology Blood hematocrit {28.7} %; He...</td>\n",
       "      <td>[Aspirin {325} mg ; Amlodipine {5} mg ; Isosor...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan]</td>\n",
       "      <td>[BLACK/AFRICAN AMERICAN F 77.0$nan$nan$Aspirin...</td>\n",
       "      <td>[nan, 0, 0, 1, 1, 0, nan, 0, nan]</td>\n",
       "      <td>[-1, 0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id   hadm_id                              demographics_in_visit  \\\n",
       "3     16679562  20001395  [HISPANIC/LATINO M 73.0, HISPANIC/LATINO M 73....   \n",
       "5     10189736  20001789  [WHITE M 71.0, WHITE M 71.0, WHITE M 71.0, WHI...   \n",
       "9     13390157  20002497  [HISPANIC/LATINO M 44.0, HISPANIC/LATINO M 44....   \n",
       "10    10995547  20003740  [WHITE M 69.0, WHITE M 69.0, WHITE M 69.0, WHI...   \n",
       "11    19657904  20004357  [BLACK/AFRICAN AMERICAN F 77.0, BLACK/AFRICAN ...   \n",
       "\n",
       "                                   lab_tests_in_visit  \\\n",
       "3   [Hematology Blood hematocrit {51.2} %; Hematol...   \n",
       "5   [Hematology Blood hematocrit {29.4} %; Hematol...   \n",
       "9   [nan, Hematology Blood hematocrit {41.4} %; He...   \n",
       "10  [nan, Hematology Blood hematocrit {30.9} %; He...   \n",
       "11  [nan, Hematology Blood hematocrit {28.7} %; He...   \n",
       "\n",
       "                                 medications_in_visit  \\\n",
       "3   [Influenza Vaccine Quadrivalent {0.5} mL ; Bis...   \n",
       "5   [PNEUMOcoccal 23-valent polysaccharide vaccine...   \n",
       "9   [Metoprolol Succinate XL {100} mg ; , Bag {1} ...   \n",
       "10  [Lansoprazole Oral Disintegrating Tab {30} mg ...   \n",
       "11  [Aspirin {325} mg ; Amlodipine {5} mg ; Isosor...   \n",
       "\n",
       "                                      vitals_in_visit  \\\n",
       "3   [temp {} heartrate {80.0} resprate {16.0} o2sa...   \n",
       "5   [temp {98.7} heartrate {66.0} resprate {18.0} ...   \n",
       "9   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "10  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "11      [nan, nan, nan, nan, nan, nan, nan, nan, nan]   \n",
       "\n",
       "                                        days_in_visit  \\\n",
       "3   [HISPANIC/LATINO M 73.0$temp {} heartrate {80....   \n",
       "5   [WHITE M 71.0$temp {98.7} heartrate {66.0} res...   \n",
       "9   [HISPANIC/LATINO M 44.0$nan$nan$Metoprolol Suc...   \n",
       "10  [WHITE M 69.0$nan$nan$Lansoprazole Oral Disint...   \n",
       "11  [BLACK/AFRICAN AMERICAN F 77.0$nan$nan$Aspirin...   \n",
       "\n",
       "                                  aki_status_in_visit  \\\n",
       "3                         [0, 0, 0, 1, 1, 0, 0, 1, 0]   \n",
       "5                                   [0, 0, 0, 0, nan]   \n",
       "9         [nan, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, nan]   \n",
       "10  [nan, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0...   \n",
       "11                  [nan, 0, 0, 1, 1, 0, nan, 0, nan]   \n",
       "\n",
       "                                                 days  \n",
       "3                         [0, 1, 2, 3, 4, 5, 6, 7, 8]  \n",
       "5                                     [0, 1, 2, 3, 4]  \n",
       "9          [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]  \n",
       "10  [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,...  \n",
       "11                       [-1, 0, 1, 2, 3, 4, 5, 6, 7]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/svetlana.maslenkova/LSTM/dataframes/pid_train_df_finetuning.pkl', 'rb') as f:\n",
    "    pid_train_df_finetuning = pickle.load(f)\n",
    "print(f'Train dataset is loaded from <=== {DF_PATH}pid_train_df_finetuning.pkl')\n",
    "pid_train_df_finetuning.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EHR_PRETRAINING(nn.Module):\n",
    "    def __init__(self, max_length, vocab_size, device, pred_window=2, observing_window=3,  H=128, embedding_size=200, drop=0.6):\n",
    "        super(EHR_PRETRAINING, self).__init__()\n",
    "\n",
    "        self.observing_window = observing_window\n",
    "        self.pred_window = pred_window\n",
    "        self.H = H\n",
    "        self.max_length = max_length\n",
    "        self.max_length_diags = 30\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.device = device\n",
    "        self.drop = drop\n",
    "\n",
    "        # self.embedding = pretrained_model\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "\n",
    "        self.lstm_day = nn.LSTM(input_size=embedding_size,\n",
    "                            hidden_size=self.H,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.fc_day = nn.Linear(self.max_length * 2 * self.H, 2048)\n",
    "\n",
    "        self.fc_adm = nn.Linear(2048*self.observing_window +  self.max_length_diags * 2 * self.H, 2048)\n",
    "\n",
    "        self.lstm_adm = nn.LSTM(input_size=2048,\n",
    "                            hidden_size=self.H,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.drop = nn.Dropout(p=drop)\n",
    "\n",
    "        # self.fc_2 = nn.Linear(self.H*2, 2)\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=self.H*2, out_features=256)\n",
    "        )\n",
    "\n",
    "    def forward(self, tensor_day, tensor_diagnoses):\n",
    "\n",
    "        batch_size = tensor_day.size()[0]\n",
    "\n",
    "        # full_output = torch.tensor([]).to(device=self.device)\n",
    "        out_emb_diags = self.embedding(tensor_diagnoses.squeeze(1))\n",
    "        out_lstm_diags, _ = self.lstm_day(out_emb_diags)\n",
    "        full_output = out_lstm_diags.reshape(batch_size, self.max_length_diags * 2 * self.H)\n",
    "        \n",
    "\n",
    "        for d in range(self.observing_window):\n",
    "            # embedding layer applied to all tensors [16,400,200]\n",
    "            out_emb = self.embedding(tensor_day[:, d, :].squeeze(1))\n",
    "            # print('out_emb', out_emb.size())\n",
    "\n",
    "            # lstm layer applied to embedded tensors\n",
    "            output_lstm_day= self.drop(self.fc_day(\\\n",
    "                                    self.lstm_day(out_emb)[0]\\\n",
    "                                        .reshape(batch_size, self.max_length * 2 * self.H)))\n",
    "\n",
    "            # print('output_lstm_day', output_lstm_day.size())                   \n",
    "            # concatenate for all * days\n",
    "            full_output = torch.cat([full_output, output_lstm_day], dim=1) # [16, 768]\n",
    "\n",
    "        # print('full_output size: ', full_output.size(), '\\n')\n",
    "        output = self.fc_adm(full_output)\n",
    "        # print('output after fc_adm size: ', output.size(), '\\n')\n",
    "        output_vector, _ = self.lstm_adm(output)\n",
    "        \n",
    "        # the fisrt transformation\n",
    "        output_vector_X = self.drop(output_vector)\n",
    "        projection_X = self.projection(output_vector_X)\n",
    "        # the second transformation\n",
    "        output_vector_Y = self.drop(output_vector)\n",
    "        projection_Y = self.projection(output_vector_Y)\n",
    "\n",
    "        return output_vector_X, projection_X, output_vector_Y, projection_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EHR_PRETRAINING(max_length=400, vocab_size=vocab_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vector_X, projection_X, output_vector_Y, projection_Y = model(tensor_day, tensor_diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0077, -0.0525, -0.0229,  ..., -0.0229, -0.0504, -0.0723],\n",
       "        [-0.0111, -0.0547,  0.0023,  ..., -0.0253, -0.0226, -0.0172],\n",
       "        [-0.0487, -0.0492,  0.0155,  ..., -0.0660, -0.0363, -0.0215],\n",
       "        ...,\n",
       "        [ 0.0125, -0.0496, -0.0211,  ...,  0.0148, -0.0285, -0.0610],\n",
       "        [ 0.0076, -0.0459, -0.0400,  ..., -0.0580, -0.0201, -0.0605],\n",
       "        [ 0.0199, -0.0673, -0.0606,  ..., -0.0248, -0.0150, -0.0662]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_Y"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f41d6bb73514239eeae9d84db1aabfbecf43feae35a358a827a9ce792198f6fa"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
