{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURR_PATH = os.getcwd()\n",
    "CURR_PATH = '/home/svetlanamaslenkova/Documents/AKI_deep/LSTM'\n",
    "DATA_PATH = '/home/svetlanamaslenkova/Documents/data/physionet.org/files/mimiciv/2.0/'\n",
    "DF_PATH = CURR_PATH +'/dataframes_2/'\n",
    "PKL_PATH = CURR_PATH+'/pickles_2/'\n",
    "DF_PATH = CURR_PATH+'/dataframes_2/'\n",
    "ICU_PATH = DATA_PATH + 'icu/'\n",
    "HOSP_PATH = DATA_PATH + 'hosp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MIMIC IV tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hosp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_patients = pd.read_csv(HOSP_PATH+'patients.csv')\n",
    "\n",
    "data_patients.columns = data_patients.columns.str.lower()\n",
    "\n",
    "data_patients.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_admissions = pd.read_csv(HOSP_PATH+'admissions.csv')\n",
    "\n",
    "data_admissions.columns = data_admissions.columns.str.lower()\n",
    "\n",
    "data_admissions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_admissions['hadm_id'] = data_admissions['hadm_id'].astype(int)\n",
    "# change charttime column to datettime type\n",
    "format_ = '%Y-%m-%d %H:%M:%S'\n",
    "# data_vitals['charttime'] = pd.to_datetime(data_vitals['charttime'], format=format_)\n",
    "data_admissions['admittime'] = pd.to_datetime(data_admissions['admittime'], format=format_)\n",
    "data_admissions['dischtime'] = pd.to_datetime(data_admissions['dischtime'], format=format_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_admissions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "omr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_omr = pd.read_csv(HOSP_PATH+'omr.csv')\n",
    "data_omr.columns = data_omr.columns.str.lower()\n",
    "format_ = '%Y-%m-%d %H:%M:%S'\n",
    "data_omr['chartdate'] = pd.to_datetime(data_omr['chartdate'], format=format_)\n",
    "print(data_omr.shape)\n",
    "data_omr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_omr.result_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_data = data_omr[data_omr.result_name.isin(['Weight', 'Weight (Lbs)'])]\n",
    "weight_data['result_value'] = weight_data['result_value'].astype(float)\n",
    "\n",
    "weight_data['weight_kg'] = [np.round(v * 0.45359237) for v in weight_data.loc[:, 'result_value']]\n",
    "weight_data = data_icustays[['subject_id']].merge(weight_data[['subject_id', 'chartdate', 'weight_kg']]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers (incorectly documented weight) \n",
    "weight_data = weight_data[~(weight_data.weight_kg>300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most recent to icu stay weight of patients \n",
    "weight_data_icu = data_icustays[['subject_id', 'hadm_id',\t'stay_id', 'intime', 'outtime']]\\\n",
    "                        .merge(weight_data, on='subject_id')\n",
    "\n",
    "weight_data_icu_prev = weight_data_icu[(weight_data_icu.chartdate > weight_data_icu.intime - pd.Timedelta(360, 'd'))&(weight_data_icu.chartdate < weight_data_icu.outtime)]\\\n",
    "                                    .sort_values(['subject_id', 'intime', 'chartdate'], ascending=False)\\\n",
    "                                        .drop_duplicates('stay_id', keep='first')\n",
    "print(weight_data_icu_prev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weight up to 180 days after outtime \n",
    "weight_data_icu_future = weight_data_icu[(weight_data_icu.chartdate >= weight_data_icu.intime)&(weight_data_icu.chartdate < weight_data_icu.outtime + pd.Timedelta(180, 'd'))]\\\n",
    "                                .sort_values(['subject_id', 'intime', 'chartdate'], ascending=False)\\\n",
    "                                    .drop_duplicates('stay_id', keep='last')\n",
    "print(weight_data_icu_future.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to dataframes and fillna in weight_data_icu_prev with values from future \n",
    "weight_data_icu = weight_data_icu_prev.merge(weight_data_icu_future.rename(columns={'stay_id':'stay_id_f', 'chartdate':'chartdate_f', 'weight_kg':'weight_kg_f'}).drop(columns=['intime', 'outtime']), how='outer')\n",
    "weight_data_icu['weight_kg'] = weight_data_icu['weight_kg'].fillna(weight_data_icu['weight_kg_f'])\n",
    "weight_data_icu['chartdate'] = weight_data_icu['chartdate'].fillna(weight_data_icu['chartdate_f'])\n",
    "weight_data_icu['stay_id'] = weight_data_icu['stay_id'].fillna(weight_data_icu['stay_id_f'])\n",
    "weight_data_icu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weight_data_icu.hadm_id.unique().shape[0])\n",
    "weight_data_icu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'weight_data_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(weight_data_icu, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'weight_data_icu.pkl', 'rb') as f:\n",
    "    weight_data_icu = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_icd_diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_d_icd_diagnoses = pd.read_csv(HOSP_PATH+'d_icd_diagnoses.csv')\n",
    "\n",
    "data_d_icd_diagnoses.columns = data_d_icd_diagnoses.columns.str.lower()\n",
    "\n",
    "data_d_icd_diagnoses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diagnoses_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_diagnoses = pd.read_csv(HOSP_PATH+'diagnoses_icd.csv')\n",
    "\n",
    "data_diagnoses.columns = data_diagnoses.columns.str.lower()\n",
    "\n",
    "data_diagnoses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_labitems = pd.read_csv(HOSP_PATH+'d_labitems.csv')\n",
    "\n",
    "data_labitems.columns = data_labitems.columns.str.lower()\n",
    "data_labitems.label = data_labitems.label.str.lower()\n",
    "labitems = data_labitems.copy()\n",
    "data_labitems.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take item ids of all needed features\n",
    "creatinine_id = labitems[labitems.label.str.contains('creatinine').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "creatinine_serum_id = labitems[labitems.label.str.contains('creatinine, serum').fillna(False)].itemid.to_list()\n",
    "urine_volume_id = labitems[labitems.label.str.contains('urine volume').fillna(False)].itemid.to_list()\n",
    "anion_gap_id = labitems[labitems.label.str.contains('anion').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "albumin_id = labitems[labitems.label.str.contains('albumin').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "bands_id = labitems[labitems.label.str.contains('bands').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "bilirubin_id = labitems[labitems.label.str.contains('bilirubin').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "hematocrit_id = labitems[labitems.label.str.contains('hematocrit').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "lactate_id = labitems[labitems.label.str.contains('lactate').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "sodium_id = labitems[labitems.label.str.contains('sodium').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "bicarbonate_id = labitems[labitems.label.str.contains('bicarbonate').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "bun_id = labitems[labitems.label.str.contains('nitrogen').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "calcium_id = labitems[labitems.label.str.contains('calcium').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "chloride_id = labitems[labitems.label.str.contains('chloride').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "hemoglobin_id = list(set(labitems[labitems.label.str.contains('hemoglobin').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()) - set(['51212']))\n",
    "inr_id = labitems[labitems.label.str.contains('inr').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "platelet_id = labitems[labitems.label.str.contains('platelet').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "potassium_id = labitems[labitems.label.str.contains('potassium').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "pt_id = ['51274', '52921', '52163', '52164']\n",
    "ppt_id = ['51275', '52923', '52165', '52166', '52166', '52167']\n",
    "wbc_id = labitems[labitems.label.str.contains('wbc').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()\n",
    "glucose_id = labitems[labitems.label.str.contains('glucose').fillna(False) & labitems.fluid.isin(['Blood', 'Urine'])].itemid.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_itemids = [*creatinine_id, *creatinine_serum_id, *urine_volume_id, *anion_gap_id, *albumin_id, *bands_id, *bilirubin_id, *hematocrit_id, *lactate_id,\\\n",
    "    *sodium_id, *bicarbonate_id, *bun_id, *calcium_id, *chloride_id, *hemoglobin_id, *inr_id, *platelet_id, *potassium_id, *pt_id, *ppt_id, *wbc_id, *glucose_id]\n",
    "# all needed itemids    \n",
    "len(set(lab_itemids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load labevents table by chunks (since it is very heavy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "my_chunk = 1000000\n",
    "\n",
    "# create the iterator\n",
    "iter_csv = pd.read_csv(HOSP_PATH+'labevents.csv', \n",
    "        header=0, usecols=['subject_id', 'hadm_id', 'specimen_id', 'itemid','flag', 'charttime', 'valuenum', 'valueuom'],\n",
    "                            dtype={'subject_id':'uint32', 'flag':'str', 'valueuom':'category'},\n",
    "                       engine='c', keep_default_na=False,  skip_blank_lines=True, low_memory=False, iterator=True, chunksize=my_chunk)\n",
    "\n",
    "# concatenate according to a filter to our result dataframe\n",
    "df_result_lab = pd.concat(\n",
    "    [chunk[chunk.itemid.isin(lab_itemids)] \n",
    "    for chunk in iter_csv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents = df_result_lab.copy()\n",
    "labevents = labevents.merge(data_labitems[['itemid', 'label', 'fluid', 'category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents['hadm_id'] = pd.to_numeric(labevents['hadm_id'], errors='coerce')\n",
    "labevents['hadm_id'] = labevents['hadm_id'].fillna(0).astype(int)\n",
    "\n",
    "# change charttime column to datettime type\n",
    "format_ = '%Y-%m-%d %H:%M:%S'\n",
    "labevents['charttime'] = pd.to_datetime(labevents['charttime'], format=format_)\n",
    "\n",
    "# removing duplicated rows and rows with no valuenum\n",
    "labevents = labevents.drop_duplicates()\n",
    "labevents = labevents[~labevents.valuenum.isna()]\n",
    "\n",
    "labevents = labevents[~labevents['valuenum'].str.contains(\"[a-zA-Z]+$\")]\n",
    "labevents['valuenum'] = pd.to_numeric(labevents['valuenum'], errors='coerce')\n",
    "labevents = labevents.dropna(subset=['valuenum'])\n",
    "\n",
    "labevents.flag = labevents.flag.astype(str)\n",
    "\n",
    "labevents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents = labevents.merge(data_admissions[['subject_id',\t'hadm_id', 'admittime', 'dischtime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'labevents.pkl', 'wb') as f:\n",
    "    pickle.dump(labevents, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'labevents.pkl', 'rb') as f:\n",
    "    labevents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labevents table with createnine test results only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creatinine_blood_id = [50912, 52546]\n",
    "labevents_creatinine = labevents[labevents.itemid.isin(creatinine_blood_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents_creatinine['day_id'] = labevents_creatinine['charttime'] - labevents_creatinine['admittime']\n",
    "labevents_creatinine['day_id'] = [d.days for d in labevents_creatinine.loc[:, 'day_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents_creatinine['_12h_window_id'] = labevents_creatinine['charttime'] - labevents_creatinine['admittime']\n",
    "labevents_creatinine['_12h_window_id'] = [(d.days*24 + d.seconds//3600)//12 for d in labevents_creatinine.loc[:, '_12h_window_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents_creatinine['hour_id'] = labevents_creatinine['charttime'] - labevents_creatinine['admittime']\n",
    "labevents_creatinine['hour_id'] = [(d.days*24 + d.seconds//3600) for d in labevents_creatinine.loc[:, 'hour_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents_creatinine.sort_values(['hadm_id', 'charttime']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'labevents_creatinine.pkl', 'wb') as f:\n",
    "    pickle.dump(labevents_creatinine, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'labevents_creatinine.pkl', 'rb') as f:\n",
    "    labevents_creatinine = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_prescriptions = pd.read_csv(HOSP_PATH+'prescriptions.csv')\n",
    "\n",
    "data_prescriptions.columns = data_prescriptions.columns.str.lower()\n",
    "\n",
    "# data_prescriptions['ndc'] = data_prescriptions['ndc'].astype('uint64')\n",
    "\n",
    "data_prescriptions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_d_items = pd.read_csv(ICU_PATH + 'd_items.csv')\n",
    "\n",
    "data_d_items.columns = data_d_items.columns.str.lower()\n",
    "\n",
    "data_d_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load chartevents table in chunks (since it is very heavy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "\n",
    "my_chunk = 1000000\n",
    "\n",
    "# create the iterator\n",
    "iter_csv = pd.read_csv(ICU_PATH + 'chartevents.csv', header=0, usecols=['subject_id', 'hadm_id', 'stay_id', 'charttime', 'itemid', 'value', 'valuenum', 'valueuom'], \\\n",
    "                        dtype={'subject_id':'uint32', 'hadm_id':'uint32', 'stay_id':'uint32', 'valueuom':'category'},\\\n",
    "                            engine='c', keep_default_na=False, skip_blank_lines=True, low_memory=False, iterator=True, chunksize=my_chunk )              \n",
    "\n",
    "# concatenate according to a filter to our result dataframe\n",
    "df_result = pd.concat(\\\n",
    "    [chunk for chunk in iter_csv])\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_chartevents = df_result.copy()\n",
    "# data_chartevents.columns = data_chartevents.columns.str.lower()\n",
    "# format_ = '%Y-%m-%d %H:%M:%S'\n",
    "# data_chartevents['charttime'] = pd.to_datetime(data_chartevents['charttime'], format=format_)\n",
    "data_chartevents['valuenum'] = data_chartevents['valuenum'].replace(r'[a-zA-Z]', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# data_chartevents = data_chartevents.merge(data_d_items[['itemid', 'label', 'abbreviation', 'category', 'unitname', 'param_type']])\n",
    "print('unique stays: ', data_chartevents.stay_id.unique().shape)\n",
    "data_chartevents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chartevents.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chart_items = data_chartevents.drop_duplicates('itemid', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print items\n",
    "print('itemid | label | category | valuenum')\n",
    "for _, row in  unique_chart_items.sort_values('category').iterrows():\n",
    "    print(row.itemid, '|', row.label, '|', row.category, '|', row.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in data_d_items[data_d_items.category=='Routine Vital Signs'].iterrows():\n",
    "    print(row.itemid, '|', row.label, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_itemids = data_d_items[data_d_items.category=='Labs'].itemid.unique()\n",
    "labs_itemids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs = data_chartevents[data_chartevents.itemid.isin(labs_itemids)]\n",
    "chartevents_labs = chartevents_labs.merge(data_d_items[['itemid', 'label', 'abbreviation', 'category', 'unitname', 'param_type']])\n",
    "chartevents_labs['valuenum'] = chartevents_labs['valuenum'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_labs.pkl', 'wb') as f:\n",
    "    pickle.dump(chartevents_labs, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creatinine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in data_d_items[data_d_items.category=='Labs'].iterrows():\n",
    "    print(row.itemid, '|', row.label, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemid_scr = 220615\n",
    "chartevents_creatinine = chartevents_labs[chartevents_labs.itemid==itemid_scr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_creatinine.pkl', 'wb') as f:\n",
    "    pickle.dump(chartevents_creatinine, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_creatinine.pkl', 'rb') as f:\n",
    "    chartevents_creatinine = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_datetimeevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_datetimeevents = pd.read_csv(ICU_PATH + 'datetimeevents.csv')\n",
    "\n",
    "data_datetimeevents.columns = data_datetimeevents.columns.str.lower()\n",
    "\n",
    "data_datetimeevents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "icustays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_icustays = pd.read_csv(ICU_PATH + 'icustays.csv')\n",
    "\n",
    "data_icustays.columns = data_icustays.columns.str.lower()\n",
    "\n",
    "data_icustays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays['hadm_id'] = data_icustays['hadm_id'].astype(int)\n",
    "# change charttime column to datettime type\n",
    "format_ = '%Y-%m-%d %H:%M:%S'\n",
    "data_icustays['intime'] = pd.to_datetime(data_icustays['intime'], format=format_)\n",
    "data_icustays['outtime'] = pd.to_datetime(data_icustays['outtime'], format=format_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n of unique patients: ', (data_icustays.subject_id.unique().shape[0]))\n",
    "print('n of unique admissions: ', (data_icustays.hadm_id.unique().shape[0]))\n",
    "print('n of unique ICU stays: : ', (data_icustays.stay_id.unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = data_icustays.merge(data_admissions[['subject_id', 'hadm_id', 'admittime']], how='left')\n",
    "S['day_id'] = S['intime'] - S['admittime']\n",
    "S['day_id'] = [d.days for d in S.loc[:, 'day_id']]\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out icu stays with less than 2 days \n",
    "data_icustays = data_icustays[data_icustays.los>=2].sort_values(['subject_id', 'hadm_id', 'stay_id'])\n",
    "print(data_icustays.shape)\n",
    "data_icustays.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "\n",
    "data_inputevents = pd.read_csv(ICU_PATH + 'inputevents.csv')\n",
    "\n",
    "data_inputevents.columns = data_inputevents.columns.str.lower()\n",
    "\n",
    "data_inputevents.head().iloc[:, :14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputevents = data_inputevents.merge(data_icustays[['stay_id', 'intime']], on='stay_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('itemid','|', 'label','|', 'abbreviation','|', 'category')\n",
    "for _,row in data_d_items[data_d_items.linksto=='inputevents'].iterrows():\n",
    "    print(row.itemid,'|', row.label,'|', row.abbreviation,'|', row.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputevents = data_inputevents.merge(data_d_items[['itemid', 'label', 'abbreviation', 'category']], on='itemid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change charttime column to datettime type\n",
    "format_ = '%Y-%m-%d %H:%M:%S'\n",
    "data_inputevents['starttime'] = pd.to_datetime(data_inputevents['starttime'], format=format_)\n",
    "data_inputevents['endtime'] = pd.to_datetime(data_inputevents['endtime'], format=format_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingridients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_ingredientevents = pd.read_csv(ICU_PATH + 'ingredientevents.csv')\n",
    "\n",
    "data_ingredientevents.columns = data_ingredientevents.columns.str.lower()\n",
    "\n",
    "data_ingredientevents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingredientevents.merge(data_d_items[['itemid', 'label',\t'abbreviation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputevents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load outputevents in chuncks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "\n",
    "data_outputevents = pd.read_csv(ICU_PATH + 'outputevents.csv')\n",
    "\n",
    "data_outputevents = data_outputevents.merge(data_d_items, on='itemid')\n",
    "\n",
    "data_outputevents.columns = data_outputevents.columns.str.lower()\n",
    "data_outputevents['hadm_id'] = data_outputevents['hadm_id'].astype(int)\n",
    "# change charttime column to datettime type\n",
    "format_ = '%Y-%m-%d %H:%M:%S'\n",
    "data_outputevents['charttime'] = pd.to_datetime(data_outputevents['charttime'], format=format_)\n",
    "\n",
    "data_outputevents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('itemid | label | abbreviation | category')\n",
    "for _, row in data_outputevents.drop_duplicates('itemid').iterrows():\n",
    "    print(f'{row.itemid} | {row.label} |  {row.abbreviation} | {row.category}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outputevents = data_outputevents.merge(data_icustays[['subject_id',\t'hadm_id', 'stay_id', 'intime']])\\\n",
    "                                        .merge(data_admissions[['subject_id',\t'hadm_id', 'admittime']])\\\n",
    "                                            .sort_values(['subject_id','hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge labevents with icu_stays to get icu stay column\n",
    "O = data_outputevents.merge(data_icustays[['subject_id', 'hadm_id',\t'stay_id', 'intime', 'outtime']])\\\n",
    "                        .merge(data_admissions[['subject_id',\t'hadm_id', 'admittime']])\\\n",
    "                            .sort_values(['subject_id', 'hadm_id', 'charttime'])\n",
    "\n",
    "# # remove wrong rows with inconsistency between intime, outtime and charttime\n",
    "# O = O[(O.charttime > O.intime)&(O.charttime < O.outtime)]\n",
    "# # get day ids for starting from admittime and intime\n",
    "# O['day_id'] = O['charttime'] - O['admittime']\n",
    "# O['day_id'] = [d.days for d in O.loc[:, 'day_id']]\n",
    "# O['icu_day_id'] = O['charttime'] - O['intime']\n",
    "# O['icu_day_id'] = [d.days for d in O.loc[:, 'icu_day_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outputevents['day_id'] = data_outputevents['charttime'] - data_outputevents['admittime']\n",
    "data_outputevents['day_id'] = [d.days for d in data_outputevents.loc[:, 'day_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outputevents['_12h_window_id'] = data_outputevents['charttime'] - data_outputevents['admittime']\n",
    "data_outputevents['_12h_window_id'] = [(d.days*24 + d.seconds//3600)//12 for d in data_outputevents.loc[:, '_12h_window_id']]\n",
    "\n",
    "data_outputevents['hour_id'] = data_outputevents['charttime'] - data_outputevents['admittime']\n",
    "data_outputevents['hour_id'] = [(d.days*24 + d.seconds//3600) for d in data_outputevents.loc[:, 'hour_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_outputevents['icu_day_id'] = data_outputevents['charttime'] - data_outputevents['intime']\n",
    "data_outputevents['icu_day_id'] = [d.days for d in data_outputevents.loc[:, 'icu_day_id']]\n",
    "\n",
    "data_outputevents['icu_12h_window_id'] = data_outputevents['charttime'] - data_outputevents['intime']\n",
    "data_outputevents['icu_12h_window_id'] = [(d.days*24 + d.seconds//3600)//12 for d in data_outputevents.loc[:, 'icu_12h_window_id']]\n",
    "\n",
    "data_outputevents['icu_hour_id'] = data_outputevents['charttime'] - data_outputevents['intime']\n",
    "data_outputevents['icu_hour_id'] = [(d.days*24 + d.seconds//3600) for d in data_outputevents.loc[:, 'icu_hour_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_outputevents.shape)\n",
    "data_outputevents.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'data_outputevents.pkl', 'wb') as f:\n",
    "    pickle.dump(data_outputevents, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'data_outputevents.pkl', 'rb') as f:\n",
    "    data_outputevents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "procedureevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_procedureevents = pd.read_csv(ICU_PATH + 'procedureevents.csv')\n",
    "\n",
    "data_procedureevents.columns = data_procedureevents.columns.str.lower()\n",
    "\n",
    "data_procedureevents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDC map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the table with mapping NDC codes to ATC codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ndc_map = pd.read_csv('/home/svetlanamaslenkova/Documents/data/FDA NDC directory with atc5 atc4 ingredients (2020_06_17)/ndc_map 2020_06_17 (atc5 atc4 ingredients).csv')\n",
    "\n",
    "ndc_map.columns = ndc_map.columns.str.lower()\n",
    "\n",
    "ndc_map.atc4_name = ndc_map.atc4_name.astype('str')\n",
    "\n",
    "ndc_map = ndc_map[~ndc_map.atc4.isna()]\n",
    "\n",
    "print(ndc_map.shape)\n",
    "ndc_map.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading prepared dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/svetlanamaslenkova/Documents/AKI_deep/LSTM/pickles/' + 'pid_labevents.pkl', 'rb') as f:\n",
    "    pid_labevents = pickle.load(f)\n",
    "print('number of admissions from ICU: ', data_icustays[data_icustays.hadm_id.isin(pid_labevents.hadm_id.unique())].hadm_id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/svetlanamaslenkova/Documents/AKI_deep/LSTM/pickles/' + 'aki_status_df.pkl', 'rb') as f:\n",
    "    final_aki_status = pickle.load(f)\n",
    "final_aki_status = final_aki_status[~final_aki_status.isna()]\n",
    "print('number of admissions from ICU: ', data_icustays[data_icustays.hadm_id.isin(final_aki_status.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "final_aki_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_vitals.pkl', 'rb') as f:\n",
    "    pid_vitals = pickle.load(f)\n",
    "temp = pid_vitals[pid_vitals.vitals.str.contains(r'[0-9]')]\n",
    "print('number of admissions from ICU with any information: ', data_icustays[data_icustays.hadm_id.isin(temp.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "print('number of admissions from ICU: ', data_icustays[data_icustays.hadm_id.isin(pid_vitals.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "pid_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_medications.pkl', 'rb') as f:\n",
    "    pid_medications = pickle.load(f)\n",
    "temp = pid_medications[pid_medications.medications.str.contains(r'[a-zA-Z]')]\n",
    "print('number of admissions from ICU with any information: ', data_icustays[data_icustays.hadm_id.isin(temp.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "print('number of admissions from ICU: ', data_icustays[data_icustays.hadm_id.isin(pid_medications.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "pid_medications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'data_demographics.pkl', 'rb') as f:\n",
    "    data_demographics = pickle.load(f)\n",
    "temp = data_demographics[data_demographics.demographics.str.contains(r'M|F')]\n",
    "print('number of admissions from ICU with any information: ', data_icustays[data_icustays.hadm_id.isin(temp.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "print('number of admissions from ICU: ', data_icustays[data_icustays.hadm_id.isin(data_demographics.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "data_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/svetlanamaslenkova/Documents/AKI_deep/LSTM/pickles/' + 'hid_previous_diagnoses.pkl', 'rb') as f:\n",
    "    df_previous_diags = pickle.load(f)\n",
    "temp = df_previous_diags[df_previous_diags.previous_diags_icd.str.contains('D')]\n",
    "print('number of admissions from ICU with any information: ', data_icustays[data_icustays.hadm_id.isin(temp.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "print('number of admissions from ICU: ', data_icustays[data_icustays.hadm_id.isin(df_previous_diags.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "df_previous_diags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'labevents_creatinine.pkl', 'rb') as f:\n",
    "    labevents_creatinine = pickle.load(f)\n",
    "print('number of admissions from ICU: ', data_icustays[data_icustays.hadm_id.isin(labevents_creatinine.hadm_id.unique())].hadm_id.unique().shape[0])\n",
    "labevents_creatinine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_status_icu.pkl', 'rb') as f:\n",
    "    aki_status_icu = pickle.load(f)\n",
    "aki_status_icu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_stage_labels.pkl', 'rb') as f:\n",
    "    aki_stage_labels = pickle.load(f)\n",
    "aki_stage_labels.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n of unique patients: ', (data_icustays.subject_id.unique().shape[0]))\n",
    "print('n of unique admissions: ', (data_icustays.hadm_id.unique().shape[0]))\n",
    "print('n of unique ICU stays: : ', (data_icustays.stay_id.unique().shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers are not consistent because one day a patient can have AKI 1 and the next day AKI 2, so the same patient will fall into two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of admissions with aki status available from ICU wards\n",
    "# icu_aki_status = final_aki_status.merge(data_icustays, on='hadm_id', how='inner')\n",
    "icu_aki_status = aki_stage_labels.copy()\n",
    "print('number of admissions with aki status available from ICU wards: ', \\\n",
    "                    icu_aki_status.hadm_id.unique().shape[0])\n",
    "\n",
    "# print('number of admissions in icu: ', data_icustays.hadm_id.unique().shape[0])\n",
    "g_adm = aki_stage_labels.groupby('hadm_id').sum()\n",
    "print('admissions with no AKI in ICU: ', g_adm[g_adm.ANY_AKI==0].index.shape[0])\n",
    "print('admissions with AKI 1 in ICU: ', icu_aki_status[icu_aki_status.AKI_1==1].drop_duplicates(subset=['hadm_id']).shape[0])\n",
    "print('admissions with AKI 2 in ICU: ', icu_aki_status[icu_aki_status.AKI_2==1].drop_duplicates(subset=['hadm_id']).shape[0])\n",
    "print('admissions with AKI 3 in ICU: ', icu_aki_status[icu_aki_status.AKI_3==1].drop_duplicates(subset=['hadm_id']).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of stays with aki status available from ICU wards: ', \\\n",
    "                    icu_aki_status.stay_id.unique().shape[0])\n",
    "g_adm = aki_stage_labels.groupby('stay_id').sum()\n",
    "print('admissions with no AKI in ICU: ', g_adm[g_adm.ANY_AKI==0].index.shape[0])\n",
    "print('admissions with AKI 1 in ICU: ', icu_aki_status[icu_aki_status.AKI_1==1].drop_duplicates(subset=['stay_id']).shape[0])\n",
    "print('admissions with AKI 2 in ICU: ', icu_aki_status[icu_aki_status.AKI_2==1].drop_duplicates(subset=['stay_id']).shape[0])\n",
    "print('admissions with AKI 3 in ICU: ', icu_aki_status[icu_aki_status.AKI_3==1].drop_duplicates(subset=['stay_id']).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make labels for the second day in ICU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_stage_labels_second_day = aki_stage_labels[aki_stage_labels.icu_day_id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_stage_labels_second_day = aki_stage_labels_second_day.groupby('stay_id').sum().reset_index()[['subject_id', 'hadm_id', 'stay_id', 'AKI_1',\t'AKI_2',\t'AKI_3',\t'ANY_AKI', 'NO_AKI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_stage_labels_second_day['AKI_2'] = list(np.where((aki_stage_labels_second_day['AKI_3']==0), aki_stage_labels_second_day['AKI_2'], 0))\n",
    "aki_stage_labels_second_day['AKI_1'] = list(np.where(((aki_stage_labels_second_day['AKI_3']==0)&(aki_stage_labels_second_day['AKI_2']==0)), aki_stage_labels_second_day['AKI_1'], 0))\n",
    "aki_stage_labels_second_day['ANY_AKI'] = np.where(((aki_stage_labels_second_day['AKI_1']==0)&(aki_stage_labels_second_day['AKI_2']==0)&(aki_stage_labels_second_day['AKI_3']==0)), 0, 1)\n",
    "aki_stage_labels_second_day['NO_AKI'] = np.where(((aki_stage_labels_second_day['AKI_1']==0)&(aki_stage_labels_second_day['AKI_2']==0)&(aki_stage_labels_second_day['AKI_3']==0)), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_stage_labels_second_day['AKI_1'] = aki_stage_labels_second_day['AKI_1'].astype(bool).astype(int)\n",
    "aki_stage_labels_second_day['AKI_2'] = aki_stage_labels_second_day['AKI_2'].astype(bool).astype(int)\n",
    "aki_stage_labels_second_day['AKI_3'] = aki_stage_labels_second_day['AKI_3'].astype(bool).astype(int)\n",
    "aki_stage_labels_second_day['ANY_AKI'] = aki_stage_labels_second_day['ANY_AKI'].astype(bool).astype(int)\n",
    "aki_stage_labels_second_day['NO_AKI'] = aki_stage_labels_second_day['NO_AKI'].astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_stage_labels_second_day.pkl', 'wb') as f:\n",
    "    pickle.dump(aki_stage_labels_second_day, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_stage_labels_second_day.pkl', 'rb') as f:\n",
    "    aki_stage_labels_second_day = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here numbers are consistent because the labels are for the second day in ICU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of stays with aki status available from ICU wards: ', \\\n",
    "                    aki_stage_labels_second_day.stay_id.unique().shape[0])\n",
    "g_adm = aki_stage_labels_second_day.groupby('stay_id').sum()\n",
    "print('admissions with no AKI in ICU: ', g_adm[g_adm.ANY_AKI==0].index.shape[0])\n",
    "print('admissions with AKI 1 in ICU: ', aki_stage_labels_second_day[aki_stage_labels_second_day.AKI_1==1].stay_id.unique().shape[0])\n",
    "print('admissions with AKI 2 in ICU: ', aki_stage_labels_second_day[aki_stage_labels_second_day.AKI_2==1].stay_id.unique().shape[0])\n",
    "print('admissions with AKI 3 in ICU: ', aki_stage_labels_second_day[aki_stage_labels_second_day.AKI_3==1].stay_id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "icu_aki_status = aki_status_icu.copy()\n",
    "g0 = icu_aki_status[(icu_aki_status.AKI_1==1)].sort_values(['hadm_id', 'day_id'])\\\n",
    "                        .drop_duplicates(['hadm_id'], keep='first')\\\n",
    "                            .groupby('day_id')\\\n",
    "                                .count()\n",
    "index0 = g0.AKI_1.sort_values(ascending=False).index\n",
    "values0 = g0.AKI_1.sort_values(ascending=False).values\n",
    "\n",
    "g1 = icu_aki_status[(icu_aki_status.AKI_1==1)&(icu_aki_status.AKI_2==0)].sort_values(['hadm_id', 'day_id'])\\\n",
    "                        .drop_duplicates(['hadm_id'], keep='first')\\\n",
    "                            .groupby('day_id')\\\n",
    "                                .count()\n",
    "index1 = g1.AKI_1.sort_values(ascending=False).index\n",
    "values1 = g1.AKI_1.sort_values(ascending=False).values\n",
    "\n",
    "g2 = icu_aki_status[(icu_aki_status.AKI_2==1)&(icu_aki_status.AKI_3==0)].sort_values(['hadm_id', 'day_id'])\\\n",
    "                        .drop_duplicates(['hadm_id'], keep='first')\\\n",
    "                            .groupby('day_id')\\\n",
    "                                .count()\n",
    "index2 = g2.AKI_2.sort_values(ascending=False).index\n",
    "values2 = g2.AKI_2.sort_values(ascending=False).values\n",
    "\n",
    "g3 = icu_aki_status[icu_aki_status.AKI_3==1].sort_values(['hadm_id', 'day_id'])\\\n",
    "                        .drop_duplicates(['hadm_id'], keep='first')\\\n",
    "                            .groupby('day_id')\\\n",
    "                                .count()\n",
    "index3 = g3.AKI_3.sort_values(ascending=False).index\n",
    "values3 = g3.AKI_3.sort_values(ascending=False).values\n",
    "\n",
    "fig, (ax2) = plt.subplots(1, 1, figsize=(12, 6), sharex=False) \n",
    "\n",
    "ax2.set_xticks(index1)\n",
    "# ax2.set_yticks(np.arange(0, 3000, 100))\n",
    "ax2.set_xlim([0,25])\n",
    "ax2.set_xlabel('day_id')\n",
    "ax2.set_ylabel('n of patients with AKI')\n",
    "ax2.bar(index0, values0, width=0.9, label='AKI of any stage')\n",
    "ax2.bar(index1, values1, width=0.9, label='AKI of stage 1')\n",
    "ax2.bar(index2, values2, width=0.9, label='AKI stage 2')\n",
    "ax2.bar(index3, values3, width=0.9, label='AKI stage 3')\n",
    "ax2.set_title('Number of patients having the first AKI onset on a particular day of an admission')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "from matplotlib import pyplot as plt\n",
    "icu_aki_status = aki_status_icu.copy()\n",
    "\n",
    "g0 = icu_aki_status[(icu_aki_status.AKI_1==1)].sort_values(['hadm_id', 'icu_12h_window_id'])\\\n",
    "                        .drop_duplicates(['stay_id'], keep='first')\\\n",
    "                            .groupby('icu_day_id')\\\n",
    "                                .count()\n",
    "index0 = g0.AKI_1.sort_values(ascending=False).index\n",
    "values0 = g0.AKI_1.sort_values(ascending=False).values\n",
    "\n",
    "g1 = icu_aki_status[(icu_aki_status.AKI_1==1)&(icu_aki_status.AKI_2==0)].sort_values(['hadm_id', 'icu_12h_window_id'])\\\n",
    "                        .drop_duplicates(['stay_id'], keep='first')\\\n",
    "                            .groupby('icu_day_id')\\\n",
    "                                .count()\n",
    "index1 = g1.AKI_1.sort_values(ascending=False).index\n",
    "values1 = g1.AKI_1.sort_values(ascending=False).values\n",
    "\n",
    "g2 = icu_aki_status[(icu_aki_status.AKI_2==1)&(icu_aki_status.AKI_3==0)].sort_values(['hadm_id', 'icu_12h_window_id'])\\\n",
    "                        .drop_duplicates(['stay_id'], keep='first')\\\n",
    "                            .groupby('day_id')\\\n",
    "                                .count()\n",
    "index2 = g2.AKI_2.sort_values(ascending=False).index\n",
    "values2 = g2.AKI_2.sort_values(ascending=False).values\n",
    "\n",
    "g3 = icu_aki_status[icu_aki_status.AKI_3==1].sort_values(['hadm_id', 'icu_12h_window_id'])\\\n",
    "                        .drop_duplicates(['stay_id'], keep='first')\\\n",
    "                            .groupby('day_id')\\\n",
    "                                .count()\n",
    "index3 = g3.AKI_3.sort_values(ascending=False).index\n",
    "values3 = g3.AKI_3.sort_values(ascending=False).values\n",
    "\n",
    "fig, (ax2) = plt.subplots(1, 1, figsize=(12, 6), sharex=False) \n",
    "\n",
    "ax2.set_xticks(index1)\n",
    "# ax2.set_yticks(np.arange(0, 3000, 100))\n",
    "ax2.set_xlim([0,25])\n",
    "ax2.set_xlabel('icu_day_id')\n",
    "ax2.set_ylabel('n of patients with AKI')\n",
    "ax2.bar(index0, values0, width=0.9, label='AKI of any stage')\n",
    "ax2.bar(index1, values1, width=0.9, label='AKI of stage 1')\n",
    "ax2.bar(index2, values2, width=0.9, label='AKI stage 2')\n",
    "ax2.bar(index3, values3, width=0.9, label='AKI stage 3')\n",
    "ax2.set_title('Number of patients having the first AKI onset on a particular day of an ICU stay')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = data_icustays.merge(data_admissions[['subject_id', 'hadm_id', 'admittime']], how='left')\n",
    "# S['day_id'] = S['intime'] - S['admittime']\n",
    "# S['day_id'] = [d.days for d in S.loc[:, 'day_id']]\n",
    "S[S.day_id>0].stay_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of patients who arrived to ICU on the first day of an admission:  {S[S.day_id==0].stay_id.unique().shape[0]}')\n",
    "print(f'Number of patients who arrived to ICU after being admitted to the hospital:  {S[S.day_id>0].stay_id.unique().shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "length of ICU stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n of unique ICU stays with length of stay at least than 2 days: : ', (data_icustays[data_icustays.los>=2].stay_id.unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(np.round(data_icustays.los.min(),2) , np.round(data_icustays.los.max(), 2))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 4), sharex=False)\n",
    "ax1.hist(data_icustays.los,  bins=50, range=(0,20),histtype ='bar', facecolor='#088F8F')\n",
    "ax1.set_xticks(np.arange(0, 20))\n",
    "ax1.set_xlabel('Number of days in ICU')\n",
    "ax1.set_ylabel('Number of patients')\n",
    "ax1.grid()\n",
    "\n",
    "ax2.boxplot(data_icustays.los, vert=False)\n",
    "ax2.set_xticks(np.arange(0, 50, 2 ))\n",
    "ax2.set_xlim([0,50])\n",
    "ax2.set_xlabel('Number of days in ICU')\n",
    "ax2.grid()\n",
    "\n",
    "fig.suptitle(\"Length of ICU stay\", fontsize=\"x-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AKI status for ICU patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get urine output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'weight_data_icu.pkl', 'rb') as f:\n",
    "    weight_data_icu = pickle.load(f)\n",
    "weight_data_icu.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('itemid | label | value | valueuom | abbreviation | category')\n",
    "for _, row in data_outputevents[data_outputevents.category=='Output'].drop_duplicates('itemid').iterrows():\n",
    "    print(f'{row.itemid} | {row.label} | {row.value}  | {row.valueuom} | {row.abbreviation} | {row.category}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urine_output_ids = [226559, 226627, 226561]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d_items[data_d_items.itemid.isin(urine_output_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urine_output_df = data_outputevents[data_outputevents.itemid.isin(urine_output_ids)].sort_values(['subject_id',\t'hadm_id',\t'stay_id', 'charttime'])\n",
    "\n",
    "urine_output_df['icu_6h_window_id'] = urine_output_df['charttime'] - urine_output_df['intime']\n",
    "urine_output_df['icu_6h_window_id'] = [(d.days*24 + d.seconds//3600)//6 for d in urine_output_df.loc[:, 'icu_6h_window_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_urine_output_6h = urine_output_df[['subject_id', 'hadm_id',\t'stay_id', 'icu_day_id',  'icu_6h_window_id', 'value']]\\\n",
    "                            .groupby(['subject_id', 'hadm_id', 'stay_id','icu_day_id', 'icu_6h_window_id'])\\\n",
    "                                .agg('sum').reset_index()\\\n",
    "                                    .merge(weight_data_icu[['subject_id', 'hadm_id', 'stay_id', 'weight_kg']]).sort_values(['subject_id','hadm_id','stay_id','icu_6h_window_id'])\n",
    "\n",
    "sum_urine_output_12h = urine_output_df[['subject_id', 'hadm_id','stay_id', 'icu_day_id', 'icu_12h_window_id', 'value']]\\\n",
    "                            .groupby(['subject_id', 'hadm_id', 'stay_id','icu_day_id', 'icu_12h_window_id'])\\\n",
    "                                .agg('sum')\\\n",
    "                                    .reset_index().merge(weight_data_icu[['subject_id', 'hadm_id', 'stay_id', 'weight_kg']]).sort_values(['subject_id','hadm_id','stay_id','icu_12h_window_id'])\n",
    "                                    \n",
    "sum_urine_output_24h = urine_output_df[['subject_id', 'hadm_id','stay_id', 'icu_day_id', 'value']]\\\n",
    "                            .groupby(['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'])\\\n",
    "                                .agg('sum')\\\n",
    "                                    .reset_index().merge(weight_data_icu[['subject_id', 'hadm_id', 'stay_id', 'weight_kg']]).sort_values(['subject_id','hadm_id','stay_id','icu_day_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_urine_output_6h['urine_ml_kg_h_6h'] = sum_urine_output_6h['value'] / sum_urine_output_6h['weight_kg'] / 6\n",
    "sum_urine_output_12h['urine_ml_kg_h_12h'] = sum_urine_output_12h['value'] / sum_urine_output_12h['weight_kg'] / 12\n",
    "sum_urine_output_24h['urine_ml_kg_h_24h'] = sum_urine_output_24h['value'] / sum_urine_output_24h['weight_kg'] / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_urine_output_6h['AKI_1'] = (sum_urine_output_6h.urine_ml_kg_h_6h < 0.5).astype(int).values\n",
    "sum_urine_output_12h['AKI_2'] = (sum_urine_output_12h.urine_ml_kg_h_12h < 0.5).astype(int).values\n",
    "sum_urine_output_24h['AKI_3'] = (sum_urine_output_24h.urine_ml_kg_h_24h < 0.3).astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the examples of urine output rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum_urine_output_6h.stay_id.unique().shape)\n",
    "print(sum_urine_output_12h.stay_id.unique().shape)\n",
    "print(sum_urine_output_24h.stay_id.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urine AKI critetia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aki_status_urine_out(stay_id, interval='24'):\n",
    "    adm_urine_output_6h = sum_urine_output_6h[sum_urine_output_6h.stay_id==stay_id]\n",
    "    adm_urine_output_12h = sum_urine_output_12h[sum_urine_output_12h.stay_id==stay_id]\n",
    "    adm_urine_output_24h = sum_urine_output_24h[sum_urine_output_24h.stay_id==stay_id]\n",
    "    AKI_1_list = []\n",
    "    AKI_2_list = []\n",
    "    AKI_3_list = []\n",
    "    AKI_1_12h_list = []\n",
    "    AKI_2_12h_list = []\n",
    "    AKI_3_12h_list = []\n",
    "    stay_id_list_1 = []\n",
    "    stay_id_list_2 = []\n",
    "    #days in icu\n",
    "    try:\n",
    "        if interval=='24':\n",
    "            days = list(adm_urine_output_24h.icu_day_id.unique())\n",
    "            arranged_days = list(np.arange(0, np.max(days) + 1))\n",
    "        for day in arranged_days:\n",
    "            if day in days:\n",
    "                # i = arranged_days.index(day)\n",
    "                if sum(adm_urine_output_6h[adm_urine_output_6h.icu_day_id==day].AKI_1.values)>0:\n",
    "                    AKI_1_list.append(1)\n",
    "                else:\n",
    "                    AKI_1_list.append(0)\n",
    "                if (sum(adm_urine_output_12h[adm_urine_output_12h.icu_day_id==day].AKI_2.values)>0)&(AKI_1_list[day]==True):\n",
    "                    AKI_2_list.append(1)\n",
    "                else:\n",
    "                    AKI_2_list.append(0)\n",
    "                if (sum(adm_urine_output_24h[adm_urine_output_24h.icu_day_id==day].AKI_3.values)>0)&(AKI_1_list[day]==True):\n",
    "                    AKI_3_list.append(1)\n",
    "                else:\n",
    "                    AKI_3_list.append(0)\n",
    "            else:\n",
    "                AKI_1_list.append(0)\n",
    "                AKI_2_list.append(0)\n",
    "                AKI_3_list.append(0)\n",
    "            stay_id_list_1.append(stay_id)\n",
    "        dict_ = {'stay_id':stay_id_list_1, 'icu_day_id':arranged_days, 'AKI_1_urine':AKI_1_list, 'AKI_2_urine':AKI_2_list, 'AKI_3_urine':AKI_3_list}\n",
    "        # not correct:\n",
    "        if interval=='12':\n",
    "            wind_6h = adm_urine_output_6h.icu_6h_window_id.unique()\n",
    "            wind_12h = adm_urine_output_12h.icu_12h_window_id.unique()\n",
    "            day_id_list = []\n",
    "            for wind in np.arange(np.min(wind_12h), np.max(wind_12h)+1):\n",
    "                if sum(adm_urine_output_6h[adm_urine_output_6h.icu_6h_window_id.isin(np.arange(wind*2, wind*2+2))].AKI_1.values)>0:\n",
    "                    AKI_1_12h_list.append(1)\n",
    "                else:\n",
    "                    AKI_1_12h_list.append(0)\n",
    "                if (sum(adm_urine_output_12h[adm_urine_output_12h.icu_12h_window_id==wind].AKI_2.values)>0)&(AKI_1_12h_list[wind]==True):\n",
    "                    AKI_2_12h_list.append(1)\n",
    "                else:\n",
    "                    AKI_2_12h_list.append(0)\n",
    "                if (sum(adm_urine_output_24h[adm_urine_output_24h.icu_day_id==wind//2].AKI_3.values)>0)&(AKI_1_list[day]==True):\n",
    "                    AKI_3_12h_list.append(1)\n",
    "                else:\n",
    "                    AKI_3_12h_list.append(0)\n",
    "                day_id_list.appens\n",
    "                stay_id_list_2.append(wind//2)\n",
    "            dict_ = {'stay_id':stay_id_list_2, 'icu_day_id':days, 'wind_12h':wind_12h, 'AKI_1_urine':AKI_1_list, 'AKI_2_urine':AKI_2_list, 'AKI_3_urine':AKI_3_list}\n",
    "        \n",
    "        return dict_\n",
    "    except:\n",
    "        print(stay_id)\n",
    "        raise\n",
    "        # errors.append(stay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cells are used for checking the function and its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_urine_output_24h[adm_urine_output_24h.stay_id==stay_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_urine_output_12h[adm_urine_output_12h.stay_id==stay_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_urine_output_6h[adm_urine_output_6h.stay_id==stay_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urine_output_df[urine_output_df.stay_id==stay_id].sort_values('charttime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay_id=38118624\n",
    "adm_urine_output_6h = sum_urine_output_6h[sum_urine_output_6h.stay_id==stay_id]\n",
    "adm_urine_output_12h = sum_urine_output_12h[sum_urine_output_12h.stay_id==stay_id]\n",
    "adm_urine_output_24h = sum_urine_output_24h[sum_urine_output_24h.stay_id==stay_id]\n",
    "AKI_1_list = []\n",
    "AKI_2_list = []\n",
    "AKI_3_list = []\n",
    "AKI_1_12h_list = []\n",
    "AKI_2_12h_list = []\n",
    "AKI_3_12h_list = []\n",
    "stay_id_list_1 = []\n",
    "stay_id_list_2 = []\n",
    "\n",
    "days = list(adm_urine_output_24h.icu_day_id.unique())\n",
    "arranged_days = np.arange(np.min(days), np.max(days) + 1)\n",
    "for day in arranged_days:\n",
    "    if day in days:\n",
    "        # i = arranged_days.index(day)\n",
    "        if sum(adm_urine_output_6h[adm_urine_output_6h.icu_day_id==day].AKI_1.values)>0:\n",
    "            AKI_1_list.append(1)\n",
    "        else:\n",
    "            AKI_1_list.append(0)\n",
    "        if (sum(adm_urine_output_12h[adm_urine_output_12h.icu_day_id==day].AKI_2.values)>0)&(AKI_1_list[day]==True):\n",
    "            AKI_2_list.append(1)\n",
    "        else:\n",
    "            AKI_2_list.append(0)\n",
    "        if (sum(adm_urine_output_24h[adm_urine_output_24h.icu_day_id==day].AKI_3.values)>0)&(AKI_1_list[day]==True):\n",
    "            AKI_3_list.append(1)\n",
    "        else:\n",
    "            AKI_3_list.append(0)\n",
    "    else:\n",
    "        AKI_1_list.append(0)\n",
    "        AKI_2_list.append(0)\n",
    "        AKI_3_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_aki_status_urine_out(38118624))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data_icustays.drop_duplicates(subset=['stay_id'], keep='first').subject_id.unique()\n",
    "admissions = data_icustays.drop_duplicates(subset=['stay_id'], keep='first').hadm_id.unique()\n",
    "icu_stays = data_icustays.drop_duplicates(subset=['stay_id'], keep='first').stay_id.unique()\n",
    "icu_stays_weight_available = sum_urine_output_24h.stay_id.unique()\n",
    "print('patients: ', len(patients))\n",
    "print('admissions: ', len(admissions))\n",
    "print(\"icu_stays: \", len(icu_stays))\n",
    "print(\"icu stays with weight data available: \", len(icu_stays_weight_available))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use multiptoccessing module for faster preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import traceback\n",
    "import multiprocessing\n",
    "\n",
    "stays = icu_stays_weight_available\n",
    "pid_aki_status_urine_icu = pd.DataFrame()\n",
    "chunk_size = 10000\n",
    "# chunk_size = 10\n",
    "n_chunks = len(stays)//chunk_size\n",
    "# n_chunks = 2\n",
    "errors = []\n",
    "\n",
    "for i in range(0,n_chunks+1):\n",
    "    with multiprocessing.Pool(processes=70) as pool_obj:\n",
    "        pid_aki_status = pool_obj.map(get_aki_status_urine_out, stays[i*chunk_size:(i+1)*chunk_size])\n",
    "\n",
    "    for e in pid_aki_status[:]:\n",
    "        temp = pd.DataFrame(e)\n",
    "        pid_aki_status_urine_icu = pd.concat([pid_aki_status_urine_icu, temp], ignore_index=True)\n",
    "\n",
    "    print(\"Finished {} stays\".format((i+1)*chunk_size))\n",
    "\n",
    "    with open(PKL_PATH + 'pid_aki_status_urine_icu.pkl', 'wb') as f:\n",
    "        pickle.dump(pid_aki_status_urine_icu, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creatinine AKI criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm for detecting the AKI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating AKI status for each day of an admission\n",
    "print_on = False\n",
    "def get_aki_status(admission):\n",
    "    try:\n",
    "        adm_labs = labevents_creatinine[(labevents_creatinine.hadm_id==admission)].sort_values('day_id')\n",
    "        if len(adm_labs)<1:\n",
    "            print('no Scr values available for', admission)\n",
    "            return\n",
    "        patient = data_admissions[data_admissions.hadm_id==admission].subject_id.values[0]\n",
    "        # admittime = data_admissions[data_admissions.hadm_id==admission].admittime\n",
    "        days = adm_labs.day_id.values.tolist()\n",
    "        hadm_ids = []\n",
    "        aki_status = {'AKI_1':[], 'AKI_2':[], 'AKI_3':[]}\n",
    "        AKI_1 = False\n",
    "        AKI_2 = False\n",
    "        AKI_3 = False\n",
    "        specimen_ids = []\n",
    "\n",
    "        all_days = np.arange(np.min(days), np.max(days)+1)\n",
    "\n",
    "        for day in all_days:\n",
    "            hadm_ids.append(admission)\n",
    "            if day not in days:\n",
    "                if print_on:\n",
    "                    print(f'day {day} - no SCr')\n",
    "                    print(f'AKI_1  [{int(False)}], AKI_2 [{int(False)}], AKI_3 [{int(False)}]')\n",
    "                    print('----------------')\n",
    "                aki_status['AKI_1'].append(int(AKI_1))\n",
    "                aki_status['AKI_2'].append(int(AKI_2))\n",
    "                aki_status['AKI_3'].append(int(AKI_3))\n",
    "                specimen_ids.append(None)\n",
    "                continue\n",
    "            \n",
    "            row_creatinine = adm_labs[adm_labs.day_id==day].sort_values('valuenum', ascending=False)\n",
    "            C1 = float(row_creatinine.valuenum.values[0])\n",
    "            charttime = row_creatinine.charttime.values[0]\n",
    "            specimen_id = row_creatinine.specimen_id.values[0]\n",
    "            \n",
    "            if print_on:\n",
    "                print(f'day {day} creatinine {C1}')\n",
    "            \n",
    "            df_baseline_1 = adm_labs[(adm_labs.charttime + np.timedelta64(24*7, 'h') >= charttime) \\\n",
    "                                            & (adm_labs.charttime < charttime)]\n",
    "\n",
    "            df_median_baseline = labevents_creatinine[(labevents_creatinine.subject_id==patient)\\\n",
    "                                            &(labevents_creatinine.charttime + np.timedelta64(365, 'D') >= charttime) \\\n",
    "                                                & (labevents_creatinine.charttime < charttime)]\n",
    "\n",
    "            df_baseline_2 = adm_labs[(adm_labs.charttime + np.timedelta64(48, 'h') >= charttime) \\\n",
    "                                            & (adm_labs.charttime < charttime)]\n",
    "            # get baselines values\n",
    "            if len(df_baseline_1) > 0:\n",
    "                scr_baseline_1 = np.min(df_baseline_1.valuenum.values)\n",
    "\n",
    "            elif len(df_median_baseline):\n",
    "                scr_baseline_1 = np.median(df_median_baseline.valuenum.values)\n",
    "            else:\n",
    "                scr_baseline_1 = None\n",
    "\n",
    "            if len(df_baseline_2) > 0:\n",
    "                scr_baseline_2 = np.min(df_baseline_2.valuenum.values) #.sort_values('value', ascending=True).value.values[0]\n",
    "            else:\n",
    "                scr_baseline_2 = None\n",
    "            if print_on:\n",
    "                # print(f' baseline1 = {scr_baseline_1}, baseline2 = {scr_baseline_2}')\n",
    "                print('baseline_1', scr_baseline_1)\n",
    "                print('baseline_2', scr_baseline_2)\n",
    "            # calculate aki\n",
    "            if C1 >= 4.0:\n",
    "                AKI_3 = True\n",
    "                AKI_2 = True\n",
    "                AKI_1 = True\n",
    "            elif (scr_baseline_1 is not None):\n",
    "                RV = np.round(C1 / scr_baseline_1, 2)\n",
    "                if print_on:\n",
    "                    print(f'RV = {C1} / {scr_baseline_1} = {RV}')\n",
    "                if (RV >= 1.5):\n",
    "                    if RV >=3.0:\n",
    "                        AKI_3 = True\n",
    "                        AKI_2 = True\n",
    "                        AKI_1 = True\n",
    "                    elif 3.0 > RV >=2.0:\n",
    "                        AKI_3 = False\n",
    "                        AKI_2 = True\n",
    "                        AKI_1 = True\n",
    "                    elif 2.0 > RV >= 1.5:\n",
    "                        AKI_3 = False\n",
    "                        AKI_2 = False\n",
    "                        AKI_1 = True\n",
    "                elif  (scr_baseline_2 is not None):\n",
    "                    if (C1 - scr_baseline_2 > 0.29):\n",
    "                        AKI_3 = False\n",
    "                        AKI_2 = False\n",
    "                        AKI_1 = True\n",
    "                    else:\n",
    "                        AKI_3 = False\n",
    "                        AKI_2 = False\n",
    "                        AKI_1 = False\n",
    "                else:\n",
    "                    AKI_3 = False\n",
    "                    AKI_2 = False\n",
    "                    AKI_1 = False\n",
    "            elif (scr_baseline_2 is not None):\n",
    "                if (C1 - scr_baseline_2 > 0.29):    \n",
    "                        AKI_1 = False\n",
    "                        AKI_2 = False\n",
    "                        AKI_1 = True\n",
    "            else:\n",
    "                AKI_1 = False\n",
    "                AKI_2 = False\n",
    "                AKI_3 = False\n",
    "\n",
    "            specimen_ids.append(specimen_id)\n",
    "           \n",
    "            aki_status['AKI_1'].append(int(AKI_1))\n",
    "            aki_status['AKI_2'].append(int(AKI_2))\n",
    "            aki_status['AKI_3'].append(int(AKI_3))\n",
    "\n",
    "            if print_on:\n",
    "                print(f'AKI_1  [{int(AKI_1)}], AKI_2 [{int(AKI_2)}], AKI_3 [{int(AKI_3)}]')\n",
    "                print('----------------')\n",
    "    except:\n",
    "        print(admission)\n",
    "        # raise\n",
    "\n",
    "    return {'hadm_id':hadm_ids, 'specimen_id':specimen_ids, 'day_id':all_days, 'AKI_1':aki_status['AKI_1'], 'AKI_2':aki_status['AKI_2'], 'AKI_3':aki_status['AKI_3']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents_creatinine.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d_items.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data_icustays.drop_duplicates(subset=['stay_id'], keep='first').subject_id.unique()\n",
    "admissions = data_icustays.drop_duplicates(subset=['stay_id'], keep='first').hadm_id.unique()\n",
    "icu_stays = data_icustays.drop_duplicates(subset=['stay_id'], keep='first').stay_id.unique()\n",
    "print('patients: ', len(patients))\n",
    "print('admissions: ', len(admissions))\n",
    "print(\"icu_stays: \", len(icu_stays))\n",
    "print('n of unique ICU stays with length of stay at least than 2 days: : ', (data_icustays[data_icustays.los>=2].stay_id.unique().shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    #return lst3\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scr_counts = labevents_creatinine.groupby('hadm_id').count().sort_values('subject_id')\n",
    "admissions_with_2_scr_tests = scr_counts[scr_counts.subject_id > 1].reset_index().hadm_id.unique()\n",
    "icu_admissions_with_2_scr_tests = intersection(admissions, admissions_with_2_scr_tests)\n",
    "icu_admissions_with_2_scr_tests_and_2_days_in_icu = intersection(icu_admissions_with_2_scr_tests, list(data_icustays[data_icustays.los>=2].hadm_id.unique()))\n",
    "print('n of admissions with at least 2 SCr measurements and at least 2 days in ICU: ', len(icu_admissions_with_2_scr_temps_and_2_days_in_icu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pid_aki_status = []\n",
    "errors = []\n",
    "i = 0\n",
    "for adm in icu_admissions_with_2_scr_tests_and_2_days_in_icu:\n",
    "    if i % 100==0:\n",
    "        print(f'------ {i}/{len(icu_admissions_with_2_scr_temps_and_2_days_in_icu)} admissions finished ------')\n",
    "    try:\n",
    "        pid_aki_status.append(get_aki_status(adm))\n",
    "    except:\n",
    "        print(adm)\n",
    "        errors.add(adm)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import traceback\n",
    "import multiprocessing\n",
    "\n",
    "admissions = icu_admissions_with_2_scr_tests_and_2_days_in_icu\n",
    "final_aki_status_icu = pd.DataFrame()\n",
    "chunk_size = 5000\n",
    "n_chunks = len(admissions)//chunk_size\n",
    "errors = []\n",
    "\n",
    "for i in range(0,n_chunks+1):\n",
    "    with multiprocessing.Pool(processes=80) as pool_obj:\n",
    "        pid_aki_status = pool_obj.map(get_aki_status, admissions[i*chunk_size:(i+1)*chunk_size])\n",
    "\n",
    "    for e in pid_aki_status[:]:\n",
    "        temp = pd.DataFrame(e)\n",
    "        final_aki_status_icu = pd.concat([final_aki_status_icu, temp], ignore_index=True)\n",
    "\n",
    "    print(\"Finished {} admissions\".format((i+1)*chunk_size))\n",
    "\n",
    "    with open(PKL_PATH + 'final_aki_status_icu.pkl', 'wb') as f:\n",
    "        pickle.dump(final_aki_status_icu, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_aki_status_icu[final_aki_status_icu.AKI_3==1].sort_values(['hadm_id', 'day_id']).drop_duplicates('hadm_id', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine two criterias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter stays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays = data_icustays[data_icustays.los>=2].sort_values(['subject_id', 'hadm_id', 'stay_id'])\n",
    "print(data_icustays.shape)\n",
    "data_icustays.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge createnine AKI status with labevents to get icu_day_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'final_aki_status_icu.pkl', 'rb') as f:\n",
    "    final_aki_status_icu = pickle.load(f)\n",
    "final_aki_status_icu.rename(columns={'AKI_1':'AKI_1_scr', 'AKI_2':'AKI_2_scr', 'AKI_3':'AKI_3_scr'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_aki_status_icu.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge labevents with icu_stays to get icu stay column\n",
    "L = labevents.merge(data_icustays[['subject_id', 'hadm_id',\t'stay_id', 'intime', 'outtime']]).sort_values(['subject_id', 'hadm_id', 'charttime'])\n",
    "# remove wrong rows with inconsistency between intime, outtime and charttime\n",
    "L = L[(L.charttime > L.intime)&(L.charttime < L.outtime)]\n",
    "# get day ids for starting from admittime and intime\n",
    "L['day_id'] = L['charttime'] - L['admittime']\n",
    "L['day_id'] = [d.days for d in L.loc[:, 'day_id']]\n",
    "L['icu_day_id'] = L['charttime'] - L['intime']\n",
    "L['icu_day_id'] = [d.days for d in L.loc[:, 'icu_day_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_aki_status_icu = final_aki_status_icu.merge(L[['specimen_id','icu_day_id', 'charttime', 'stay_id']], how='inner', on=['specimen_id']).drop_duplicates()\n",
    "print(f'Number of unique admissions: ', final_aki_status_icu.hadm_id.unique().shape[0])\n",
    "print(f'Shape: ', final_aki_status_icu.shape)\n",
    "final_aki_status_icu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients with multiple icu stays\n",
    "data_icustays[data_icustays.duplicated(subset=['subject_id', 'hadm_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge urine AKI status with icu_stays to get hadm_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_aki_status_urine_icu.pkl', 'rb') as f:\n",
    "    pid_aki_status_urine_icu = pickle.load(f)\n",
    "\n",
    "pid_aki_status_urine_icu.rename(columns={'day_id':'icu_day_id'}, inplace=True)\n",
    "pid_aki_status_urine_icu = pid_aki_status_urine_icu.merge(data_icustays[['hadm_id', 'stay_id']], on='stay_id', how='left')\n",
    "\n",
    "print(f'Number of unique ICU stays: ', pid_aki_status_urine_icu.stay_id.unique().shape[0])\n",
    "print(f'Number of unique admissions: ', pid_aki_status_urine_icu.hadm_id.unique().shape[0])\n",
    "print(f'Shape: ', pid_aki_status_urine_icu.shape)\n",
    "pid_aki_status_urine_icu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge two criterias on icu_day_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu = final_aki_status_icu.merge(pid_aki_status_urine_icu, on=['hadm_id', 'icu_day_id'], how='left').sort_values(['hadm_id', 'day_id', 'icu_day_id'])\n",
    "aki_status_icu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out rows without stay_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu = aki_status_icu[~(aki_status_icu.stay_id_x.isna())].rename(columns={'stay_id_x':'stay_id'}).drop(columns=['stay_id_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add urine criteria to SCr criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu = aki_status_icu.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu['AKI_1'] = (aki_status_icu['AKI_1_scr'] + aki_status_icu['AKI_1_urine']).astype(bool).astype(int)\n",
    "aki_status_icu['AKI_2'] = (aki_status_icu['AKI_2_scr'] + aki_status_icu['AKI_2_urine']).astype(bool).astype(int)\n",
    "aki_status_icu['AKI_3'] = (aki_status_icu['AKI_3_scr'] + aki_status_icu['AKI_3_urine']).astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rows with positive AKI: ')\n",
    "print('AKI_1 SCr:', aki_status_icu[aki_status_icu.AKI_1_scr==1].shape[0], 'Urine: ', aki_status_icu[aki_status_icu.AKI_1_urine==1].shape[0], 'Both: ', aki_status_icu[aki_status_icu.AKI_1==1].shape[0])\n",
    "print('AKI_2 SCr:', aki_status_icu[aki_status_icu.AKI_2_scr==1].shape[0], 'Urine: ', aki_status_icu[aki_status_icu.AKI_2_urine==1].shape[0], 'Both: ', aki_status_icu[aki_status_icu.AKI_2==1].shape[0])\n",
    "print('AKI_3 SCr:', aki_status_icu[aki_status_icu.AKI_3_scr==1].shape[0], 'Urine: ', aki_status_icu[aki_status_icu.AKI_3_scr==1].shape[0], 'Both: ', aki_status_icu[aki_status_icu.AKI_3==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ICU Stays with positive AKI: ')\n",
    "print('AKI_1 SCr:', aki_status_icu[aki_status_icu.AKI_1_scr==1].stay_id.unique().shape[0], 'Urine: ', aki_status_icu[aki_status_icu.AKI_1_urine==1].stay_id.unique().shape[0], 'Both: ', aki_status_icu[aki_status_icu.AKI_1==1].stay_id.unique().shape[0])\n",
    "print('AKI_2 SCr:', aki_status_icu[aki_status_icu.AKI_2_scr==1].stay_id.unique().shape[0], 'Urine: ', aki_status_icu[aki_status_icu.AKI_2_urine==1].stay_id.unique().shape[0], 'Both: ', aki_status_icu[aki_status_icu.AKI_2==1].stay_id.unique().shape[0])\n",
    "print('AKI_3 SCr:', aki_status_icu[aki_status_icu.AKI_3_scr==1].stay_id.unique().shape[0], 'Urine: ', aki_status_icu[aki_status_icu.AKI_3_scr==1].stay_id.unique().shape[0], 'Both: ', aki_status_icu[aki_status_icu.AKI_3==1].stay_id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu = aki_status_icu.merge(data_icustays[['subject_id', 'hadm_id', 'stay_id', 'intime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu['icu_day_id'] = aki_status_icu['charttime'] - aki_status_icu['intime']\n",
    "aki_status_icu['icu_day_id'] = [d.days for d in aki_status_icu.loc[:, 'icu_day_id']]\n",
    "\n",
    "aki_status_icu['icu_12h_window_id'] = aki_status_icu['charttime'] - aki_status_icu['intime']\n",
    "aki_status_icu['icu_12h_window_id'] = [(d.days*24 + d.seconds//3600)//12 for d in aki_status_icu.loc[:, 'icu_12h_window_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aki_status_icu = aki_status_icu[['subject_id', 'hadm_id', 'stay_id', 'specimen_id', 'day_id', 'icu_day_id', 'icu_12h_window_id', 'charttime', 'intime', 'AKI_1_scr',\t'AKI_2_scr',\t'AKI_3_scr', 'AKI_1_urine',\t'AKI_2_urine',\t'AKI_3_urine',\t'AKI_1',\t'AKI_2',\t'AKI_3']]\n",
    "aki_status_icu = aki_status_icu[['subject_id', 'hadm_id', 'stay_id', 'specimen_id', 'day_id', 'icu_day_id',  'charttime', 'intime', 'AKI_1_scr',\t'AKI_2_scr',\t'AKI_3_scr', 'AKI_1_urine',\t'AKI_2_urine',\t'AKI_3_urine',\t'AKI_1',\t'AKI_2',\t'AKI_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add labels for model that uses softmax activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_stage_labels = aki_status_icu.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_stage_labels['AKI_2'] = list(np.where((aki_stage_labels['AKI_3']==0), aki_stage_labels['AKI_2'], 0))\n",
    "aki_stage_labels['AKI_1'] = list(np.where(((aki_stage_labels['AKI_3']==0)&(aki_stage_labels['AKI_2']==0)), aki_stage_labels['AKI_1'], 0))\n",
    "aki_stage_labels['ANY_AKI'] = np.where(((icu_aki_status['AKI_1']==0)&(icu_aki_status['AKI_2']==0)&(icu_aki_status['AKI_3']==0)), 0, 1)\n",
    "aki_stage_labels['NO_AKI'] = np.where(((icu_aki_status['AKI_1']==0)&(icu_aki_status['AKI_2']==0)&(icu_aki_status['AKI_3']==0)), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_stage_labels.pkl', 'wb') as f:\n",
    "    pickle.dump(aki_stage_labels, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_status_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(aki_status_icu, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_status_icu.pkl', 'rb') as f:\n",
    "    aki_status_icu = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_stage_labels.pkl', 'rb') as f:\n",
    "    aki_stage_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu.stay_id.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering admissions and stays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out admissions with AKI diagnoses and no AKI found by criterias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icd codes for AKI\n",
    "AKI_icd = list(data_d_icd_diagnoses[(data_d_icd_diagnoses.long_title.str.contains('acute'))\\\n",
    "                & (data_d_icd_diagnoses.long_title.str.contains('kidney'))\\\n",
    "                    & (data_d_icd_diagnoses.long_title.str.contains(('|').join(['failure', 'injury'])))\\\n",
    "                        |(data_d_icd_diagnoses.icd_code.str.contains('N17'))\\\n",
    "                            |(data_d_icd_diagnoses.icd_code.str.contains('^584'))]\\\n",
    "                        .icd_code.values)\n",
    "\n",
    "print(AKI_icd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d_icd_diagnoses.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in data_d_icd_diagnoses[data_d_icd_diagnoses.icd_code.isin(AKI_icd)].iterrows():\n",
    "    print(row.icd_code, row.icd_version, row.long_title)\n",
    "    # print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admissions with AKI icd code \n",
    "aki_admissions = list(data_diagnoses[data_diagnoses.icd_code.isin(AKI_icd)].hadm_id.unique())\n",
    "print(len(aki_admissions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = aki_status_icu.groupby('hadm_id')\n",
    "g = pd.DataFrame(g.sum().AKI_1==0).reset_index()\n",
    "neg_by_criteria_adms = g[g.AKI_1==True].hadm_id.unique()\n",
    "print(f'n admissions with no AKI found by criterias: ', len(neg_by_criteria_adms))\n",
    "\n",
    "pos_by_criteris_adms = aki_status_icu[(aki_status_icu.AKI_1==1)].hadm_id.unique()\n",
    "print(f'n admissions with AKI found by criterias: ', len(pos_by_criteris_adms))\n",
    "\n",
    "print(f'total adms with AKI status available: ', aki_status_icu.hadm_id.unique().shape[0])\n",
    "print(f'total stays with AKI status available: ', aki_status_icu.stay_id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_adms = aki_status_icu[(aki_status_icu.hadm_id.isin(aki_admissions))&(aki_status_icu.hadm_id.isin(neg_by_criteria_adms))].hadm_id.unique()\n",
    "fn_stays = aki_status_icu[(aki_status_icu.hadm_id.isin(aki_admissions))&(aki_status_icu.hadm_id.isin(neg_by_criteria_adms))].stay_id.unique()\n",
    "print(f'(FN) admissions with AKI diagnoses and no AKI found by criterias: ',fn_adms.shape[0], ', stays: ', fn_stays.shape[0])\n",
    "tn_adms = aki_status_icu[(~(aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(neg_by_criteria_adms))].hadm_id.unique()\n",
    "tn_stays = aki_status_icu[(~(aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(neg_by_criteria_adms))].stay_id.unique()\n",
    "print(f'(TN) admissions with no AKI diagnoses and no AKI found by criterias: ',tn_adms.shape[0], ', stays: ', tn_stays.shape[0])\n",
    "\n",
    "fp_adms = aki_status_icu[(~(aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(pos_by_criteris_adms))].hadm_id.unique()\n",
    "fp_stays = aki_status_icu[(~(aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(pos_by_criteris_adms))].stay_id.unique()\n",
    "print(f'(FP) admissions with no AKI diagnoses and AKI found by criterias: ',fp_adms.shape[0], ', stays: ', fp_stays.shape[0])\n",
    "tp_adms = aki_status_icu[((aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(pos_by_criteris_adms))].hadm_id.unique()\n",
    "tp_stays = aki_status_icu[((aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(pos_by_criteris_adms))].stay_id.unique()\n",
    "print(f'(TP) admissions with  AKI diagnoses and AKI found by criterias: ',tp_adms.shape[0], ', stays: ', tp_stays.shape[0])\n",
    "\n",
    "print(f'total admissions: {len(fn_adms)+len(tn_adms)+len(fp_adms)+len(tp_adms)}, stays: {len(fn_stays)+len(tn_stays)+len(fp_stays)+len(tp_stays)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abnormal createnine on the fisrt day:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First day of an admission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = labevents_creatinine.sort_values(['subject_id', 'hadm_id', 'charttime'], ascending=True).drop_duplicates('hadm_id', keep='first')\n",
    "normal_first_scr_adms = list(F[F.flag==''].hadm_id.unique())\n",
    "len(normal_first_scr_adms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents_creatinine[labevents_creatinine.hadm_id==24597018].sort_values(['subject_id', 'hadm_id', 'charttime'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stays and admissions with available AKI status and first SCr test result - normal\n",
    "normal_scr_adms = aki_status_icu[aki_status_icu.hadm_id.isin(normal_first_scr_adms)].hadm_id.unique()\n",
    "normal_scr_stays = aki_status_icu[aki_status_icu.hadm_id.isin(normal_first_scr_adms)].stay_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nn admissions with available AKI status and first creatinine measurement==normal: ', len(normal_scr_adms))\n",
    "print(f'n ICU stays with available AKI status and first creatinine measurement==normal: ', len(normal_scr_stays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First day of ICU stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisrt_scr_icu = chartevents_creatinine.sort_values(['subject_id','hadm_id','stay_id','charttime'], ascending=True).drop_duplicates(['subject_id','hadm_id','stay_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stays_fisrt_scr_normal_icu = fisrt_scr_icu[~(fisrt_scr_icu.valuenum>1.2)].stay_id.unique()\n",
    "adms_fisrt_scr_normal_icu = fisrt_scr_icu[~(fisrt_scr_icu.valuenum>1.2)].hadm_id.unique()\n",
    "\n",
    "# Stays and admissions with available AKI status and first SCr test result - normal\n",
    "normal_scr_adms = aki_status_icu[aki_status_icu.stay_id.isin(stays_fisrt_scr_normal_icu)].hadm_id.unique()\n",
    "normal_scr_stays = aki_status_icu[aki_status_icu.stay_id.isin(stays_fisrt_scr_normal_icu)].stay_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'n admissions with available AKI status: ', aki_status_icu.hadm_id.unique().shape[0])\n",
    "print(f'n ICU stays with available AKI status: ', aki_status_icu.stay_id.unique().shape[0])\n",
    "\n",
    "print(f'n ICU stays with available AKI status and first creatinine measurement (during ICU stay)==normal: ', len(normal_scr_stays))\n",
    "# print(f'n admissions with available AKI status and first creatinine measurement (during ICU stay)==normal: ', len(adms_fisrt_scr_normal_icu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describing the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_adms = aki_status_icu[(aki_status_icu.stay_id.isin(normal_scr_stays))&(aki_status_icu.hadm_id.isin(aki_admissions))&(aki_status_icu.hadm_id.isin(neg_by_criteria_adms))].hadm_id.unique()\n",
    "fn_stays = aki_status_icu[(aki_status_icu.stay_id.isin(normal_scr_stays))&(aki_status_icu.hadm_id.isin(aki_admissions))&(aki_status_icu.hadm_id.isin(neg_by_criteria_adms))].stay_id.unique()\n",
    "print(f'(FN) admissions with AKI diagnoses and no AKI found by criterias: ',fn_adms.shape[0], ', stays --->', fn_stays.shape[0])\n",
    "tn_adms = aki_status_icu[(aki_status_icu.stay_id.isin(normal_scr_stays))&(~(aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(neg_by_criteria_adms))].hadm_id.unique()\n",
    "tn_stays = aki_status_icu[(aki_status_icu.stay_id.isin(stays_fisrt_scr_normal_icu))&(~(aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(neg_by_criteria_adms))].stay_id.unique()\n",
    "print(f'(TN) admissions with no AKI diagnoses and no AKI found by criterias: ',tn_adms.shape[0], ', stays ---> ', tn_stays.shape[0])\n",
    "\n",
    "fp_adms = aki_status_icu[(aki_status_icu.stay_id.isin(normal_scr_stays))&(~(aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(pos_by_criteris_adms))].hadm_id.unique()\n",
    "fp_stays = aki_status_icu[(aki_status_icu.stay_id.isin(normal_scr_stays))&(~(aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(pos_by_criteris_adms))].stay_id.unique()\n",
    "print(f'(FP) admissions with no AKI diagnoses and AKI found by criterias: ',fp_adms.shape[0], ', stays ---> ', fp_stays.shape[0])\n",
    "tp_adms = aki_status_icu[(aki_status_icu.stay_id.isin(normal_scr_stays))&((aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(pos_by_criteris_adms))].hadm_id.unique()\n",
    "tp_stays = aki_status_icu[(aki_status_icu.stay_id.isin(normal_scr_stays))&((aki_status_icu.hadm_id.isin(aki_admissions)))&(aki_status_icu.hadm_id.isin(pos_by_criteris_adms))].stay_id.unique()\n",
    "print(f'(TP) admissions with  AKI diagnoses and AKI found by criterias: ',tp_adms.shape[0], ', stays ---> ', tp_stays.shape[0])\n",
    "\n",
    "print(f'total admissions: {len(fn_adms)+len(tn_adms)+len(fp_adms)+len(tp_adms)}, stays ---> {len(fn_stays)+len(tn_stays)+len(fp_stays)+len(tp_stays)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    normalize:     If True, show the proportions for each category. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories, annot_kws={\"size\": 18})\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tn, fp, fn, tp = 10676, 8530, 982, 3784\n",
    "cf = np.asarray([tn, fp, fn, tp]).reshape(2,2)\n",
    "\n",
    "labels = ['TN','FP', 'FN', 'TP']\n",
    "# labels = np.asarray(labels).reshape(2,2)\n",
    "# categories = ['Algorithm', 'Diagnoses records']\n",
    "\n",
    "make_confusion_matrix(cf, \n",
    "                      group_names=labels,\n",
    "                      categories=False, \n",
    "                      xyticks=True,\n",
    "                      xyplotlabels=False,\n",
    "                      sum_stats=False,\n",
    "                      percent=False,\n",
    "                      cbar=False\n",
    "                      )\n",
    "plt.ylabel('Diagnosis            No diagnosis', fontsize=12)\n",
    "plt.xlabel('No AKI found by algorithm               AKI found by algorithm', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out stays with AKI onset on the first day in ICU. I kept AKI stage 1 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu = aki_status_icu.sort_values(['subject_id',\t'hadm_id',\t'stay_id', 'icu_day_id'])\n",
    "F = aki_status_icu.drop_duplicates('stay_id', keep='first')\n",
    "F = F[(~(F.AKI_2==1))&((F.stay_id.isin(tp_stays))|(F.stay_id.isin(tn_stays)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stays_tp_tn_normalSCr = F.stay_id.to_list()\n",
    "print(len(stays_tp_tn_normalSCr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all admissions are at least 2 days long\n",
    "data_icustays[(data_icustays.stay_id.isin(stays_tp_tn_normalSCr))&(data_icustays.los<2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check if all stays have info for the first 2 days in icu\n",
    "stays_tp_tn_normalSCr_have_01_days = data_icustays[(data_icustays.stay_id.isin(stays_tp_tn_normalSCr))&~(data_icustays.stay_id.isin(stays_without_12h_0123))].stay_id.unique()\n",
    "print(len(stays_tp_tn_normalSCr_have_01_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting adms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_stays, temp = train_test_split(stays_tp_tn_normalSCr_have_01_days, test_size=0.2, random_state=42)\n",
    "test_stays, val_stays = train_test_split(temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_stays))\n",
    "print(len(test_stays))\n",
    "print(len(val_stays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    #return lst3\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(intersection(train_stays, tp_stays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(intersection(test_stays, tp_stays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = tp_adms[0]\n",
    "aki_status_icu[aki_status_icu.hadm_id==adm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = data_diagnoses.merge(data_d_icd_diagnoses)\n",
    "subject_id = D[D.hadm_id==adm].subject_id.values[0]\n",
    "D[D.hadm_id==adm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.subject_id==subject_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_urine_output_6h[sum_urine_output_6h.hadm_id==adm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_urine_output_24h[sum_urine_output_24h.hadm_id==adm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_data[weight_data.subject_id==subject_id]\n",
    "weight_data_icu[weight_data_icu.subject_id==subject_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urine_output_df[urine_output_df.hadm_id==adm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labevents_creatinine[labevents_creatinine.hadm_id==22595853]\n",
    "labevents_creatinine[labevents_creatinine.subject_id==subject_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chartevents vitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making pid_vitals dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_items_vitals = [225309, 225312, 226329, 220048, 225310, 224192, 228640, 220179, 223762, 227243, 220181, 224643, 224167, 220052, 220051, 220050, 220180,\n",
    "                        227242, 223761, 223765, 223766, 224645, 224646, 224647, 226092, 220045, 224359, 227016, 227015, 220046, 220047, 227858, 227916, 223764,\n",
    "                        223765, 224647]\n",
    "print(len(set(chart_items_vitals)))\n",
    "for _, row in data_d_items[data_d_items.itemid.isin(chart_items_vitals)].iterrows():\n",
    "    print(row.itemid, '|', row.label, '|', row.category,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lab events from the table, because they are in labevents already \n",
    "data_chartevents_nl = data_chartevents[~data_chartevents.category.str.contains('Labs')]\n",
    "\n",
    "# create dataframe with unique item ids\n",
    "unique_chart_items = data_chartevents_nl.drop_duplicates(subset=['itemid'])\n",
    "\n",
    "chartevents_vitals = data_chartevents_nl[data_chartevents_nl.category=='Routine Vital Signs']\n",
    "print(chartevents_vitals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format_ = '%Y-%m-%d %H:%M:%S'\n",
    "# chartevents_vitals['charttime'] = pd.to_datetime(chartevents_vitals['charttime'], format=format_)\n",
    "\n",
    "chartevents_vitals['valueuom'] = chartevents_vitals['valueuom'].fillna(-1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals = chartevents_vitals.merge(data_icustays[['subject_id', 'hadm_id', 'stay_id', 'intime', 'outtime']])\\\n",
    "                                        .merge(data_admissions[['subject_id', 'hadm_id', 'admittime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals['icu_day_id'] = chartevents_vitals['charttime'] - chartevents_vitals['intime']\n",
    "chartevents_vitals['icu_day_id'] = [d.days for d in chartevents_vitals.loc[:, 'icu_day_id']]\n",
    "\n",
    "chartevents_vitals['icu_12h_window_id'] = chartevents_vitals['charttime'] - chartevents_vitals['intime']\n",
    "chartevents_vitals['icu_12h_window_id'] = [(d.days*24 + d.seconds//3600)//12 for d in chartevents_vitals.loc[:, 'icu_12h_window_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals['day_id'] = chartevents_vitals['charttime'] - chartevents_vitals['admittime']\n",
    "chartevents_vitals['day_id'] = [d.days for d in chartevents_vitals.loc[:, 'day_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals = chartevents_vitals.sort_values(['subject_id', 'charttime', 'stay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_chartevents_vitals = chartevents_vitals[chartevents_vitals.value.str.contains('[a-zA-Z]')]\n",
    "str_chartevents_vitals.abbreviation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chartevents_vitals = chartevents_vitals[~(chartevents_vitals.value.str.contains('[a-zA-Z]'))]\n",
    "num_chartevents_vitals['valuenum'] = num_chartevents_vitals['valuenum'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals.abbreviation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviation_mapping = {'Orthostatic HR lying':'ohr lying', 'Orthostatic HR sitting':'ohr sitting', 'Orthostatic BPs lying':'obps lying', \\\n",
    "    'Orthostatic BPd lying':'obpd lying', 'Orthostatic BPs sitting':'obps sitting', 'Orthostatic BPs standing':'obps standing', \\\n",
    "       'Orthostatic HR standing':'ohr standing',  'Rest HR -  Aerobic Activity Response':'rhr aar'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals.replace({'abbreviation':abbreviation_mapping}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals.abbreviation.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_vitals.pkl', 'wb') as f:\n",
    "    pickle.dump(chartevents_vitals, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_vitals.pkl', 'rb') as f:\n",
    "    chartevents_vitals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making PID for 12h window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of admissions with aki status available from ICU wards\n",
    "admissions = aki_status_icu.hadm_id.unique()\n",
    "stays = aki_status_icu.stay_id.unique()\n",
    "print(admissions.shape[0])\n",
    "print(stays.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay = stays[0]\n",
    "data_icustays[data_icustays.stay_id==stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = num_chartevents_vitals[num_chartevents_vitals.stay_id.isin(stays[:3])][['subject_id', 'hadm_id', 'stay_id', 'valuenum', 'valueuom', 'label', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id','label', 'icu_day_id', 'icu_12h_window_id'])\\\n",
    "        .agg({'valueuom':min, 'valuenum':['min', 'max']})\\\n",
    "            .reset_index()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.droplevel(0, axis=1)\n",
    "test.columns = [ 'subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id', 'icu_12h_window_id', 'valueuom', 'min_value', 'max_value']\n",
    "test = test.sort_values(['subject_id', 'icu_12h_window_id'])\n",
    "test['vitals'] = test['label'] + ' {' + test['min_value'].astype(str) + '} ' + ' {' + test['max_value'].astype(str) + '} ' + test['valueuom']\n",
    "test.groupby(['icu_12h_window_id','icu_day_id', 'subject_id', 'hadm_id', 'stay_id']).vitals.apply('; '.join).reset_index(name='vitals')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chartevents_vitals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried to use label OR abbrevation OR itemid\n",
    "temp = num_chartevents_vitals[['subject_id', 'hadm_id', 'stay_id', 'itemid', 'valuenum', 'valueuom', 'abbreviation', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id','itemid', 'icu_day_id', 'icu_12h_window_id'])\\\n",
    "        .agg({'valueuom':min, 'valuenum':['min', 'max']})\\\n",
    "            .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print('1st row im progress..')\n",
    "# temp = temp.droplevel(0, axis=1)\n",
    "# print('2st row im progress..')\n",
    "# temp.columns = [ 'subject_id', 'hadm_id', 'stay_id', 'itemid', 'icu_day_id', 'icu_12h_window_id', 'valueuom', 'min_value', 'max_value']\n",
    "# print('3st row im progress..')\n",
    "# temp = temp.sort_values(['subject_id', 'icu_12h_window_id'])\n",
    "print('4st row im progress..')\n",
    "temp['vitals_codes'] = 'v'+ temp['itemid'].astype(str) + ' {' + temp['min_value'].astype(str) + '} ' + ' {' + temp['max_value'].astype(str) + '}'\n",
    "print('5st row im progress..')\n",
    "pid_vitals_codes = temp.groupby(['icu_12h_window_id','icu_day_id', 'subject_id', 'hadm_id', 'stay_id']).vitals_codes.apply('; '.join).reset_index(name='vitals_codes').sort_values(['subject_id', 'icu_12h_window_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_vitals_codes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pid_vitals.hadm_id.unique().shape)\n",
    "pid_vitals.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_vitals = pid_vitals.merge(pid_vitals_codes, on=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id', 'icu_12h_window_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_vitals = pid_vitals.drop(columns=['vitals_codes_x']).rename(columns={'vitals_codes_y':'vitals_codes'})\n",
    "pid_vitals.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_vitals.iloc[1,:].vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_vitals.iloc[1,:].vitals_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_vitals_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(pid_vitals, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_vitals_icu.pkl', 'rb') as f:\n",
    "    pid_vitals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_vitals[pid_vitals.stay_id==37510196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals[(chartevents_vitals.stay_id==37510196)&(chartevents_vitals.label=='Non Invasive Blood Pressure systolic')&(chartevents_vitals.icu_12h_window_id==6)].sort_values('charttime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.subject_id==10001884]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d_items[data_d_items.label.str.lower().str.contains('urine')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outputevents.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outputevents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only two categories in outputevents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_outputevents.category.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent output events are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outputevents.groupby(['label']).count().sort_values('subject_id', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print unique labels for outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print items\n",
    "unique_output_items = data_outputevents.drop_duplicates('label')\n",
    "print('itemid | label | category | valuenum')\n",
    "for _, row in  unique_output_items.sort_values('category').iterrows():\n",
    "    print(row.itemid, '|', row.label, '|', row.category, '|', row.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all outputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_outputevents[data_outputevents.stay_id.isin(stays[:3])][['subject_id', 'hadm_id', 'stay_id', 'value', 'valueuom', 'itemid', 'label', 'abbreviation', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id','itemid','label', 'abbreviation', 'icu_day_id', 'icu_12h_window_id'])\\\n",
    "        .agg({'valueuom':min, 'value':sum})\\\n",
    "            .reset_index()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = [ 'subject_id', 'hadm_id', 'stay_id','itemid', 'label', 'abbreviation', 'icu_day_id', 'icu_12h_window_id', 'valueuom', 'sum_output']\n",
    "test = test.sort_values(['subject_id', 'icu_12h_window_id'])\n",
    "test['outputs_codes'] = 'o' + test['itemid'].astype(str) + ' {' + test['sum_output'].astype(str) + '}'\n",
    "test = test.groupby(['icu_12h_window_id','icu_day_id', 'subject_id', 'hadm_id', 'stay_id']).outputs_codes.apply('; '.join).reset_index(name='outputs_codes').sort_values(['subject_id', 'icu_12h_window_id'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "g = data_outputevents[['subject_id', 'hadm_id', 'stay_id', 'value', 'valueuom', 'itemid', 'label', 'abbreviation', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id','itemid','label', 'abbreviation', 'icu_day_id', 'icu_12h_window_id'])\\\n",
    "        .agg({'valueuom':min, 'value':sum})\\\n",
    "            .reset_index()\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f'1st row is in progress...')\n",
    "g.columns = [ 'subject_id', 'hadm_id', 'stay_id','itemid', 'label', 'abbreviation', 'icu_day_id', 'icu_12h_window_id', 'valueuom', 'sum_output']\n",
    "g= g.sort_values(['subject_id', 'icu_12h_window_id'])\n",
    "print(f'2nd row is in progress...')\n",
    "g['outputs_codes'] = 'o' + g['itemid'].astype(str) + ' {' + g['sum_output'].astype(str) + '}'\n",
    "print(f'3nd row is in progress...')\n",
    "pid_outputs_codes = g.groupby(['icu_12h_window_id','icu_day_id', 'subject_id', 'hadm_id', 'stay_id']).outputs_codes.apply('; '.join)\\\n",
    "                        .reset_index(name='outputs_codes').sort_values(['subject_id', 'icu_12h_window_id'])\n",
    "pid_outputs_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_outputs = pid_outputs.merge(pid_outputs_codes, on=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id', 'icu_12h_window_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_outputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pid_outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_outputs.pkl', 'wb') as f:\n",
    "    pickle.dump(pid_outputs, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_outputs.pkl', 'rb') as f:\n",
    "    pid_outputs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.subject_id==19999987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay = 36195440\n",
    "pid_outputs[pid_outputs.stay_id==stay].outputs.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outputevents[(data_outputevents.stay_id==stay)&(data_outputevents.label=='Oral Gastric')&(data_outputevents.icu_12h_window_id==1)].sort_values('charttime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputevents.rateuom.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_inputevents['length_minutes'] = data_inputevents['endtime'] - data_inputevents['starttime']\n",
    "data_inputevents['length_minutes'] = [t.days*24*60 + t.seconds // 60 for t in data_inputevents.loc[:, 'length_minutes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_inputevents['start_icu_day_id'] = data_inputevents['starttime'] - data_inputevents['intime']\n",
    "data_inputevents['start_icu_day_id'] = [t.days for t in data_inputevents.loc[:, 'start_icu_day_id']]\n",
    "\n",
    "data_inputevents['stop_icu_day_id'] = data_inputevents['endtime'] - data_inputevents['intime']\n",
    "data_inputevents['stop_icu_day_id'] = [t.days for t in data_inputevents.loc[:, 'stop_icu_day_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_inputevents['start_icu_12h_id'] = data_inputevents['starttime'] - data_inputevents['intime']\n",
    "data_inputevents['start_icu_12h_id'] = [(t.days*24 + t.seconds//3600)//12 for t in data_inputevents.loc[:, 'start_icu_12h_id']]\n",
    "\n",
    "data_inputevents['stop_icu_12h_id'] = data_inputevents['endtime'] - data_inputevents['intime']\n",
    "data_inputevents['stop_icu_12h_id'] = [(t.days*24 + t.seconds//3600)//12 for t in data_inputevents.loc[:, 'stop_icu_12h_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rates = data_inputevents.drop_duplicates('rateuom')[['subject_id', 'hadm_id', 'stay_id', 'intime', 'starttime', 'endtime', 'length_minutes', 'itemid', 'amount', 'amountuom', 'rate',\t'rateuom', 'patientweight', 'ordercategoryname']]\n",
    "unique_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputevents.ordercategoryname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputevents.secondaryordercategoryname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputevents.ordercategorydescription.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_inputevents.length_minutes.max())\n",
    "data_inputevents.length_minutes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = list(unique_rates.rateuom.values)\n",
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medications = data_inputevents[data_inputevents.category=='Medications']\n",
    "data_medications = data_medications[['subject_id',\t'hadm_id',\t'stay_id',\t'starttime',\t'endtime', 'itemid',\t'amount',\t'amountuom', 'rate',\t'rateuom', 'patientweight', 'intime', 'length_minutes',\t'start_icu_day_id',\t'stop_icu_day_id',\t'start_icu_12h_id','stop_icu_12h_id','label']]\n",
    "data_medications.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH+'data_medications_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(data_medications, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH+'data_medications_icu.pkl', 'rb') as f:\n",
    "    data_medications = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.stay_id==32336619]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay = 39553978\n",
    "day = 2\n",
    "wind = 0\n",
    "stay_medications = data_medications[data_medications.stay_id==stay]\n",
    "subject_id = stay_medications.subject_id.unique()[0]\n",
    "hadm_id = stay_medications.hadm_id.unique()[0]\n",
    "if len(stay_medications)<1:\n",
    "    print('no meds')\n",
    "min_day_id = np.min(stay_medications.start_icu_day_id)\n",
    "max_day_id = np.max(stay_medications.stop_icu_day_id)\n",
    "days_arranged = np.arange(min_day_id, max_day_id+1)\n",
    "\n",
    "min_wind_id = np.min(stay_medications.start_icu_12h_id)\n",
    "max_wind_id = np.max(stay_medications.stop_icu_12h_id)\n",
    "winds_arranged = np.arange(min_wind_id, max_wind_id+1)\n",
    "\n",
    "med_names_l = []\n",
    "med_codes_l = []\n",
    "subject_id_l = []\n",
    "hadm_id_l = []\n",
    "days_arranged = []\n",
    "\n",
    "for wind in winds_arranged:\n",
    "    day = wind // 2\n",
    "    # day_med_info = stay_medications[(stay_medications.start_icu_day_id <= day)&(stay_medications.stop_icu_day_id >= day)]\n",
    "    _12h_med_info = stay_medications[(stay_medications.start_icu_12h_id <= wind)&(stay_medications.stop_icu_12h_id >= wind)]\n",
    "    med_names = _12h_med_info.label.unique()\n",
    "    med_codes = _12h_med_info.itemid.unique()\n",
    "    med_names_l.append('; '.join(med_names))\n",
    "    med_codes_l.append(' '.join(map(str,med_codes)))\n",
    "    subject_id_l.append(subject_id)\n",
    "    hadm_id_l.append(hadm_id)\n",
    "    days_arranged.append(day)\n",
    "\n",
    "pid_medications = {'subject_id': subject_id_l, 'hadm_id': hadm_id_l, 'icu_day_id': days_arranged, '_12h_window_id':winds_arranged, 'medications_names': med_names_l, 'medications_codes':med_codes_l}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in pid_medications.items():\n",
    "    print(k, len(pid_medications[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pid_medications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def get_medications_data(stay, raise_=False, winds_arranged=[0,1]):\n",
    "    try:\n",
    "        stay_medications = data_medications[data_medications.stay_id==stay]\n",
    "        if len(stay_medications)<1:\n",
    "            return\n",
    "        subject_id = stay_medications.subject_id.unique()[0]\n",
    "        hadm_id = stay_medications.hadm_id.unique()[0]\n",
    "        if len(stay_medications)<1:\n",
    "            return\n",
    "        min_day_id = np.min(stay_medications.start_icu_day_id)\n",
    "        max_day_id = np.max(stay_medications.stop_icu_day_id)\n",
    "        days_arranged = np.arange(min_day_id, max_day_id+1)\n",
    "        if winds_arranged is None:\n",
    "            min_wind_id = np.min(stay_medications.start_icu_12h_id)\n",
    "            max_wind_id = np.max(stay_medications.stop_icu_12h_id)\n",
    "            winds_arranged = np.arange(min_wind_id, max_wind_id+1)\n",
    "\n",
    "        med_names_l = []\n",
    "        med_codes_l = []\n",
    "        subject_id_l = []\n",
    "        hadm_id_l = []\n",
    "        stay_id_l = []\n",
    "        days_arranged = []\n",
    "\n",
    "        for wind in winds_arranged:\n",
    "            day = wind // 2\n",
    "            # day_med_info = stay_medications[(stay_medications.start_icu_day_id <= day)&(stay_medications.stop_icu_day_id >= day)]\n",
    "            _12h_med_info = stay_medications[(stay_medications.start_icu_12h_id <= wind)&(stay_medications.stop_icu_12h_id >= wind)]\n",
    "            # med_names = _12h_med_info.label.unique()\n",
    "            med_codes = list(_12h_med_info.itemid.unique())\n",
    "            # med_names_l.append('; '.join(med_names))\n",
    "            # med_codes_l.append(' '.join(map(lambda x: 'm' + str(x), med_codes)))\n",
    "            med_codes_l = [*med_codes_l, *med_codes]\n",
    "            subject_id_l.append(subject_id)\n",
    "            hadm_id_l.append(hadm_id)\n",
    "            stay_id_l.append(stay)\n",
    "            days_arranged.append(day)\n",
    "\n",
    "        pid_medications = {'subject_id': subject_id_l, 'hadm_id': hadm_id_l, 'stay_id':stay_id_l, 'icu_day_id': days_arranged, '_12h_window_id':winds_arranged, 'medications_codes':med_codes_l}\n",
    "        # pid_medications = {'subject_id': subject_id_l, 'hadm_id': hadm_id_l, 'stay_id':stay_id_l, 'icu_day_id': days_arranged, '_12h_window_id':winds_arranged, 'medications_names': med_names_l, 'medications_codes':med_codes_l}\n",
    "        return pid_medications\n",
    "    except:\n",
    "        print(stay)\n",
    "        if raise_:\n",
    "            raise\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def get_medications_data(stay, raise_=False, winds_arranged=[0,1]):\n",
    "    try:\n",
    "        stay_medications = data_medications[data_medications.stay_id==stay]\n",
    "        if len(stay_medications)<1:\n",
    "            return\n",
    "        subject_id = stay_medications.subject_id.unique()[0]\n",
    "        hadm_id = stay_medications.hadm_id.unique()[0]\n",
    "        if len(stay_medications)<1:\n",
    "            return\n",
    "        min_day_id = np.min(stay_medications.start_icu_day_id)\n",
    "        max_day_id = np.max(stay_medications.stop_icu_day_id)\n",
    "        days_arranged = np.arange(min_day_id, max_day_id+1)\n",
    "        if winds_arranged is None:\n",
    "            min_wind_id = np.min(stay_medications.start_icu_12h_id)\n",
    "            max_wind_id = np.max(stay_medications.stop_icu_12h_id)\n",
    "            winds_arranged = np.arange(min_wind_id, max_wind_id+1)\n",
    "\n",
    "        med_names_l = []\n",
    "        med_codes_l = []\n",
    "        subject_id_l = []\n",
    "        hadm_id_l = []\n",
    "        stay_id_l = []\n",
    "        days_arranged = []\n",
    "\n",
    "        for wind in winds_arranged:\n",
    "            day = wind // 2\n",
    "            # day_med_info = stay_medications[(stay_medications.start_icu_day_id <= day)&(stay_medications.stop_icu_day_id >= day)]\n",
    "            _12h_med_info = stay_medications[(stay_medications.start_icu_12h_id <= wind)&(stay_medications.stop_icu_12h_id >= wind)]\n",
    "            # med_names = _12h_med_info.label.unique()\n",
    "            med_codes = list(_12h_med_info.itemid.unique())\n",
    "            # med_names_l.append('; '.join(med_names))\n",
    "            # med_codes_l.append(' '.join(map(lambda x: 'm' + str(x), med_codes)))\n",
    "            med_codes_l = [*med_codes_l, *med_codes]\n",
    "            subject_id_l.append(subject_id)\n",
    "            hadm_id_l.append(hadm_id)\n",
    "            stay_id_l.append(stay)\n",
    "            days_arranged.append(day)\n",
    "\n",
    "        pid_medications = {'subject_id': subject_id_l, 'hadm_id': hadm_id_l, 'stay_id':stay_id_l, 'icu_day_id': days_arranged, '_12h_window_id':winds_arranged, 'medications_codes':med_codes_l}\n",
    "        # pid_medications = {'subject_id': subject_id_l, 'hadm_id': hadm_id_l, 'stay_id':stay_id_l, 'icu_day_id': days_arranged, '_12h_window_id':winds_arranged, 'medications_names': med_names_l, 'medications_codes':med_codes_l}\n",
    "        return pid_medications\n",
    "    except:\n",
    "        print(stay)\n",
    "        if raise_:\n",
    "            raise\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_medications_data(stay, raise_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay = 37510196\n",
    "pd.DataFrame(get_medications_data(stay, raise_=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medications[data_medications.stay_id==stay].sort_values(['start_icu_12h_id',\t'stop_icu_12h_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import traceback\n",
    "import multiprocessing\n",
    "\n",
    "final_meds = pd.DataFrame()\n",
    "chunk_size = 15000\n",
    "stays = list(data_icustays.stay_id.unique())\n",
    "n_chunks = len(stays)//chunk_size\n",
    "# n_chunks = 1\n",
    "\n",
    "\n",
    "for i in range(0, n_chunks+1):\n",
    "    with multiprocessing.Pool(processes=88) as pool_obj:\n",
    "        pid_medications = pool_obj.map(get_medications_data, stays[i*chunk_size:(i+1)*chunk_size])\n",
    "\n",
    "    for e in pid_medications[:]:\n",
    "        temp = pd.DataFrame(e)\n",
    "        final_meds = pd.concat([final_meds, temp], ignore_index=True)\n",
    "\n",
    "    print(\"------------ Finished {} admissions ------------\".format((i+1)*chunk_size))\n",
    "\n",
    "    with open(PKL_PATH + 'pid_medications_icu.pkl', 'wb') as f:\n",
    "        pickle.dump(final_meds, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_medications_icu.pkl', 'rb') as f:\n",
    "    pid_medications = pickle.load(f)\n",
    "pid_medications.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multihot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are used to preproccess data into the multihot vector format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH+'data_medications_icu.pkl', 'rb') as f:\n",
    "    data_medications = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data_medications[(data_medications.start_icu_day_id==0)][['subject_id',\t'hadm_id',\t'stay_id',\t'itemid', 'label']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.pivot_table(temp, index=['subject_id', 'hadm_id', 'stay_id'], columns='label')\n",
    "temp = temp.droplevel(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = ['med_' + col for col in temp.columns]\n",
    "temp.columns = new_names\n",
    "multihot_meds_icu_day_0 = temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihot_meds_icu_day_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'multihot_meds_icu_day_0.pkl', 'wb') as f:\n",
    "    pickle.dump(multihot_meds_icu_day_0, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chartevents Lab results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_labevents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs['valuenum'] = chartevents_labs['valuenum'].fillna(-1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_items_labs = chartevents_labs.itemid.unique()\n",
    "\n",
    "for _, row in data_d_items[data_d_items.itemid.isin(chart_items_labs)].iterrows():\n",
    "    print(row.itemid, '|', row.label, '|', row.abbreviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labs = chartevents_labs.merge(data_icustays[['subject_id', 'hadm_id', 'stay_id', 'intime', 'outtime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labs['icu_day_id'] = data_labs['charttime'] - data_labs['intime']\n",
    "data_labs['icu_day_id'] = [d.days for d in data_labs.loc[:, 'icu_day_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labs['icu_12h_window_id'] = data_labs['charttime'] - data_labs['intime']\n",
    "data_labs['icu_12h_window_id'] = [(d.days*24 + d.seconds//3600)//12 for d in data_labs.loc[:, 'icu_12h_window_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labs = data_labs.sort_values(['subject_id', 'charttime', 'stay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_labs = data_labs[data_labs.value.str.contains('[a-zA-Z]')]\n",
    "print(str_labs.abbreviation.unique())\n",
    "str_labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no str values so we proceed with making pid_dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs = data_labs[~(data_labs.value.str.contains('[a-zA-Z]'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_labs.pkl', 'wb') as f:\n",
    "    pickle.dump(chartevents_labs, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_labs.pkl', 'rb') as f:\n",
    "    chartevents_labs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PID labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stays = data_icustays[data_icustays.los>2].stay_id\n",
    "\n",
    "test = chartevents_labs[chartevents_labs.stay_id.isin(stays[:3])][['subject_id', 'hadm_id', 'stay_id', 'valuenum', 'valueuom','itemid', 'label', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id','itemid','label', 'icu_day_id'])\\\n",
    "        .agg({'valueuom':min, 'valuenum':'max'})\\\n",
    "            .reset_index()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print('1st row im progress..')\n",
    "#  = temp.droplevel(0, axis=1)\n",
    "# print('2st row im progress..')\n",
    "test.columns = ['subject_id', 'hadm_id', 'stay_id', 'itemid', 'label', 'icu_day_id',  'valueuom', 'max_value']\n",
    "# print('3st row im progress..')\n",
    "test = test.sort_values(['subject_id', 'icu_day_id'])\n",
    "print('4st row im progress..')\n",
    "# test['labs_names'] = test['label']  + ' {' + test['max_value'].astype(str) + '}'\n",
    "test['labs_codes'] = 'l' + test['itemid'].astype(str)  + ' {' + test['max_value'].astype(str) + '}'\n",
    "print('5st row im progress..')\n",
    "test_labs = test.groupby(['icu_day_id', 'subject_id', 'hadm_id', 'stay_id']).labs_codes.apply('; '.join).reset_index(name='labs_codes').sort_values(['subject_id', 'icu_day_id'])\n",
    "test_labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp = chartevents_labs[['subject_id', 'hadm_id', 'stay_id', 'valuenum', 'valueuom','itemid', 'label', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id','itemid','label', 'icu_day_id'])\\\n",
    "        .agg({'valueuom':min, 'valuenum':'max'})\\\n",
    "            .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print('1st row im progress..')\n",
    "# temp = temp.droplevel(0, axis=1)\n",
    "print('2st row im progress..')\n",
    "temp.columns = ['subject_id', 'hadm_id', 'stay_id', 'itemid', 'label', 'icu_day_id',  'valueuom', 'max_value']\n",
    "print('3st row im progress..')\n",
    "temp = temp.sort_values(['subject_id', 'icu_day_id'])\n",
    "print('4st row im progress..')\n",
    "temp['labs_codes'] = 'l' + temp['itemid'].astype(str)  + ' {' + temp['max_value'].astype(str) + '}'\n",
    "print('5st row im progress..')\n",
    "pid_labs_codes = temp.groupby(['icu_day_id', 'subject_id', 'hadm_id', 'stay_id']).labs_codes.apply('; '.join).reset_index(name='labs_codes').sort_values(['subject_id', 'icu_day_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_labs_codes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_labs = pid_labs.merge(pid_labs_codes, on=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_labs.loc[1, :].labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_labs.loc[1, :].labs_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_labs_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(pid_labs, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_labs_icu.pkl', 'rb') as f:\n",
    "    pid_labs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_omr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_icustays.shape)\n",
    "data_icustays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n of subject_ids which are NOT in data_omr table: ', data_icustays[~(data_icustays.subject_id.isin(data_omr.subject_id.unique()))].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics = data_icustays[['subject_id', 'hadm_id', 'stay_id', 'intime', 'outtime']].merge(data_omr[['subject_id', 'chartdate', 'result_name', 'result_value']], on='subject_id', how='outer').drop_duplicates()\n",
    "print(data_demographics.stay_id.unique().shape)\n",
    "data_demographics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics = data_demographics[(data_demographics.chartdate > data_demographics.intime - pd.Timedelta(360, 'd'))&(data_demographics.chartdate < data_demographics.outtime)]\\\n",
    "                                    .sort_values(['subject_id', 'intime', 'chartdate'], ascending=False)\\\n",
    "                                        .drop_duplicates(['stay_id', 'result_name'], keep='first')\\\n",
    "                                            .sort_values(['subject_id', 'chartdate'])\n",
    "print(data_demographics.stay_id.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics['result_name'] = data_demographics['result_name'].str.replace(\"(Inches)|(kg/m2)|(Lbs)|(\\(\\))\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics['name_result_value'] = data_demographics['result_name'] + ' {' + data_demographics['result_value'] + '} '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics.result_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = data_demographics.groupby(['hadm_id', 'stay_id']).name_result_value.apply(' '.join).reset_index(name='name_result_value')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_admissions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_patients.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics = pd.merge(data_admissions[['subject_id',\t'hadm_id',\t'admittime',\t'dischtime', 'race']], \\\n",
    "                                data_patients[['subject_id',\t'gender',\t'anchor_age',\t'anchor_year']], \\\n",
    "                                how='outer', on=['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get age of patients at the time of an admission\n",
    "data_demographics['age_of_birth'] = data_demographics['anchor_year'] - data_demographics['anchor_age']\n",
    "data_demographics['age'] = [value.year for value in data_demographics['admittime']] - data_demographics['age_of_birth']\n",
    "\n",
    "# drop unnecessary columns\n",
    "data_demographics = data_demographics.drop(['anchor_age','anchor_year', 'age_of_birth'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics.age = data_demographics.age.fillna(-1)\n",
    "data_demographics['age'] = data_demographics['age'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics = data_demographics.merge(res, on=['hadm_id'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build demographics sentence\n",
    "data_demographics['demographics'] = data_demographics['race'].astype(str) + ' ' + data_demographics['gender'].astype(str) + ' {' +  data_demographics['age'].astype(str) + '} ' + data_demographics['name_result_value'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics.race.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics['race'] = data_demographics['race'].str.replace(r'-', '')\n",
    "data_demographics['demographics'] = data_demographics['demographics'].str.replace(r'-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics[data_demographics.subject_id==subj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_demographics_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(data_demographics, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/svetlanamaslenkova/Documents/AKI_deep/LSTM/pickles/' + 'hid_previous_diagnoses.pkl', 'rb') as f:\n",
    "    hid_previous_diagnoses = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prev_diagnoses = hid_previous_diagnoses.merge(data_icustays[['subject_id', 'hadm_id', 'stay_id']], on='hadm_id', how='right')\n",
    "data_prev_diagnoses = data_prev_diagnoses[['subject_id', 'hadm_id', 'stay_id', 'previous_diags_icd', 'previous_diags_titles']]\n",
    "print(data_prev_diagnoses.shape)\n",
    "data_prev_diagnoses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_prev_diagnoses_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(data_prev_diagnoses, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle \n",
    "\n",
    "with open(PKL_PATH + 'pid_prev_diagnoses_icu.pkl', 'rb') as f:\n",
    "    pid_prev_diagnoses_icu = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_duags = pid_prev_diagnoses_icu.previous_diags_icd.str.split(' ').explode().unique()\n",
    "len(unique_duags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diagnoses.icd_code.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PATH = '/home/svetlanamaslenkova/Documents/AKI_deep/LSTM/pickles_2/aki_stage_labels.pkl'\n",
    "\n",
    "with open(LABELS_PATH, 'rb') as f:\n",
    "    aki_stage_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_status_icu.pkl', 'rb') as f:\n",
    "    aki_status_icu = pickle.load(f)\n",
    "aki_status_icu = aki_status_icu.groupby(['subject_id',\t'hadm_id',\t'stay_id', 'icu_day_id', 'specimen_id']).sum().reset_index()\n",
    "aki_status_icu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay = 30696680\n",
    "aki_status_icu[aki_status_icu.stay_id==stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay = 38020798\n",
    "subj = 12380418\n",
    "aki_status_icu[aki_status_icu.stay_id==stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_vitals_icu.pkl', 'rb') as f:\n",
    "    pid_vitals = pickle.load(f)\n",
    "print('unique stays: ', pid_vitals.stay_id.unique().shape[0])\n",
    "pid_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_vitals[pid_vitals.stay_id==stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals[chartevents_vitals.stay_id==stay].sort_values('charttime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_outputs.pkl', 'rb') as f:\n",
    "    pid_outputs = pickle.load(f)\n",
    "print('unique stays: ', pid_outputs.stay_id.unique().shape[0])\n",
    "pid_outputs[pid_outputs.subject_id==10001884].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_outputs[pid_outputs.stay_id==stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outputevents[data_outputevents.stay_id==stay].sort_values('charttime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_medications_icu.pkl', 'rb') as f:\n",
    "    pid_medications = pickle.load(f)\n",
    "pid_medications.rename(columns={'_12h_window_id':'icu_12h_window_id'}, inplace=True)\n",
    "print('unique stays: ', pid_medications.stay_id.unique().shape[0])\n",
    "pid_medications[pid_medications.subject_id==10001884].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_medications[pid_medications.stay_id==stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.stay_id==stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_labs_icu.pkl', 'rb') as f:\n",
    "    pid_labs = pickle.load(f)\n",
    "print('unique stays: ', pid_labs.stay_id.unique().shape[0])\n",
    "pid_labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_demographics_icu.pkl', 'rb') as f:\n",
    "    pid_demographics_icu =  pickle.load(f)\n",
    "print('unique stays: ', pid_demographics_icu.stay_id.unique().shape[0])\n",
    "pid_demographics_icu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu[pid_demographics_icu.subject_id==16093826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_patients[data_patients.subject_id==16093826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_prev_diagnoses_icu.pkl', 'rb') as f:\n",
    "    pid_prev_diagnoses_icu =  pickle.load(f)\n",
    "print('unique stays: ', pid_prev_diagnoses_icu.stay_id.unique().shape[0])\n",
    "pid_prev_diagnoses_icu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_prev_diagnoses_icu[pid_prev_diagnoses_icu.subject_id==subj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_admissions[data_admissions.subject_id==subj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first concatenate vitals, outputs and medication since they are 12h-level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous info\n",
    "pid_dataset_icu_cont = pid_vitals.merge(pid_outputs, how='outer', on=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id', 'icu_12h_window_id'])\\\n",
    "                            .merge(pid_medications, how='outer', on=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id', 'icu_12h_window_id'])\\\n",
    "                                .merge(pid_labs, how='outer', on=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'])\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_dataset_icu_cont.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static info\n",
    "pid_dataset_icu_static = pid_prev_diagnoses_icu.merge(pid_demographics_icu[['subject_id',\t'hadm_id',\t'stay_id',\t'demographics']], how='outer', on=['subject_id',\t'hadm_id'])\n",
    "pid_dataset_icu_static = pid_dataset_icu_static.rename(columns={'stay_id_x':'stay_id'}).drop(columns=['stay_id_y']).drop_duplicates()                       \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_dataset_icu_static.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two dataframes\n",
    "pid_dataset_icu = pid_dataset_icu_cont.merge(pid_dataset_icu_static, on=['subject_id',\t'hadm_id',\t'stay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels\n",
    "# pid_dataset_icu = pid_dataset_icu.merge(aki_status_icu[['subject_id',\t'hadm_id',\t'stay_id',\t'day_id',\t'icu_day_id',\t'icu_12h_window_id', 'AKI_1', 'AKI_2', 'AKI_3']], how='outer')\n",
    "pid_dataset_icu = pid_dataset_icu.merge(aki_stage_labels[['subject_id',\t'hadm_id',\t'stay_id',\t'day_id',\t'icu_day_id', 'AKI_1', 'AKI_2', 'AKI_3', 'NO_AKI', 'ANY_AKI']], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out nans\n",
    "pid_dataset_icu = pid_dataset_icu[~((pid_dataset_icu.outputs.isna())&(pid_dataset_icu.medications_names.isna())& (pid_dataset_icu.vitals.isna()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_dataset_icu.columns = ['icu_12h_window_id','icu_day_id', 'subject_id', 'hadm_id', 'stay_id','vitals_names', 'vitals_codes','outputs_names', 'outputs_codes',\\\n",
    "     'medications_names', 'medications_codes','labs_names', 'labs_codes', 'previous_diags_codes','previous_diags_names','demographics',  'day_id','AKI_1', 'AKI_2', 'AKI_3', 'NO_AKI', 'ANY_AKI']\n",
    "         \n",
    "# rearrange columns\n",
    "pid_dataset_icu = pid_dataset_icu[['subject_id',\t'hadm_id',\t'stay_id', 'day_id', 'icu_12h_window_id',\t'icu_day_id', 'demographics',\t'previous_diags_codes',\t\\\n",
    "    'previous_diags_names', 'vitals_names','vitals_codes',\t'labs_names','labs_codes',\t'outputs_names','outputs_codes',\t'medications_names','medications_codes', \\\n",
    "        'AKI_1', 'AKI_2', 'AKI_3', 'NO_AKI', 'ANY_AKI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_dataset_icu['demographics'] = pid_dataset_icu['demographics'].fillna('')\n",
    "pid_dataset_icu['previous_diags_codes'] = pid_dataset_icu['previous_diags_codes'].fillna('')\n",
    "pid_dataset_icu['previous_diags_names'] = pid_dataset_icu['previous_diags_names'].fillna('')\n",
    "pid_dataset_icu['vitals_names'] = pid_dataset_icu['vitals_names'].fillna('')\n",
    "pid_dataset_icu['vitals_codes'] = pid_dataset_icu['vitals_codes'].fillna('')\n",
    "pid_dataset_icu['labs_names'] = pid_dataset_icu['labs_names'].fillna('')\n",
    "pid_dataset_icu['labs_codes'] = pid_dataset_icu['labs_codes'].fillna('')\n",
    "pid_dataset_icu['outputs_names'] = pid_dataset_icu['outputs_names'].fillna('')\n",
    "pid_dataset_icu['outputs_codes'] = pid_dataset_icu['outputs_codes'].fillna('')\n",
    "pid_dataset_icu['medications_names'] = pid_dataset_icu['medications_names'].fillna('')\n",
    "pid_dataset_icu['medications_codes'] = pid_dataset_icu['medications_codes'].fillna('')\n",
    "\n",
    "pid_dataset_icu['AKI_1'] = pid_dataset_icu['AKI_1'].fillna(0)\n",
    "pid_dataset_icu['AKI_2'] = pid_dataset_icu['AKI_2'].fillna(0)\n",
    "pid_dataset_icu['AKI_3'] = pid_dataset_icu['AKI_3'].fillna(0)\n",
    "pid_dataset_icu['NO_AKI'] = pid_dataset_icu['NO_AKI'].fillna(0)\n",
    "pid_dataset_icu['ANY_AKI'] = pid_dataset_icu['ANY_AKI'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add concatenated info\n",
    "pid_dataset_icu['icu_12h_info_codes'] =  pid_dataset_icu['vitals_codes'] + ' $ ' +  pid_dataset_icu['outputs_codes'] + ' $ ' + pid_dataset_icu['medications_codes']\n",
    "pid_dataset_icu['icu_12h_info_names'] =   pid_dataset_icu['vitals_names'] + ' $ ' + pid_dataset_icu['outputs_names'] + ' $ ' + pid_dataset_icu['medications_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_dataset_icu.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter stays with no info for 0,1 days in icu\n",
    "stays_12h_0123 = []\n",
    "stays_without_12h_0123 = []\n",
    "for stay in pid_dataset_icu.stay_id.unique():\n",
    "    if np.isin(pid_dataset_icu[pid_dataset_icu.stay_id==stay].icu_12h_window_id.values, np.array([0,1,2,3])).sum() >3:\n",
    "        stays_12h_0123.append(stay)\n",
    "    elif np.isin(pid_dataset_icu[pid_dataset_icu.stay_id==stay].icu_day_id.values, np.array([0,1])).sum()>1:\n",
    "        stays_12h_0123.append(stay)\n",
    "        \n",
    "    else:\n",
    "        stays_without_12h_0123.append(stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(stays_12h_0123))\n",
    "print(len(stays_without_12h_0123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(stays_12h_0123))\n",
    "print(len(stays_without_12h_0123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer ICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = 28994087\n",
    "pid_dataset_icu[pid_dataset_icu.hadm_id==adm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_dataset_icu.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient - level info: demographics, last body measurements\n",
    "pid_dataset_icu.iloc[0, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12h info: vitals, medications, outputs\n",
    "pid_dataset_icu.iloc[0, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24h info: labs\n",
    "pid_dataset_icu.iloc[0, -9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 day info codes\n",
    "pid_dataset_icu.iloc[0, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 day info names\n",
    "pid_dataset_icu.iloc[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_dataset_icu.stay_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_dataset_icu.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_stays))\n",
    "print(len(test_stays))\n",
    "print(len(val_stays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_train_dataset_icu = pid_dataset_icu[pid_dataset_icu.stay_id.isin(train_stays)]\n",
    "pid_test_dataset_icu = pid_dataset_icu[pid_dataset_icu.stay_id.isin(test_stays)]\n",
    "pid_val_dataset_icu = pid_dataset_icu[pid_dataset_icu.stay_id.isin(val_stays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DF_PATH + 'pid_train_dataset_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(pid_train_dataset_icu, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(DF_PATH + 'pid_test_dataset_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(pid_test_dataset_icu, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(DF_PATH + 'pid_val_dataset_icu.pkl', 'wb') as f:\n",
    "    pickle.dump(pid_val_dataset_icu, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_stage_labels_second_day.pkl', 'rb') as f:\n",
    "    aki_stage_labels_second_day = pickle.load(f)\n",
    "aki_stage_labels_second_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset by stay_id and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value not in lst2]\n",
    "    #return lst3\n",
    "    return lst3\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    #return lst3\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DF_PATH + 'pid_train_dataset_icu.pkl', 'rb') as f:\n",
    "    pid_train_dataset_icu = pickle.load(f)\n",
    "\n",
    "with open(DF_PATH + 'pid_test_dataset_icu.pkl', 'rb') as f:\n",
    "    pid_test_dataset_icu = pickle.load(f)\n",
    "\n",
    "with open(DF_PATH + 'pid_val_dataset_icu.pkl', 'rb') as f:\n",
    "    pid_val_dataset_icu = pickle.load(f)\n",
    "\n",
    "LABELS_PATH = '/home/svetlanamaslenkova/Documents/AKI_deep/LSTM/pickles_2/aki_stage_labels.pkl'\n",
    "\n",
    "with open(LABELS_PATH, 'rb') as f:\n",
    "    aki_stage_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([pid_train_dataset_icu, pid_test_dataset_icu, pid_val_dataset_icu])\n",
    "stays = dataset.stay_id.unique()\n",
    "len(stays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_stage_labels = aki_stage_labels[aki_stage_labels.stay_id.isin(stays)&(aki_stage_labels.icu_day_id==1)]\n",
    "aki_stage_labels.stay_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_train_dataset_icu = pid_train_dataset_icu[pid_train_dataset_icu.stay_id.isin(aki_stage_labels.stay_id.unique())]\n",
    "pid_test_dataset_icu = pid_test_dataset_icu[pid_test_dataset_icu.stay_id.isin(aki_stage_labels.stay_id.unique())]\n",
    "pid_val_dataset_icu = pid_val_dataset_icu[pid_val_dataset_icu.stay_id.isin(aki_stage_labels.stay_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pid_train_dataset_icu.stay_id.unique().shape[0])\n",
    "print(pid_test_dataset_icu.stay_id.unique().shape[0])\n",
    "print(pid_val_dataset_icu.stay_id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_train_dataset_icu = pid_train_dataset_icu.replace(r'[{}]', '', regex=True)\n",
    "pid_test_dataset_icu = pid_test_dataset_icu.replace(r'[{}]', '', regex=True)\n",
    "pid_val_dataset_icu = pid_val_dataset_icu.replace(r'[{}]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in pid_test_dataset_icu[:50].groupby(['subject_id', 'hadm_id', 'stay_id']):\n",
    "    print(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in pid_test_dataset_icu.groupby(['subject_id', 'hadm_id', 'stay_id']):\n",
    "    if not os.path.exists(DF_PATH+'test_data'):\n",
    "        os.mkdir(DF_PATH+'test_data')\n",
    "    p = os.path.join(DF_PATH+'test_data', \"icu_stay_{}.csv\".format(str(i[2]).lower()))\n",
    "    x.to_csv(p, index=False)\n",
    "    print(f'Saved to {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/home/svetlanamaslenkova/Documents/AKI_deep/LSTM/dataframes_2/test_data/icu_stay_34868320.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in pid_train_dataset_icu.groupby(['subject_id', 'hadm_id', 'stay_id']):\n",
    "    if not os.path.exists(DF_PATH+'train_data'):\n",
    "        os.mkdir(DF_PATH+'train_data')\n",
    "    p = os.path.join(DF_PATH+'train_data', \"icu_stay_{}.csv\".format(str(i[2]).lower()))\n",
    "    x.to_csv(p, index=False)\n",
    "    print(f'Saved to {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in pid_val_dataset_icu.groupby(['subject_id', 'hadm_id', 'stay_id']):\n",
    "    if not os.path.exists(DF_PATH+'val_data'):\n",
    "        os.mkdir(DF_PATH+'val_data')\n",
    "    p = os.path.join(DF_PATH+'val_data', \"icu_stay_{}.csv\".format(str(i[2]).lower()))\n",
    "    x.to_csv(p, index=False)\n",
    "    print(f'Saved to {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer txt files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_train_dataset_icu.stay_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_pid_dataset_icu = pd.concat([pid_train_dataset_icu, pid_val_dataset_icu]).fillna('')\n",
    "print(tokenizer_pid_dataset_icu.stay_id.unique().shape[0])\n",
    "print(tokenizer_pid_dataset_icu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_train_dataset_icu.iloc[:1, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_train_dataset_icu.iloc[:1, 10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def create_text_seq(data, txt_dir, titles=False):\n",
    "    if titles:\n",
    "        previous_diags = 'previous_diags_titles'\n",
    "        info = 'icu_12h_info_titles'\n",
    "        labs = 'labs'\n",
    "    else:\n",
    "        previous_diags = 'previous_diags_icd'\n",
    "        info = 'icu_12h_info' \n",
    "        labs = 'labs_codes'\n",
    "\n",
    "    text_data = []\n",
    "    file_count = 0\n",
    "    hadm_id_d = {}\n",
    "\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        hadm_id = row['hadm_id']\n",
    "        icu_day_id = row['icu_day_id']\n",
    "        if hadm_id not in hadm_id_d:\n",
    "            hadm_id_d[hadm_id] = []\n",
    "            text_data.append(row['demographics'])\n",
    "            text_data.append(row[previous_diags])\n",
    "        if icu_day_id not in hadm_id_d[hadm_id]:\n",
    "            hadm_id_d[hadm_id].append(icu_day_id)\n",
    "            text_data.append(row[labs])\n",
    "        text_data.append(row[info])\n",
    "        if (len(text_data) % 5000) == 0:\n",
    "            # once we hit the 5K mark, save to file\n",
    "            if not os.path.exists(txt_dir):\n",
    "                os.makedirs(txt_dir)\n",
    "            with open(f'{txt_dir}/text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "                fp.write('\\n'.join(text_data))\n",
    "            text_data = []\n",
    "            file_count += 1\n",
    "            print(f\"Saved {5000 + (5000 * (file_count - 1))} samples\")\n",
    "\n",
    "    if (len(data) % 5000) != 0:\n",
    "        with open(f'{txt_dir}/text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "            fp.write('\\n'.join(text_data))\n",
    "        print(f\"Saved {5000 + (5000 * (file_count - 1)) + len(text_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT_DIR_TRAIN = '/home/svetlanamaslenkova/Documents/AKI_deep/LSTM/txt_files/icu_train'\n",
    "create_text_seq(data=tokenizer_pid_dataset_icu, txt_dir=TXT_DIR_TRAIN, titles=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT_DIR_TRAIN = '/home/svetlanamaslenkova/Documents/AKI_deep/LSTM/txt_files/icu_train_titles'\n",
    "create_text_seq(data=tokenizer_pid_dataset_icu, txt_dir=TXT_DIR_TRAIN, titles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aki_status_icu[aki_status_icu.stay_id==31090461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right on\n",
    "pid_dataset_icu[pid_dataset_icu.stay_id==31090461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left on\n",
    "pid_dataset_icu[pid_dataset_icu.stay_id==31090461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_admissions[data_admissions.subject_id==10840421].sort_values('admittime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.subject_id==10840421]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_DATA_PATH = '/home/svetlanamaslenkova/Documents/AKI_deep/xgb/dataframes/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_demographics_icu.pkl', 'rb') as f:\n",
    "    pid_demographics_icu =  pickle.load(f)\n",
    "print('unique stays: ', pid_demographics_icu.stay_id.unique().shape[0])\n",
    "pid_demographics_icu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.subject_id==10004457]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu = pid_demographics_icu.merge(data_icustays, on=['subject_id', 'hadm_id'], how='outer')\n",
    "# pid_demographics_icu[pid_demographics_icu.admittime>pid_demographics_icu.intime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_omr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics = data_icustays[['subject_id', 'hadm_id', 'stay_id', 'intime', 'outtime']].merge(data_omr[['subject_id', 'chartdate', 'result_name', 'result_value']], on='subject_id', how='inner').drop_duplicates()\n",
    "print(data_demographics.stay_id.unique().shape)\n",
    "data_demographics.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics[data_demographics.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_omr[data_omr.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics = data_demographics[(data_demographics.chartdate > data_demographics.intime - pd.Timedelta(360, 'd'))&(data_demographics.chartdate < data_demographics.outtime)]\\\n",
    "                                    .sort_values(['subject_id', 'intime', 'chartdate'], ascending=False)\\\n",
    "                                        .drop_duplicates(['stay_id', 'result_name'], keep='first')\\\n",
    "                                            .sort_values(['subject_id', 'chartdate'])\n",
    "print(data_demographics.stay_id.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics[data_demographics.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get omr numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_pressure_df = data_demographics[data_demographics.result_name.str.lower().str.contains('pressure')]\n",
    "data_demographics_omr = data_demographics[~(data_demographics.result_name.str.lower().str.contains('pressure'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr['result_value'] = pd.to_numeric(data_demographics_omr['result_value'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr = pd.pivot_table(data_demographics_omr, values='result_value', index=['subject_id', 'hadm_id', 'stay_id'], columns='result_name').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr = data_demographics_omr[['subject_id',\t'hadm_id',\t'stay_id', 'BMI (kg/m2)',\t'Height (Inches)',\t'Weight (Lbs)']]\n",
    "data_demographics_omr.columns = ['subject_id',\t'hadm_id',\t'stay_id', 'BMI',\t'Height',\t'Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 15926317\n",
    "data_demographics_omr[data_demographics_omr.subject_id==p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get BP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_pressure_df.drop_duplicates('result_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systolic_l, diastolic_l = [], []\n",
    "for pair in blood_pressure_df.result_value.str.split('/').values:\n",
    "    systolic_l.append(pair[0])\n",
    "    diastolic_l.append(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_pressure_df['systolic'] = systolic_l\n",
    "blood_pressure_df['diastolic'] = diastolic_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_pressure_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_df = pd.pivot_table(blood_pressure_df, values=['systolic', 'diastolic'], index=['subject_id', 'hadm_id', 'stay_id'], columns='result_name')\\\n",
    "            .droplevel(0, axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_df.columns = ['subject_id',\t'hadm_id',\t'stay_id', 'diastolic_bp', 'diastolic_bp_lying', 'diastolic_bp_sitting', 'diastolic_bp_standing', 'diastolic_bp_standing_1m', 'diastolic_bp_standing_3m', 'systolic_bp', 'systolic_bp_lying', 'systolic_bp_sitting', 'systolic_bp_standing', 'systolic_bp_standing_1m', 'systolic_bp_standing_3m' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_df = bp_df[['subject_id',\t'hadm_id',\t'stay_id', 'diastolic_bp', 'systolic_bp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine two frames:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr = data_demographics_omr.merge(bp_df, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 15926317\n",
    "pid_demographics_icu[pid_demographics_icu.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics_omr[data_demographics_omr.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_demographics_omr.pkl', 'wb') as f:\n",
    "    pickle.dump(data_demographics_omr, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine with Race, gender, ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu[pid_demographics_icu.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many stay_id_x and y are not the same\n",
    "print(pid_demographics_icu[~(pid_demographics_icu.stay_id_x==pid_demographics_icu.stay_id_y)].shape)\n",
    "pid_demographics_icu[~(pid_demographics_icu.stay_id_x==pid_demographics_icu.stay_id_y)].isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu['stay_id_x'] = pid_demographics_icu['stay_id_x'].fillna(pid_demographics_icu['stay_id_y']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu = pid_demographics_icu.rename(columns={'stay_id_x':'stay_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo = pid_demographics_icu[~(pid_demographics_icu.stay_id.isna())][['subject_id',\t'hadm_id',\t'stay_id', 'race',\t'gender', 'age']]\n",
    "demo = pid_demographics_icu[['subject_id',\t'hadm_id',\t'stay_id', 'race',\t'gender', 'age']]\n",
    "# data_demographics = demo.merge(data_demographics_omr, on=['subject_id',\t'hadm_id',\t'stay_id'], how='outer' )\n",
    "# data_demographics = demo.merge(data_demographics_omr, on=['subject_id',\t'hadm_id'], how='outer' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 15926317\n",
    "pid_demographics_icu[data_demographics.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_demographics['stay_id_x'] = data_demographics['stay_id_x'].fillna(data_demographics['stay_id_y']).fillna(0)\n",
    "# data_demographics = data_demographics.rename(columns={'stay_id_x':'stay_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_demographics.shape)\n",
    "data_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_demographics.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast categorical to numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu.gender[pid_demographics_icu.gender == 'F'] = 1\n",
    "pid_demographics_icu.gender[pid_demographics_icu.gender == 'M'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.factorize(pid_demographics_icu['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu['race'] = pd.factorize(pid_demographics_icu['race'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu['stay_id'] = pid_demographics_icu['stay_id'].fillna(0).astype('int64')\n",
    "pid_demographics_icu['hadm_id'] = pid_demographics_icu['hadm_id'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pid_demographics_icu = pid_demographics_icu.drop('stay_id_y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_omr[data_omr.subject_id==p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(XGB_DATA_PATH + 'data_demographics_xgb.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_demographics, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_labs.pkl', 'rb') as f:\n",
    "    chartevents_labs = pickle.load(f)\n",
    "chartevents_labs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stays = data_icustays[data_icustays.los>2].stay_id\n",
    "\n",
    "test = chartevents_labs[chartevents_labs.stay_id.isin(stays[:3])][['subject_id', 'hadm_id', 'stay_id', 'valuenum', 'valueuom','itemid', 'label', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id'])\\\n",
    "        .agg({ 'valuenum':['min','max']})\\\n",
    "            .reset_index()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.droplevel(0, axis=1)\n",
    "test.columns = ['subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id',  'min_value', 'max_value']\n",
    "test = test.sort_values(['subject_id', 'icu_day_id'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.pivot_table(test, index=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'], columns='label', values=['min_value', 'max_value'])\n",
    "# test = test.droplevel(0, axis=1)\n",
    "new_names = [*['min_'+col for col in test.iloc[:, :63].columns], *['max_'+col for col in test.iloc[:, 63:].columns]]\n",
    "test.columns = new_names\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = chartevents_labs[['subject_id', 'hadm_id', 'stay_id', 'valuenum', 'valueuom','itemid', 'label', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id'])\\\n",
    "        .agg({ 'valuenum':['min','max']})\\\n",
    "            .reset_index()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.droplevel(0, axis=1)\n",
    "temp.columns = ['subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id',  'min_value', 'max_value']\n",
    "temp = temp.sort_values(['subject_id', 'icu_day_id'])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.pivot_table(temp, index=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'], columns='label', values=['min_value', 'max_value'])\n",
    "temp = temp.droplevel(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(temp.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = [*['min_'+col for col in temp.iloc[:, :108].columns], *['max_'+col for col in temp.iloc[:, 108:].columns]]\n",
    "temp.columns = new_names\n",
    "temp = temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labs_xgb = temp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(XGB_DATA_PATH + 'data_labs_xgb.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_labs_xgb, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_labs_xgb.pkl', 'rb') as f:\n",
    "    data_labs_xgb = pickle.load(f)\n",
    "data_labs_xgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multihot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stays = data_icustays[data_icustays.los>2].stay_id\n",
    "\n",
    "test = chartevents_labs[(chartevents_labs.stay_id.isin(stays[:3]))&(chartevents_labs.icu_day_id==0)][['subject_id', 'hadm_id', 'stay_id', 'charttime', 'valuenum', 'valueuom','itemid', 'label', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id'])\\\n",
    "        .agg({'valuenum': [lambda x: x.iloc[0], lambda x: x.iloc[-1]]})\\\n",
    "            .reset_index()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.droplevel(0, axis=1)\n",
    "test.columns = ['subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id',  'first_value', 'last_value']\n",
    "test = test.sort_values(['subject_id', 'icu_day_id'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.pivot_table(test, index=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'], columns='label', values=['first_value', 'last_value'])\n",
    "test = test.droplevel(0, axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(test.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = [*['firsl_'+col for col in test.iloc[:, :58].columns], *['last_' + col for col in test.iloc[:, 58:].columns]]\n",
    "test.columns = new_names\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs[(chartevents_labs.stay_id==37510196)&(chartevents_labs.label=='ALT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = chartevents_labs[(chartevents_labs.icu_day_id==0)][['subject_id', 'hadm_id', 'stay_id', 'charttime', 'valuenum', 'valueuom','itemid', 'label', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id'])\\\n",
    "        .agg({'valuenum': [lambda x: x.iloc[0], lambda x: x.iloc[-1]]})\\\n",
    "            .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.droplevel(0, axis=1)\n",
    "temp.columns = ['subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id',  'first_value', 'last_value']\n",
    "temp = temp.sort_values(['subject_id', 'icu_day_id'])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.pivot_table(temp, index=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'], columns='label', values=['first_value', 'last_value'])\n",
    "temp = temp.droplevel(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(temp.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = [*['first_'+col for col in temp.iloc[:, :104].columns], *['last_' + col for col in temp.iloc[:, 104:].columns]]\n",
    "temp.columns = new_names\n",
    "multihot_labs_day_0 = temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in  multihot_labs_day_0.isna().sum().sort_values(ascending=False).iteritems():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(multihot_labs_day_0))\n",
    "print(multihot_labs_day_0.hadm_id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihot_labs_day_0[multihot_labs_day_0.duplicated('hadm_id')].sort_values(['hadm_id', 'icu_day_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'multihot_labs_icu_day_0.pkl', 'wb') as f:\n",
    "    pickle.dump(multihot_labs_day_0, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_vitals.pkl', 'rb') as f:\n",
    "    chartevents_vitals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chartevents_vitals = chartevents_vitals[~(chartevents_vitals.value.str.contains('[a-zA-Z]'))]\n",
    "num_chartevents_vitals['valuenum'] = num_chartevents_vitals['valuenum'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried to use label OR abbrevation OR itemid\n",
    "temp = num_chartevents_vitals[['subject_id', 'hadm_id', 'stay_id', 'itemid', 'valuenum', 'valueuom', 'abbreviation', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id', 'abbreviation', 'icu_day_id'])\\\n",
    "        .agg({'valuenum':['min', 'max']})\\\n",
    "            .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.droplevel(0, axis=1)\n",
    "temp.columns = ['subject_id', 'hadm_id', 'stay_id', 'label', 'icu_day_id',  'min_value', 'max_value']\n",
    "temp = temp.sort_values(['subject_id', 'icu_day_id'])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.pivot_table(temp, index=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'], columns='label', values=['min_value', 'max_value'])\n",
    "temp = temp.droplevel(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(temp.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = [*['min_'+col for col in temp.iloc[:, :33].columns], *['max_'+col for col in temp.iloc[:, 33:].columns]]\n",
    "temp.columns = new_names\n",
    "temp = temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vitals_xgb = temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vitals_xgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_vitals_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(data_vitals_xgb, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multihot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_vitals = chartevents_vitals.groupby(['subject_id', 'hadm_id', 'stay_id', 'abbreviation', 'icu_day_id']).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum value of vitals is 1 and maximum is 266. 75% of the samples have around 24 measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_vitals.sort_values('value').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = num_chartevents_vitals[num_chartevents_vitals.icu_day_id==0][['subject_id', 'hadm_id', 'stay_id', 'itemid', 'valuenum', 'valueuom', 'abbreviation', 'icu_day_id', 'icu_12h_window_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id', 'abbreviation', 'icu_day_id'])\\\n",
    "        .agg({'valuenum':[lambda x: x.iloc[0], lambda x: x.iloc[-1], 'median', 'min', 'max']})\\\n",
    "            .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals[(chartevents_vitals.stay_id==37510196)&(chartevents_vitals.icu_day_id==0)&(chartevents_vitals.abbreviation=='EtCO2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.droplevel(0, axis=1)\n",
    "temp.columns = ['subject_id', 'hadm_id', 'stay_id', 'abbreviation', 'icu_day_id',  'first_value', 'last_value', 'median_value',\t'min_value', 'max_value']\n",
    "temp = temp.sort_values(['subject_id', 'icu_day_id'])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.pivot_table(temp, index=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'], columns='abbreviation', values=['first_value', 'last_value', 'median_value',\t'min_value', 'max_value'])\n",
    "temp = temp.droplevel(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(temp.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = [*['first_'+col for col in temp.iloc[:, :33].columns], *['last_' + col for col in temp.iloc[:, 33:66].columns],\\\n",
    "     *['median_' + col for col in temp.iloc[:, 66:99].columns], *['min_' + col for col in temp.iloc[:, 99:132].columns], \\\n",
    "        *['max_' + col for col in temp.iloc[:, 132:].columns]]\n",
    "temp.columns = new_names\n",
    "multihot_vitals_day_0 = temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(multihot_vitals_day_0))\n",
    "print(multihot_vitals_day_0.hadm_id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihot_vitals_day_0.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'multihot_vitals_icu_day_0.pkl', 'wb') as f:\n",
    "    pickle.dump(multihot_vitals_day_0, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'data_outputevents.pkl', 'rb') as f:\n",
    "    data_outputevents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp = data_outputevents[['subject_id', 'hadm_id', 'stay_id', 'value', 'abbreviation', 'icu_day_id']]\\\n",
    "    .groupby(['subject_id', 'hadm_id', 'stay_id', 'abbreviation', 'icu_day_id'])\\\n",
    "        .agg({ 'value':sum})\\\n",
    "            .reset_index().sort_values(['subject_id', 'icu_day_id'])\n",
    "temp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.pivot_table(temp, index=['subject_id', 'hadm_id', 'stay_id', 'icu_day_id'], columns='abbreviation', values='value').reset_index()\n",
    "temp['output'] = temp['Foley'].fillna(0) + temp['Void'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_xgb = temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_xgb = data_output_xgb[['subject_id', 'hadm_id', 'stay_id', 'icu_day_id', 'output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_xgb = data_output_xgb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_xgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_output_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(data_output_xgb, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cirrhosis_icd = data_d_icd_diagnoses[data_d_icd_diagnoses.long_title.str.contains('cirrhosis')].icd_code.to_list()\n",
    "cad_icd = data_d_icd_diagnoses[data_d_icd_diagnoses.long_title.str.contains('coronary artery', case=False)].icd_code.to_list()\n",
    "chf_icd = data_d_icd_diagnoses[(data_d_icd_diagnoses.long_title.str.contains('heart failure', case=False))\\\n",
    "                                &(data_d_icd_diagnoses.long_title.str.contains('congestive', case=False))].icd_code.to_list()\n",
    "liver_icd = data_d_icd_diagnoses[(data_d_icd_diagnoses.long_title.str.contains('liver', case=False))\\\n",
    "                                &(data_d_icd_diagnoses.long_title.str.contains('disease', case=False))].icd_code.to_list()\n",
    "mi_icd = data_d_icd_diagnoses[(data_d_icd_diagnoses.long_title.str.contains('myocardial', case=False))\\\n",
    "                                &(data_d_icd_diagnoses.long_title.str.contains('infarction', case=False))\\\n",
    "                                    &~(data_d_icd_diagnoses.long_title.str.contains('not resulting', case=False))].icd_code.to_list()\n",
    "diabetes_icd = data_d_icd_diagnoses[data_d_icd_diagnoses.long_title.str.contains('diabetes', case=False)].icd_code.to_list()\n",
    "hypertension_icd = data_d_icd_diagnoses[data_d_icd_diagnoses.long_title.str.contains('hypertension', case=False)].icd_code.to_list()\n",
    "pv_icd = data_d_icd_diagnoses[(data_d_icd_diagnoses.long_title.str.contains('peripheral', case=False))\\\n",
    "                                &(data_d_icd_diagnoses.long_title.str.contains('vascular', case=False))].icd_code.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    #return lst3\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = data_icustays.hadm_id.unique()\n",
    "D = data_diagnoses.merge(data_d_icd_diagnoses).merge(data_admissions[['subject_id', 'hadm_id', 'admittime']])\n",
    "diag_l = {'cirrhosis':cirrhosis_icd, 'cad':cad_icd, 'chf':chf_icd, 'liver':liver_icd, 'mi':mi_icd, \\\n",
    "                'diabetes':diabetes_icd, 'hypertension':hypertension_icd, 'pv':pv_icd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prev_diags_dict_l = []\n",
    "i = 0\n",
    "\n",
    "for adm in admissions:\n",
    "    p = data_admissions[data_admissions.hadm_id==adm].subject_id.values[0]\n",
    "    admittime = data_admissions[data_admissions.hadm_id==adm].admittime.values[0]\n",
    "    if i % 1000 == 0:\n",
    "        print(f'{i}/{len(admissions)}')\n",
    "    prev_diags = list(D[(D.subject_id==p) & (D.admittime < admittime)].icd_code.values)\n",
    "    prev_diags_dict = {'hadm_id':adm}\n",
    "    for name, d in diag_l.items():\n",
    "        if intersection(prev_diags, d):\n",
    "            prev_diags_dict[name] = 1\n",
    "        else:\n",
    "            prev_diags_dict[name] = 0\n",
    "    prev_diags_dict_l.append(prev_diags_dict)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prev_diags_dict_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diags_xgb = pd.DataFrame(prev_diags_dict_l)\n",
    "data_diags_xgb.sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diags_xgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_diags_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(data_diags_xgb, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inputevents.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_medications_icu.pkl', 'rb') as f:\n",
    "    pid_medications = pickle.load(f)\n",
    "\n",
    "# pid_medications = pid_medications.merge(data_icustays[['subject_id', 'hadm_id', 'stay_id', 'intime']])\n",
    "pid_medications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names for NSAIDs medications M01\n",
    "M01_names = list(ndc_map[ndc_map.atc4.str.contains('M01', case=False)]\\\n",
    "                .drop_duplicates(subset='in_name', keep='first').in_name.values)\n",
    "\n",
    "print('M01_names: ', len(M01_names))\n",
    "\n",
    "# get names for lipid-lowering  medications C10\n",
    "C10_names = list(ndc_map[ndc_map.atc4.str.contains('C10', case=False)]\\\n",
    "                .drop_duplicates(subset='in_name', keep='first').in_name.values)\n",
    "print('C10_names', len(C10_names))\n",
    "\n",
    "# get names for antithrombotic medications\n",
    "B01_names = list(ndc_map[ndc_map.atc4.str.contains('B01', case=False)]\\\n",
    "                .drop_duplicates(subset='in_name', keep='first').in_name.values)\n",
    "\n",
    "print('B01_names', len(B01_names))\n",
    "\n",
    "# get names for diabetes medications\n",
    "diabetes_A10_names = list(ndc_map[ndc_map.atc4.str.contains('A10', case=False)]\\\n",
    "                .drop_duplicates(subset='in_name', keep='first').in_name.values)\n",
    "\n",
    "print('A10_names', len(diabetes_A10_names))\n",
    "\n",
    "# get names for diuretics medications\n",
    "C03_names = list(ndc_map[ndc_map.atc4.str.contains('C03', case=False)]\\\n",
    "                .drop_duplicates(subset='in_name', keep='first').in_name.values)\n",
    "print('C03_names', len(C03_names))\n",
    "\n",
    "# get names for antihypertensives medications\n",
    "C02_names = list(ndc_map[ndc_map.atc4.str.contains('C02', case=False)]\\\n",
    "                .drop_duplicates(subset='in_name', keep='first').in_name.values)\n",
    "print('C02_names', len(C02_names))\n",
    "\n",
    "# get names for V08 contrast media medications\n",
    "V08_names = list(ndc_map[ndc_map.atc4.str.contains('V08', case=False)]\\\n",
    "                .drop_duplicates(subset='in_name', keep='first').in_name.values)\n",
    "print('V08_names', len(V08_names))\n",
    "\n",
    "# get names for lipid-lowering  medications C09 agent acting on the renin-antiotensin system\n",
    "C09_names = list(ndc_map[ndc_map.atc4.str.contains('C09', case=False)]\\\n",
    "                .drop_duplicates(subset='in_name', keep='first').in_name.values)\n",
    "print('C09_names', len(C09_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stays = data_icustays[data_icustays.los>2].stay_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping over stays to get medications for a specific day in ICU (day 0)\n",
    "medication_mappings = [M01_names, C10_names, B01_names, diabetes_A10_names, C03_names, C02_names, C09_names]\n",
    "stay_medication_mapping_dict = {}\n",
    "# day in ICU to get medication info for\n",
    "icu_day = 0 \n",
    "i = 0\n",
    "\n",
    "for stay in stays:\n",
    "    if i % 1000==0:\n",
    "        print(f'{i}/{len(stays)}')\n",
    "  \n",
    "    stay_meds = pid_medications[(pid_medications.stay_id==stay)&(pid_medications.icu_day_id==icu_day)]\n",
    "    med_list = []\n",
    "    for medication_mapping, medication_code in zip(medication_mappings, ['M01', 'C10', 'B01', 'A10', 'C03', 'C02', 'C09']):\n",
    "        # print(medication_code)\n",
    "        medication_on_day = stay_meds[(stay_meds.medications_names.str.contains('|'.join(medication_mapping), case=False, na=''))]\n",
    "        if len(medication_on_day) > 0:\n",
    "            med_list.append(1)\n",
    "        else:\n",
    "            med_list.append(0)\n",
    "    stay_medication_mapping_dict[stay] = med_list \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medications_xgb = pd.DataFrame.from_dict(stay_medication_mapping_dict, orient='index')\n",
    "data_medications_xgb.columns = ['M01', 'C10', 'B01', 'A10', 'C03', 'C02', 'C09']\n",
    "data_medications_xgb = data_medications_xgb.drop(columns=['C10', 'A10', 'C09'])\n",
    "data_medications_xgb = data_medications_xgb.reset_index().rename(columns={'index':'stay_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medications_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medications_xgb.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay_meds = pid_medications[(pid_medications.stay_id==33685454)&(pid_medications.icu_day_id==icu_day)]\n",
    "stay_meds[(stay_meds.medications_names.str.contains('|'.join(C03_names), case=False, na=''))].medications_names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C03_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_medications_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(data_medications_xgb, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling XGB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_DATA_PATH = '/home/svetlanamaslenkova/Documents/AKI_deep/xgb/dataframes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'aki_status_icu.pkl', 'rb') as f:\n",
    "    aki_status_icu = pickle.load(f)\n",
    "aki_status_icu = aki_status_icu.groupby(['subject_id',\t'hadm_id',\t'stay_id', 'icu_day_id', 'specimen_id']).sum().reset_index()\n",
    "aki_status_icu['AKI_1'] = (aki_status_icu['AKI_1_scr'] + aki_status_icu['AKI_1_urine']).astype(bool).astype(int)\n",
    "aki_status_icu['AKI_2'] = (aki_status_icu['AKI_2_scr'] + aki_status_icu['AKI_2_urine']).astype(bool).astype(int)\n",
    "aki_status_icu['AKI_3'] = (aki_status_icu['AKI_3_scr'] + aki_status_icu['AKI_3_urine']).astype(bool).astype(int)\n",
    "aki_status_icu_day1 = aki_status_icu[aki_status_icu.icu_day_id==1]\n",
    "aki_status_icu_day1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_demographics_omr.pkl', 'rb') as f:\n",
    "    data_demographics_omr = pickle.load(f)\n",
    "data_demographics_omr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 15926317\n",
    "data_demographics[data_demographics.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_labs_xgb.pkl', 'rb') as f:\n",
    "    data_labs_xgb = pickle.load(f)\n",
    "data_labs_xgb['subject_id'] = data_labs_xgb['subject_id'].astype('int64')\n",
    "data_labs_xgb['stay_id'] = data_labs_xgb['stay_id'].astype('int64')\n",
    "data_labs_xgb['hadm_id'] = data_labs_xgb['hadm_id'].astype('int64')\n",
    "# take only day 0 of ICU stay\n",
    "data_labs_xgb = data_labs_xgb[data_labs_xgb.icu_day_id==0]\n",
    "print(data_labs_xgb.shape)\n",
    "data_labs_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_vitals_xgb.pkl', 'rb') as f:\n",
    "    data_vitals_xgb = pickle.load(f)\n",
    "data_vitals_xgb['subject_id'] = data_vitals_xgb['subject_id'].astype('int64')\n",
    "data_vitals_xgb['stay_id'] = data_vitals_xgb['stay_id'].astype('int64')\n",
    "data_vitals_xgb['hadm_id'] = data_vitals_xgb['hadm_id'].astype('int64')\n",
    "# take only day 0 of ICU stay\n",
    "data_vitals_xgb = data_vitals_xgb[data_vitals_xgb.icu_day_id==0]\n",
    "print(data_vitals_xgb.shape)\n",
    "data_vitals_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_output_xgb.pkl', 'rb') as f:\n",
    "    data_output_xgb = pickle.load(f)\n",
    "data_output_xgb = data_output_xgb[data_output_xgb.icu_day_id==0]\n",
    "print(data_output_xgb.shape)\n",
    "data_output_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_diags_xgb.pkl', 'rb') as f:\n",
    "    data_diags_xgb = pickle.load(f)\n",
    "data_diags_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_medications_xgb.pkl', 'rb') as f:\n",
    "    data_medications_xgb = pickle.load(f)\n",
    "data_medications_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'pid_demographics_icu.pkl', 'rb') as f:\n",
    "    pid_demographics_icu =  pickle.load(f)\n",
    "print('unique stays: ', pid_demographics_icu.stay_id.unique().shape[0])\n",
    "pid_demographics_icu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns with a lot of nan values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print how many NaN values in each column\n",
    "for col, num_nans in data_labs_xgb.isna().sum().sort_values().iteritems():\n",
    "    print(col, num_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labs_xgb = data_labs_xgb[data_labs_xgb.isna().sum().sort_values().index[:40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labs_xgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print how many NaN values in each column\n",
    "for col, num_nans in data_vitals_xgb.isna().sum().sort_values().iteritems():\n",
    "    print(col, num_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vitals_xgb = data_vitals_xgb[data_vitals_xgb.isna().sum().sort_values().index[:18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vitals_xgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb = data_demographics_omr.merge(data_labs_xgb[data_labs_xgb.icu_day_id==0], on=['subject_id', 'hadm_id', 'stay_id'], how='outer')\\\n",
    "                        .merge(data_vitals_xgb[data_vitals_xgb.icu_day_id==0], on=['subject_id', 'hadm_id', 'stay_id'], how='outer')\\\n",
    "                            .merge(data_output_xgb[data_output_xgb.icu_day_id==0], on=['subject_id', 'hadm_id', 'stay_id'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge data with demographics from pid_demographics_icu dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb = data_xgb.merge(pid_demographics_icu[['subject_id',\t'hadm_id', 'race', 'gender', 'age']], on=['subject_id', 'hadm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_xgb.icu_day_id.unique())\n",
    "print(data_xgb.icu_day_id_x.unique())\n",
    "print(data_xgb.icu_day_id_y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb['icu_day_id'] = data_xgb['icu_day_id'].fillna(0)\n",
    "data_xgb = data_xgb.drop(['icu_day_id', 'icu_day_id_x', 'icu_day_id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 15926317\n",
    "data_xgb[data_xgb.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_omr[data_omr.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_icustays[data_icustays.subject_id==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in data_xgb.isna().sum().sort_values().iteritems():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge data for the 0 day in ICU and labels for the 1st day in ICU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_xgb.shape)\n",
    "data_xgb.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aki_status_icu_day1.shape)\n",
    "aki_status_icu_day1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb = data_xgb.merge(aki_status_icu_day1[['subject_id',\t'hadm_id',\t'stay_id', 'AKI_1',\t'AKI_2', 'AKI_3']])\n",
    "print(data_xgb.shape)\n",
    "data_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb = data_xgb.drop_duplicates(subset=['subject_id',\t'hadm_id', 'stay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'unique patients: {data_xgb.subject_id.unique().shape[0]}')\n",
    "print(f'unique admissions: {data_xgb.hadm_id.unique().shape[0]}')\n",
    "print(f'unique ICU stays: {data_xgb.stay_id.unique().shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_demographics_icu[pid_demographics_icu.subject_id==19926342]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XGB_DATA_PATH + 'data_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(data_xgb, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore LIME explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_labs.pkl', 'rb') as f:\n",
    "    chartevents_labs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH + 'chartevents_vitals.pkl', 'rb') as f:\n",
    "    chartevents_vitals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PKL_PATH+'data_medications_icu.pkl', 'rb') as f:\n",
    "    data_medications = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs[chartevents_labs.itemid.isin([220228, 225625])].drop_duplicates('itemid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_labs[chartevents_labs.itemid==220228].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_vitals[chartevents_vitals.isin([220045])].drop_duplicates('itemid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d_icd_diagnoses[data_d_icd_diagnoses.icd_code.isin(['5920', '25053', '2724', 'E8798', '2572', 'Z87891', 'E0500', '7908', 'I2720', 'Z8505'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medications[data_medications.itemid.isin([223258, 227522, 225166, 223262])].drop_duplicates('itemid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb5fdc613a097f32ece1e000bc60f17f3e33b8b9e39d8b8753abf3e45200e5d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
